[2024-05-14T01:08:54.141+0000] {processor.py:161} INFO - Started process (PID=34) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:08:54.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T01:08:54.155+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:08:54.155+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:08:54.209+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:08:54.667+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:08:54.666+0000] {override.py:1769} INFO - Created Permission View: can read on DAG:data_pipeline_jobs104
[2024-05-14T01:08:54.752+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:08:54.751+0000] {override.py:1769} INFO - Created Permission View: can edit on DAG:data_pipeline_jobs104
[2024-05-14T01:08:54.788+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:08:54.788+0000] {override.py:1769} INFO - Created Permission View: can delete on DAG:data_pipeline_jobs104
[2024-05-14T01:08:54.802+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:08:54.802+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-14T01:08:54.816+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:08:54.816+0000] {dag.py:3069} INFO - Creating ORM DAG for data_pipeline_jobs104
[2024-05-14T01:08:54.818+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:08:54.818+0000] {dag.py:3834} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T01:08:54.881+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.747 seconds
[2024-05-14T01:54:03.663+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:54:03.664+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T01:54:03.670+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:54:03.670+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:54:03.691+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:54:03.867+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:54:03.867+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T01:54:03.901+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:54:03.901+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T01:54:03.931+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.276 seconds
[2024-05-14T01:54:33.974+0000] {processor.py:161} INFO - Started process (PID=91) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:54:33.975+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T01:54:33.976+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:54:33.975+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:54:33.979+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:54:33.990+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:54:33.989+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T01:54:33.998+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:54:33.998+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T01:54:34.006+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.036 seconds
[2024-05-14T01:55:04.707+0000] {processor.py:161} INFO - Started process (PID=149) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:55:04.709+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T01:55:04.714+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:55:04.714+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:55:04.722+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:55:04.748+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:55:04.747+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T01:55:04.760+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:55:04.760+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T01:55:04.774+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.087 seconds
[2024-05-14T01:55:34.815+0000] {processor.py:161} INFO - Started process (PID=208) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:55:34.816+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T01:55:34.818+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:55:34.818+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:55:34.825+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:55:34.840+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:55:34.839+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T01:55:34.847+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:55:34.847+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T01:55:34.856+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.050 seconds
[2024-05-14T01:56:05.023+0000] {processor.py:161} INFO - Started process (PID=267) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:56:05.025+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T01:56:05.028+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:56:05.028+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:56:05.038+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:56:05.060+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:56:05.059+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T01:56:05.072+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:56:05.071+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T01:56:05.083+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.072 seconds
[2024-05-14T01:56:35.163+0000] {processor.py:161} INFO - Started process (PID=325) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:56:35.165+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T01:56:35.170+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:56:35.170+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:56:35.184+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:56:35.206+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:56:35.206+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T01:56:35.217+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:56:35.216+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T01:56:35.228+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.074 seconds
[2024-05-14T01:57:05.294+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:57:05.298+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T01:57:05.301+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:57:05.300+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:57:05.310+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:57:05.329+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:57:05.329+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T01:57:05.338+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:57:05.338+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T01:57:05.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.064 seconds
[2024-05-14T01:57:36.054+0000] {processor.py:161} INFO - Started process (PID=443) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:57:36.056+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T01:57:36.058+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:57:36.058+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:57:36.067+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:57:36.086+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:57:36.086+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T01:57:36.095+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:57:36.095+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T01:57:36.106+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.062 seconds
[2024-05-14T01:58:06.796+0000] {processor.py:161} INFO - Started process (PID=502) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:58:06.798+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T01:58:06.800+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:58:06.800+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:58:06.808+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:58:06.827+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:58:06.826+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T01:58:06.835+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:58:06.835+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T01:58:06.846+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.060 seconds
[2024-05-14T01:58:37.546+0000] {processor.py:161} INFO - Started process (PID=560) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:58:37.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T01:58:37.551+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:58:37.551+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:58:37.559+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:58:37.577+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:58:37.577+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T01:58:37.586+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:58:37.586+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T01:58:37.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.059 seconds
[2024-05-14T01:59:08.355+0000] {processor.py:161} INFO - Started process (PID=619) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:59:08.357+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T01:59:08.359+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:59:08.359+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:59:08.369+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:59:08.388+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:59:08.388+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T01:59:08.397+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:59:08.397+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T01:59:08.408+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.062 seconds
[2024-05-14T01:59:39.138+0000] {processor.py:161} INFO - Started process (PID=678) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:59:39.140+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T01:59:39.144+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:59:39.143+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:59:39.155+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T01:59:39.175+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:59:39.175+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T01:59:39.184+0000] {logging_mixin.py:188} INFO - [2024-05-14T01:59:39.184+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T01:59:39.195+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.069 seconds
[2024-05-14T02:00:09.942+0000] {processor.py:161} INFO - Started process (PID=737) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:00:09.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:00:09.946+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:00:09.946+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:00:09.955+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:00:09.974+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:00:09.973+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:00:09.983+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:00:09.982+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:00:09.994+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.063 seconds
[2024-05-14T02:00:40.735+0000] {processor.py:161} INFO - Started process (PID=796) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:00:40.736+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:00:40.737+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:00:40.737+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:00:40.741+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:00:40.752+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:00:40.752+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:00:40.758+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:00:40.758+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:00:40.768+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.037 seconds
[2024-05-14T02:01:10.933+0000] {processor.py:161} INFO - Started process (PID=855) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:01:10.934+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:01:10.935+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:01:10.935+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:01:10.939+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:01:10.956+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:01:10.956+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:01:10.965+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:01:10.964+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:01:10.975+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.047 seconds
[2024-05-14T02:01:41.060+0000] {processor.py:161} INFO - Started process (PID=914) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:01:41.061+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:01:41.065+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:01:41.064+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:01:41.074+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:01:41.093+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:01:41.093+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:01:41.102+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:01:41.101+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:01:41.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.065 seconds
[2024-05-14T02:02:11.272+0000] {processor.py:161} INFO - Started process (PID=973) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:02:11.274+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:02:11.276+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:02:11.276+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:02:11.285+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:02:11.305+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:02:11.305+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:02:11.315+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:02:11.314+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:02:11.326+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.065 seconds
[2024-05-14T02:02:41.456+0000] {processor.py:161} INFO - Started process (PID=1032) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:02:41.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:02:41.461+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:02:41.460+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:02:41.472+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:02:41.497+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:02:41.497+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:02:41.507+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:02:41.507+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:02:41.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.075 seconds
[2024-05-14T02:03:11.578+0000] {processor.py:161} INFO - Started process (PID=1091) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:03:11.581+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:03:11.584+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:03:11.584+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:03:11.593+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:03:11.612+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:03:11.612+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:03:11.621+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:03:11.621+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:03:11.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.066 seconds
[2024-05-14T02:03:42.374+0000] {processor.py:161} INFO - Started process (PID=1150) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:03:42.375+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:03:42.379+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:03:42.378+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:03:42.388+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:03:42.410+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:03:42.410+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:03:42.420+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:03:42.420+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:03:42.432+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.068 seconds
[2024-05-14T02:04:12.460+0000] {processor.py:161} INFO - Started process (PID=1208) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:04:12.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:04:12.464+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:04:12.464+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:04:12.471+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:04:12.489+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:04:12.489+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:04:12.500+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:04:12.499+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:04:12.512+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.058 seconds
[2024-05-14T02:04:42.574+0000] {processor.py:161} INFO - Started process (PID=1267) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:04:42.575+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:04:42.576+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:04:42.576+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:04:42.580+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:04:42.593+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:04:42.593+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:04:42.603+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:04:42.602+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:04:42.615+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.050 seconds
[2024-05-14T02:05:12.748+0000] {processor.py:161} INFO - Started process (PID=1326) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:05:12.750+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:05:12.754+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:05:12.753+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:05:12.766+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:05:12.791+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:05:12.791+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:05:12.801+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:05:12.801+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:05:12.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.088 seconds
[2024-05-14T02:05:43.557+0000] {processor.py:161} INFO - Started process (PID=1385) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:05:43.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:05:43.562+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:05:43.562+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:05:43.571+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:05:43.586+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:05:43.586+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:05:43.594+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:05:43.594+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:05:43.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.059 seconds
[2024-05-14T02:06:13.707+0000] {processor.py:161} INFO - Started process (PID=1444) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:06:13.708+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:06:13.710+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:06:13.710+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:06:13.719+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:06:13.737+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:06:13.737+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:06:13.746+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:06:13.746+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:06:13.757+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.059 seconds
[2024-05-14T02:06:43.787+0000] {processor.py:161} INFO - Started process (PID=1503) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:06:43.789+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:06:43.792+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:06:43.792+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:06:43.801+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:06:43.821+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:06:43.821+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:06:43.831+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:06:43.831+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:06:43.844+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.066 seconds
[2024-05-14T02:07:13.887+0000] {processor.py:161} INFO - Started process (PID=1562) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:07:13.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:07:13.893+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:07:13.892+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:07:13.902+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:07:13.919+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:07:13.919+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:07:13.928+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:07:13.928+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:07:13.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.066 seconds
[2024-05-14T02:07:44.202+0000] {processor.py:161} INFO - Started process (PID=1621) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:07:44.203+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:07:44.206+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:07:44.206+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:07:44.216+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:07:44.235+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:07:44.235+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:07:44.244+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:07:44.244+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:07:44.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.065 seconds
[2024-05-14T02:08:14.495+0000] {processor.py:161} INFO - Started process (PID=1680) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:08:14.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:08:14.500+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:08:14.500+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:08:14.510+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:08:14.532+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:08:14.531+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:08:14.541+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:08:14.541+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:08:14.553+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.069 seconds
[2024-05-14T02:08:44.608+0000] {processor.py:161} INFO - Started process (PID=1739) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:08:44.610+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:08:44.613+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:08:44.613+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:08:44.623+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:08:44.644+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:08:44.644+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:08:44.655+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:08:44.655+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:08:44.669+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.071 seconds
[2024-05-14T02:09:14.744+0000] {processor.py:161} INFO - Started process (PID=1798) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:09:14.745+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:09:14.748+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:09:14.748+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:09:14.757+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:09:14.776+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:09:14.776+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:09:14.785+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:09:14.785+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:09:14.797+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.062 seconds
[2024-05-14T02:09:45.155+0000] {processor.py:161} INFO - Started process (PID=1857) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:09:45.156+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:09:45.158+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:09:45.158+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:09:45.165+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:09:45.180+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:09:45.180+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:09:45.188+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:09:45.188+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:09:45.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.051 seconds
[2024-05-14T02:10:15.543+0000] {processor.py:161} INFO - Started process (PID=1916) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:10:15.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:10:15.549+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:10:15.549+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:10:15.557+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:10:15.573+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:10:15.572+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:10:15.580+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:10:15.580+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:10:15.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.057 seconds
[2024-05-14T02:10:45.677+0000] {processor.py:161} INFO - Started process (PID=1975) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:10:45.679+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:10:45.681+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:10:45.680+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:10:45.688+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:10:45.703+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:10:45.703+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:10:45.710+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:10:45.710+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:10:45.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.049 seconds
[2024-05-14T02:11:16.427+0000] {processor.py:161} INFO - Started process (PID=2033) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:11:16.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:11:16.438+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:11:16.437+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:11:16.449+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:11:16.474+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:11:16.474+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:11:16.485+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:11:16.484+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:11:16.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.087 seconds
[2024-05-14T02:11:46.647+0000] {processor.py:161} INFO - Started process (PID=2092) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:11:46.648+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:11:46.650+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:11:46.650+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:11:46.658+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:11:46.677+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:11:46.676+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:11:46.686+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:11:46.686+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:11:46.697+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.055 seconds
[2024-05-14T02:12:16.851+0000] {processor.py:161} INFO - Started process (PID=2150) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:12:16.854+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:12:16.857+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:12:16.856+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:12:16.867+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:12:16.886+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:12:16.885+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:12:16.895+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:12:16.895+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:12:16.906+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.067 seconds
[2024-05-14T02:12:47.028+0000] {processor.py:161} INFO - Started process (PID=2208) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:12:47.029+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:12:47.030+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:12:47.030+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:12:47.036+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:12:47.051+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:12:47.051+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:12:47.059+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:12:47.058+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:12:47.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.043 seconds
[2024-05-14T02:13:15.624+0000] {processor.py:161} INFO - Started process (PID=30) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:13:15.625+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:13:15.629+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:13:15.629+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:13:15.651+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:13:15.844+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:13:15.844+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:13:15.865+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:13:15.864+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:13:15.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.272 seconds
[2024-05-14T02:13:45.943+0000] {processor.py:161} INFO - Started process (PID=37) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:13:45.944+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:13:45.946+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:13:45.946+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:13:45.957+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:13:45.979+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:13:45.979+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:13:45.987+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:13:45.987+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:13:45.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.058 seconds
[2024-05-14T02:14:16.246+0000] {processor.py:161} INFO - Started process (PID=44) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:14:16.247+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:14:16.256+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:14:16.255+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:14:16.272+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:14:16.304+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:14:16.304+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:14:16.313+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:14:16.313+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:14:16.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.088 seconds
[2024-05-14T02:14:46.596+0000] {processor.py:161} INFO - Started process (PID=51) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:14:46.598+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:14:46.601+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:14:46.601+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:14:46.618+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:14:46.640+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:14:46.640+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:14:46.647+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:14:46.647+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:14:46.655+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.069 seconds
[2024-05-14T02:15:16.938+0000] {processor.py:161} INFO - Started process (PID=58) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:15:16.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:15:16.941+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:15:16.941+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:15:16.951+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:15:16.972+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:15:16.971+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:15:16.979+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:15:16.979+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:15:16.988+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.057 seconds
[2024-05-14T02:15:38.190+0000] {processor.py:161} INFO - Started process (PID=64) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:15:38.191+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:15:38.194+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:15:38.193+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:15:38.200+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:15:38.199+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 9
    from tasks.app2. import say_hello
                     ^^^^^^
SyntaxError: invalid syntax
[2024-05-14T02:15:38.201+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:15:38.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.041 seconds
[2024-05-14T02:15:41.208+0000] {processor.py:161} INFO - Started process (PID=65) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:15:41.209+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:15:41.210+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:15:41.210+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:15:41.213+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:15:41.213+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 9
    from tasks.app2. import say_hello
                     ^^^^^^
SyntaxError: invalid syntax
[2024-05-14T02:15:41.214+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:15:41.225+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.020 seconds
[2024-05-14T02:15:54.623+0000] {processor.py:161} INFO - Started process (PID=66) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:15:54.625+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:15:54.628+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:15:54.627+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:15:54.634+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:15:54.633+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10
    from 
         ^
SyntaxError: invalid syntax
[2024-05-14T02:15:54.635+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:15:54.668+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.054 seconds
[2024-05-14T02:16:10.842+0000] {processor.py:161} INFO - Started process (PID=73) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:16:10.843+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:16:10.845+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:16:10.845+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:16:10.879+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:16:10.910+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:16:10.909+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:16:10.930+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:16:10.930+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:16:10.955+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.119 seconds
[2024-05-14T02:16:41.160+0000] {processor.py:161} INFO - Started process (PID=80) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:16:41.160+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:16:41.163+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:16:41.162+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:16:41.169+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:16:41.168+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 9, in <module>
    from tasks.app2 import say_hello
ModuleNotFoundError: No module named 'tasks.app2'
[2024-05-14T02:16:41.170+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:16:41.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.030 seconds
[2024-05-14T02:17:11.489+0000] {processor.py:161} INFO - Started process (PID=87) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:17:11.491+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:17:11.493+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:17:11.492+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:17:11.499+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:17:11.498+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 9, in <module>
    from tasks.app2 import say_hello
ModuleNotFoundError: No module named 'tasks.app2'
[2024-05-14T02:17:11.500+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:17:11.515+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.033 seconds
[2024-05-14T02:17:31.724+0000] {processor.py:161} INFO - Started process (PID=88) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:17:31.725+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:17:31.726+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:17:31.726+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:17:31.751+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:17:31.825+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:17:31.825+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:17:31.831+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:17:31.831+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:17:31.842+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.129 seconds
[2024-05-14T02:17:32.885+0000] {processor.py:161} INFO - Started process (PID=89) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:17:32.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:17:32.888+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:17:32.888+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:17:32.905+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:17:32.915+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:17:32.915+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:17:32.924+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:17:32.923+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:17:32.933+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.056 seconds
[2024-05-14T02:18:03.297+0000] {processor.py:161} INFO - Started process (PID=96) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:18:03.301+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:18:03.308+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:18:03.304+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:18:03.334+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:18:03.355+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:18:03.355+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:18:03.364+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:18:03.364+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:18:03.374+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.096 seconds
[2024-05-14T02:18:33.650+0000] {processor.py:161} INFO - Started process (PID=104) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:18:33.652+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:18:33.654+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:18:33.654+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:18:33.673+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:18:33.683+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:18:33.683+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:18:33.693+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:18:33.693+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:18:33.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.059 seconds
[2024-05-14T02:19:04.057+0000] {processor.py:161} INFO - Started process (PID=112) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:19:04.060+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:19:04.061+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:19:04.061+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:19:04.080+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:19:04.190+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:19:04.190+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:19:04.196+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:19:04.196+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:19:04.205+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.163 seconds
[2024-05-14T02:19:34.329+0000] {processor.py:161} INFO - Started process (PID=126) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:19:34.330+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:19:34.331+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:19:34.331+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:19:34.350+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:19:34.375+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:19:34.375+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:19:34.383+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:19:34.383+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:19:34.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.077 seconds
[2024-05-14T02:20:04.772+0000] {processor.py:161} INFO - Started process (PID=133) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:20:04.775+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:20:04.776+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:20:04.776+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:20:04.795+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:20:04.806+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:20:04.806+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:20:04.817+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:20:04.816+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:20:04.826+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.065 seconds
[2024-05-14T02:20:35.095+0000] {processor.py:161} INFO - Started process (PID=141) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:20:35.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:20:35.096+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:20:35.096+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:20:35.106+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:20:35.157+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:20:35.157+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:20:35.163+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:20:35.163+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:20:35.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.079 seconds
[2024-05-14T02:21:05.491+0000] {processor.py:161} INFO - Started process (PID=149) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:21:05.493+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:21:05.494+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:21:05.494+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:21:05.514+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:21:05.537+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:21:05.537+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:21:05.545+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:21:05.545+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:21:05.555+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.076 seconds
[2024-05-14T02:21:35.833+0000] {processor.py:161} INFO - Started process (PID=157) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:21:35.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:21:35.835+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:21:35.835+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:21:35.845+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:21:35.853+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:21:35.853+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:21:35.861+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:21:35.861+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:21:35.871+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.043 seconds
[2024-05-14T02:22:06.156+0000] {processor.py:161} INFO - Started process (PID=165) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:22:06.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:22:06.161+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:22:06.161+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:22:06.182+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:22:06.249+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:22:06.249+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:22:06.256+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:22:06.256+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:22:06.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.122 seconds
[2024-05-14T02:22:36.461+0000] {processor.py:161} INFO - Started process (PID=173) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:22:36.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:22:36.464+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:22:36.464+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:22:36.484+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:22:36.508+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:22:36.508+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:22:36.516+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:22:36.516+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:22:36.524+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.074 seconds
[2024-05-14T02:23:06.834+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:23:06.836+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:23:06.837+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:23:06.837+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:23:06.854+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:23:06.866+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:23:06.866+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:23:06.877+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:23:06.877+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:23:06.887+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.065 seconds
[2024-05-14T02:23:37.192+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:23:37.194+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:23:37.195+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:23:37.194+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:23:37.206+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:23:37.280+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:23:37.280+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:23:37.286+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:23:37.286+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:23:37.297+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.111 seconds
[2024-05-14T02:24:07.684+0000] {processor.py:161} INFO - Started process (PID=197) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:24:07.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:24:07.688+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:24:07.688+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:24:07.705+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:24:07.750+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:24:07.750+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:24:07.762+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:24:07.762+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:24:07.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.105 seconds
[2024-05-14T02:24:38.062+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:24:38.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:24:38.063+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:24:38.063+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:24:38.073+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:24:38.080+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:24:38.080+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:24:38.087+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:24:38.087+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:24:38.096+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.038 seconds
[2024-05-14T02:25:08.413+0000] {processor.py:161} INFO - Started process (PID=213) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:25:08.414+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:25:08.416+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:25:08.415+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:25:08.434+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:25:08.504+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:25:08.503+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:25:08.509+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:25:08.509+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:25:08.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.117 seconds
[2024-05-14T02:25:38.729+0000] {processor.py:161} INFO - Started process (PID=221) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:25:38.731+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:25:38.732+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:25:38.732+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:25:38.751+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:25:38.773+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:25:38.773+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:25:38.781+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:25:38.781+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:25:38.789+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.073 seconds
[2024-05-14T02:26:09.054+0000] {processor.py:161} INFO - Started process (PID=229) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:26:09.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:26:09.058+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:26:09.058+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:26:09.075+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:26:09.086+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:26:09.086+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:26:09.096+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:26:09.096+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:26:09.106+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.060 seconds
[2024-05-14T02:26:39.388+0000] {processor.py:161} INFO - Started process (PID=236) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:26:39.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:26:39.392+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:26:39.392+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:26:39.416+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:26:39.483+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:26:39.482+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:26:39.488+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:26:39.488+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:26:39.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.122 seconds
[2024-05-14T02:27:09.715+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:27:09.724+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:27:09.729+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:27:09.726+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:27:10.007+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:27:10.149+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:27:10.149+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:27:10.167+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:27:10.167+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:27:10.179+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.482 seconds
[2024-05-14T02:27:40.222+0000] {processor.py:161} INFO - Started process (PID=252) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:27:40.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:27:40.225+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:27:40.224+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:27:40.242+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:27:40.252+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:27:40.252+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:27:40.260+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:27:40.260+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:27:40.269+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.057 seconds
[2024-05-14T02:28:10.573+0000] {processor.py:161} INFO - Started process (PID=260) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:28:10.575+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:28:10.576+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:28:10.576+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:28:10.593+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:28:10.655+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:28:10.655+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:28:10.660+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:28:10.660+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:28:10.669+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.104 seconds
[2024-05-14T02:28:41.019+0000] {processor.py:161} INFO - Started process (PID=268) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:28:41.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:28:41.021+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:28:41.021+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:28:41.035+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:28:41.053+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:28:41.053+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:28:41.061+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:28:41.061+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:28:41.070+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.056 seconds
[2024-05-14T02:29:11.347+0000] {processor.py:161} INFO - Started process (PID=276) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:29:11.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:29:11.351+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:29:11.350+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:29:11.368+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:29:11.379+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:29:11.379+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:29:11.390+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:29:11.390+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:29:11.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.064 seconds
[2024-05-14T02:29:35.641+0000] {processor.py:161} INFO - Started process (PID=284) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:29:35.643+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:29:35.644+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:29:35.644+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:29:35.657+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:29:35.655+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 32, in <module>
    task1 = PythonOperator(
            ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 220, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 899, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 232, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'say_hello' has already been added to the DAG
[2024-05-14T02:29:35.658+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:29:35.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.038 seconds
[2024-05-14T02:30:05.946+0000] {processor.py:161} INFO - Started process (PID=292) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:30:05.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:30:05.949+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:30:05.949+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:30:05.961+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:30:05.959+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 32, in <module>
    task1 = PythonOperator(
            ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 220, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 899, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 232, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'say_hello' has already been added to the DAG
[2024-05-14T02:30:05.962+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:30:05.978+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.038 seconds
[2024-05-14T02:30:36.258+0000] {processor.py:161} INFO - Started process (PID=300) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:30:36.259+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:30:36.260+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:30:36.260+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:30:36.268+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:30:36.266+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 11, in <module>
    from tasks.app import check_update
ImportError: cannot import name 'check_update' from 'tasks.app' (/opt/airflow/dags/tasks/app.py)
[2024-05-14T02:30:36.268+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:30:36.282+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.031 seconds
[2024-05-14T02:31:06.589+0000] {processor.py:161} INFO - Started process (PID=308) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:31:06.590+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:31:06.592+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:31:06.591+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:31:06.602+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:31:06.601+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 11, in <module>
    from tasks.app import check_update
ImportError: cannot import name 'check_update' from 'tasks.app' (/opt/airflow/dags/tasks/app.py)
[2024-05-14T02:31:06.603+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:31:06.620+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.041 seconds
[2024-05-14T02:31:35.894+0000] {processor.py:161} INFO - Started process (PID=316) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:31:35.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:31:35.896+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:31:35.896+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:31:35.918+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:31:35.985+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:31:35.985+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:31:35.990+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:31:35.990+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:31:35.999+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.115 seconds
[2024-05-14T02:32:06.321+0000] {processor.py:161} INFO - Started process (PID=324) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:32:06.323+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:32:06.325+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:32:06.324+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:32:06.345+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:32:06.365+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:32:06.365+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:32:06.372+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:32:06.371+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:32:06.379+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.071 seconds
[2024-05-14T02:32:36.710+0000] {processor.py:161} INFO - Started process (PID=332) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:32:36.712+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:32:36.713+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:32:36.713+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:32:36.737+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:32:36.754+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:32:36.754+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:32:36.769+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:32:36.769+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:32:36.783+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.081 seconds
[2024-05-14T02:33:07.087+0000] {processor.py:161} INFO - Started process (PID=339) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:33:07.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:33:07.091+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:33:07.091+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:33:07.112+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:33:07.176+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:33:07.176+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:33:07.182+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:33:07.181+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:33:07.190+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.112 seconds
[2024-05-14T02:33:37.446+0000] {processor.py:161} INFO - Started process (PID=347) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:33:37.449+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:33:37.450+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:33:37.450+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:33:37.464+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:33:37.486+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:33:37.486+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:33:37.495+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:33:37.494+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:33:37.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.064 seconds
[2024-05-14T02:34:07.849+0000] {processor.py:161} INFO - Started process (PID=355) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:34:07.851+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:34:07.852+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:34:07.852+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:34:07.867+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:34:07.877+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:34:07.877+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:34:07.886+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:34:07.886+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:34:07.898+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.053 seconds
[2024-05-14T02:34:38.155+0000] {processor.py:161} INFO - Started process (PID=363) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:34:38.156+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:34:38.157+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:34:38.157+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:34:38.165+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:34:38.252+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:34:38.251+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:34:38.262+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:34:38.262+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:34:38.277+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.125 seconds
[2024-05-14T02:35:08.582+0000] {processor.py:161} INFO - Started process (PID=371) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:35:08.583+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:35:08.583+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:35:08.583+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:35:08.594+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:35:08.619+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:35:08.619+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:35:08.626+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:35:08.626+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:35:08.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.059 seconds
[2024-05-14T02:35:36.025+0000] {processor.py:161} INFO - Started process (PID=373) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:35:36.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:35:36.028+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:35:36.028+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:35:36.094+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:35:36.105+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:35:36.105+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:35:36.115+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:35:36.114+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:35:36.133+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.117 seconds
[2024-05-14T02:36:06.307+0000] {processor.py:161} INFO - Started process (PID=387) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:36:06.308+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:36:06.308+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:36:06.308+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:36:06.317+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:36:06.361+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:36:06.361+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:36:06.365+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:36:06.365+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:36:06.372+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.069 seconds
[2024-05-14T02:36:11.718+0000] {processor.py:161} INFO - Started process (PID=388) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:36:11.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:36:11.721+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:36:11.721+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:36:11.737+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:36:11.735+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 58, in <module>
    task1
NameError: name 'task1' is not defined
[2024-05-14T02:36:11.739+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:36:11.794+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.089 seconds
[2024-05-14T02:36:42.112+0000] {processor.py:161} INFO - Started process (PID=396) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:36:42.114+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:36:42.116+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:36:42.115+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:36:42.136+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:36:42.133+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 58, in <module>
    task1
NameError: name 'task1' is not defined
[2024-05-14T02:36:42.138+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:36:42.156+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.061 seconds
[2024-05-14T02:37:12.395+0000] {processor.py:161} INFO - Started process (PID=404) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:37:12.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:37:12.398+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:37:12.397+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:37:12.407+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:37:12.406+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 58, in <module>
    task1
NameError: name 'task1' is not defined
[2024-05-14T02:37:12.408+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:37:12.422+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.034 seconds
[2024-05-14T02:37:42.792+0000] {processor.py:161} INFO - Started process (PID=411) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:37:42.794+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:37:42.796+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:37:42.796+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:37:42.814+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:37:42.812+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 58, in <module>
    task1
NameError: name 'task1' is not defined
[2024-05-14T02:37:42.816+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:37:42.832+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.055 seconds
[2024-05-14T02:38:12.169+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:38:12.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:38:12.173+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:38:12.172+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:38:12.200+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:38:12.290+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:38:12.289+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:38:12.297+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:38:12.296+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:38:12.310+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.152 seconds
[2024-05-14T02:38:42.548+0000] {processor.py:161} INFO - Started process (PID=427) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:38:42.550+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:38:42.551+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:38:42.551+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:38:42.567+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:38:42.588+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:38:42.588+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:38:42.596+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:38:42.595+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:38:42.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.063 seconds
[2024-05-14T02:39:12.938+0000] {processor.py:161} INFO - Started process (PID=435) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:39:12.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:39:12.941+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:39:12.940+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:39:12.965+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:39:12.988+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:39:12.988+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:39:12.996+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:39:12.996+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:39:13.006+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.080 seconds
[2024-05-14T02:39:43.290+0000] {processor.py:161} INFO - Started process (PID=443) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:39:43.291+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:39:43.292+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:39:43.292+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:39:43.309+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:39:43.329+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:39:43.329+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:39:43.336+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:39:43.336+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:39:43.344+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.064 seconds
[2024-05-14T02:40:04.607+0000] {processor.py:161} INFO - Started process (PID=445) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:40:04.610+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:40:04.612+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:40:04.611+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:40:04.638+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:40:04.705+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:40:04.705+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:40:04.718+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:40:04.718+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:40:04.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.132 seconds
[2024-05-14T02:40:20.937+0000] {processor.py:161} INFO - Started process (PID=453) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:40:20.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:40:20.941+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:40:20.940+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:40:20.955+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:40:20.953+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 15, in <module>
    from tasks.app import data_analysis
ImportError: cannot import name 'data_analysis' from 'tasks.app' (/opt/airflow/dags/tasks/app.py)
[2024-05-14T02:40:20.956+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:40:20.973+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.048 seconds
[2024-05-14T02:40:24.005+0000] {processor.py:161} INFO - Started process (PID=456) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:40:24.005+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:40:24.006+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:40:24.005+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:40:24.011+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:40:24.010+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 15, in <module>
    from tasks.app import data_analysis
ImportError: cannot import name 'data_analysis' from 'tasks.app' (/opt/airflow/dags/tasks/app.py)
[2024-05-14T02:40:24.011+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:40:24.020+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.018 seconds
[2024-05-14T02:40:47.316+0000] {processor.py:161} INFO - Started process (PID=463) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:40:47.319+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:40:47.321+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:40:47.320+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:40:47.374+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:40:47.747+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:40:47.746+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:40:47.765+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:40:47.765+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:40:47.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.487 seconds
[2024-05-14T02:41:18.136+0000] {processor.py:161} INFO - Started process (PID=471) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:41:18.138+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:41:18.139+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:41:18.139+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:41:18.164+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:41:18.211+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:41:18.210+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:41:18.223+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:41:18.222+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:41:18.236+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.109 seconds
[2024-05-14T02:41:48.578+0000] {processor.py:161} INFO - Started process (PID=478) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:41:48.580+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:41:48.581+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:41:48.581+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:41:48.601+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:41:48.673+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:41:48.673+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:41:48.678+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:41:48.678+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:41:48.686+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.123 seconds
[2024-05-14T02:42:18.988+0000] {processor.py:161} INFO - Started process (PID=486) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:42:18.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:42:18.991+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:42:18.991+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:42:19.008+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:42:19.050+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:42:19.050+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:42:19.060+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:42:19.060+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:42:19.076+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.094 seconds
[2024-05-14T02:42:49.418+0000] {processor.py:161} INFO - Started process (PID=494) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:42:49.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:42:49.420+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:42:49.420+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:42:49.437+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:42:49.517+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:42:49.516+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:42:49.522+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:42:49.522+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:42:49.530+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.121 seconds
[2024-05-14T02:43:19.884+0000] {processor.py:161} INFO - Started process (PID=502) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:43:19.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:43:19.889+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:43:19.888+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:43:19.937+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:43:19.970+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:43:19.970+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:43:19.980+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:43:19.980+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:43:19.991+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.118 seconds
[2024-05-14T02:43:50.344+0000] {processor.py:161} INFO - Started process (PID=510) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:43:50.346+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:43:50.347+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:43:50.346+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:43:50.379+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:43:50.469+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:43:50.469+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:43:50.479+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:43:50.479+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:43:50.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.157 seconds
[2024-05-14T02:44:20.782+0000] {processor.py:161} INFO - Started process (PID=517) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:44:20.785+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:44:20.787+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:44:20.786+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:44:20.818+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:44:20.854+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:44:20.854+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:44:20.863+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:44:20.862+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:44:20.874+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.105 seconds
[2024-05-14T02:44:51.404+0000] {processor.py:161} INFO - Started process (PID=525) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:44:51.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:44:51.412+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:44:51.411+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:44:51.446+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:44:51.563+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:44:51.563+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:44:51.569+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:44:51.569+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:44:51.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.196 seconds
[2024-05-14T02:45:21.876+0000] {processor.py:161} INFO - Started process (PID=533) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:45:21.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:45:21.880+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:45:21.879+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:45:21.905+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:45:21.927+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:45:21.926+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:45:21.935+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:45:21.935+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:45:21.946+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.083 seconds
[2024-05-14T02:45:52.264+0000] {processor.py:161} INFO - Started process (PID=541) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:45:52.267+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:45:52.268+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:45:52.268+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:45:52.286+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:45:52.347+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:45:52.347+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:45:52.352+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:45:52.352+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:45:52.359+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.104 seconds
[2024-05-14T02:46:22.613+0000] {processor.py:161} INFO - Started process (PID=548) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:46:22.615+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:46:22.617+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:46:22.616+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:46:22.636+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:46:22.659+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:46:22.658+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:46:22.666+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:46:22.666+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:46:22.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.072 seconds
[2024-05-14T02:46:52.982+0000] {processor.py:161} INFO - Started process (PID=555) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:46:52.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:46:52.988+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:46:52.987+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:46:53.010+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:46:53.077+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:46:53.077+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:46:53.083+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:46:53.082+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:46:53.090+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.121 seconds
[2024-05-14T02:47:23.394+0000] {processor.py:161} INFO - Started process (PID=562) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:47:23.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:47:23.399+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:47:23.399+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:47:23.421+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:47:23.443+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:47:23.443+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:47:23.452+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:47:23.452+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:47:23.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.084 seconds
[2024-05-14T02:47:53.781+0000] {processor.py:161} INFO - Started process (PID=570) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:47:53.783+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:47:53.785+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:47:53.784+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:47:53.802+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:47:53.859+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:47:53.859+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:47:53.864+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:47:53.863+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:47:53.871+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.101 seconds
[2024-05-14T02:48:24.203+0000] {processor.py:161} INFO - Started process (PID=578) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:48:24.205+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:48:24.207+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:48:24.206+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:48:24.228+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:48:24.248+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:48:24.248+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:48:24.256+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:48:24.256+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:48:24.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.071 seconds
[2024-05-14T02:48:54.531+0000] {processor.py:161} INFO - Started process (PID=586) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:48:54.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:48:54.536+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:48:54.535+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:48:54.560+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:48:54.622+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:48:54.622+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:48:54.628+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:48:54.628+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:48:54.636+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.115 seconds
[2024-05-14T02:49:24.922+0000] {processor.py:161} INFO - Started process (PID=594) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:49:24.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:49:24.926+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:49:24.926+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:49:24.953+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:49:24.978+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:49:24.977+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:49:24.987+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:49:24.987+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:49:24.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.089 seconds
[2024-05-14T02:49:55.350+0000] {processor.py:161} INFO - Started process (PID=602) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:49:55.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:49:55.354+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:49:55.353+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:49:55.369+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:49:55.445+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:49:55.445+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:49:55.450+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:49:55.450+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:49:55.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.117 seconds
[2024-05-14T02:50:25.733+0000] {processor.py:161} INFO - Started process (PID=610) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:50:25.734+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:50:25.736+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:50:25.735+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:50:25.760+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:50:25.798+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:50:25.797+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:50:25.813+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:50:25.813+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:50:25.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.133 seconds
[2024-05-14T02:50:56.252+0000] {processor.py:161} INFO - Started process (PID=618) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:50:56.255+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:50:56.256+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:50:56.256+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:50:56.286+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:50:56.374+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:50:56.374+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:50:56.379+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:50:56.379+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:50:56.387+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.166 seconds
[2024-05-14T02:51:26.701+0000] {processor.py:161} INFO - Started process (PID=626) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:51:26.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:51:26.705+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:51:26.705+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:51:26.741+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:51:26.772+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:51:26.772+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:51:26.784+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:51:26.784+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:51:26.807+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.125 seconds
[2024-05-14T02:51:57.200+0000] {processor.py:161} INFO - Started process (PID=634) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:51:57.203+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:51:57.204+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:51:57.204+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:51:57.246+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:51:57.347+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:51:57.347+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:51:57.353+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:51:57.352+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:51:57.360+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.178 seconds
[2024-05-14T02:52:27.664+0000] {processor.py:161} INFO - Started process (PID=642) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:52:27.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:52:27.667+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:52:27.667+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:52:27.707+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:52:27.734+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:52:27.734+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:52:27.743+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:52:27.743+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:52:27.753+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.102 seconds
[2024-05-14T02:52:58.125+0000] {processor.py:161} INFO - Started process (PID=650) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:52:58.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:52:58.129+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:52:58.129+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:52:58.149+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:52:58.226+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:52:58.225+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:52:58.231+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:52:58.231+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:52:58.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.133 seconds
[2024-05-14T02:53:28.558+0000] {processor.py:161} INFO - Started process (PID=658) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:53:28.560+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:53:28.560+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:53:28.560+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:53:28.575+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:53:28.596+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:53:28.596+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:53:28.607+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:53:28.607+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:53:28.619+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.071 seconds
[2024-05-14T02:53:58.991+0000] {processor.py:161} INFO - Started process (PID=666) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:53:58.992+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:53:58.994+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:53:58.994+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:53:59.009+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:53:59.066+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:53:59.065+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:53:59.070+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:53:59.070+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:53:59.077+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.096 seconds
[2024-05-14T02:54:29.373+0000] {processor.py:161} INFO - Started process (PID=674) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:54:29.374+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:54:29.375+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:54:29.375+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:54:29.402+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:54:29.421+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:54:29.421+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:54:29.430+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:54:29.430+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:54:29.443+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.078 seconds
[2024-05-14T02:54:59.798+0000] {processor.py:161} INFO - Started process (PID=682) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:54:59.800+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:54:59.801+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:54:59.800+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:54:59.816+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:54:59.874+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:54:59.874+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:54:59.879+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:54:59.879+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:54:59.886+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.099 seconds
[2024-05-14T02:55:00.959+0000] {processor.py:161} INFO - Started process (PID=684) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:55:00.967+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:55:00.974+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:55:00.970+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:55:00.997+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:55:01.025+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:55:01.025+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:55:01.367+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:55:01.366+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:55:01.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.450 seconds
[2024-05-14T02:55:31.690+0000] {processor.py:161} INFO - Started process (PID=692) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:55:31.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:55:31.693+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:55:31.693+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:55:31.717+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:55:31.738+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:55:31.738+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:55:31.745+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:55:31.745+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:55:31.754+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.076 seconds
[2024-05-14T02:56:02.119+0000] {processor.py:161} INFO - Started process (PID=700) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:56:02.121+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:56:02.122+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:56:02.122+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:56:02.141+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:56:02.197+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:56:02.197+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:56:02.201+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:56:02.201+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:56:02.209+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.100 seconds
[2024-05-14T02:56:32.550+0000] {processor.py:161} INFO - Started process (PID=708) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:56:32.552+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:56:32.554+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:56:32.553+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:56:32.578+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:56:32.598+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:56:32.598+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:56:32.607+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:56:32.607+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:56:32.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.078 seconds
[2024-05-14T02:57:02.960+0000] {processor.py:161} INFO - Started process (PID=716) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:57:02.961+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:57:02.962+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:57:02.962+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:57:02.980+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:57:03.035+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:57:03.035+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:57:03.040+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:57:03.040+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:57:03.048+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.097 seconds
[2024-05-14T02:57:33.387+0000] {processor.py:161} INFO - Started process (PID=723) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:57:33.388+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:57:33.390+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:57:33.389+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:57:33.407+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:57:33.427+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:57:33.427+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:57:33.434+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:57:33.434+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:57:33.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.065 seconds
[2024-05-14T02:57:50.664+0000] {processor.py:161} INFO - Started process (PID=730) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:57:50.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:57:50.667+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:57:50.667+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:57:50.678+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:57:50.676+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17
    from tasks.
               ^
SyntaxError: invalid syntax
[2024-05-14T02:57:50.678+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:57:50.695+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.038 seconds
[2024-05-14T02:58:06.925+0000] {processor.py:161} INFO - Started process (PID=733) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:58:06.926+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:58:06.927+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:58:06.926+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:58:06.930+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:58:06.929+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17
    from tasks.
               ^
SyntaxError: invalid syntax
[2024-05-14T02:58:06.930+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:58:06.940+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.019 seconds
[2024-05-14T02:58:15.026+0000] {processor.py:161} INFO - Started process (PID=740) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:58:15.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:58:15.029+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:58:15.029+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:58:15.057+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:58:15.141+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:58:15.141+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:58:15.145+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:58:15.145+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:58:15.153+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.139 seconds
[2024-05-14T02:58:45.486+0000] {processor.py:161} INFO - Started process (PID=748) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:58:45.487+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:58:45.489+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:58:45.488+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:58:45.507+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:58:45.528+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:58:45.528+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T02:58:45.535+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:58:45.535+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T02:58:45.543+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.067 seconds
[2024-05-14T02:59:16.140+0000] {processor.py:161} INFO - Started process (PID=756) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:59:16.141+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:59:16.143+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:59:16.142+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:59:16.155+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:59:16.152+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T02:59:16.157+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:59:16.188+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.069 seconds
[2024-05-14T02:59:46.502+0000] {processor.py:161} INFO - Started process (PID=765) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:59:46.504+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T02:59:46.506+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:59:46.505+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:59:46.516+0000] {logging_mixin.py:188} INFO - [2024-05-14T02:59:46.515+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T02:59:46.517+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T02:59:46.536+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.048 seconds
[2024-05-14T03:00:16.809+0000] {processor.py:161} INFO - Started process (PID=773) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:00:16.811+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:00:16.813+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:00:16.812+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:00:16.823+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:00:16.821+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T03:00:16.823+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:00:16.843+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.046 seconds
[2024-05-14T03:00:47.277+0000] {processor.py:161} INFO - Started process (PID=781) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:00:47.279+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:00:47.280+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:00:47.280+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:00:47.289+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:00:47.287+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T03:00:47.290+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:00:47.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.040 seconds
[2024-05-14T03:01:17.652+0000] {processor.py:161} INFO - Started process (PID=789) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:01:17.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:01:17.655+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:01:17.655+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:01:17.665+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:01:17.663+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T03:01:17.665+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:01:17.683+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.044 seconds
[2024-05-14T03:01:48.008+0000] {processor.py:161} INFO - Started process (PID=797) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:01:48.009+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:01:48.010+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:01:48.009+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:01:48.025+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:01:48.018+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 3, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:01:48.027+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:01:48.047+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.046 seconds
[2024-05-14T03:02:18.367+0000] {processor.py:161} INFO - Started process (PID=805) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:02:18.368+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:02:18.370+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:02:18.369+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:02:18.384+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:02:18.382+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 3, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:02:18.385+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:02:18.407+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.049 seconds
[2024-05-14T03:02:48.677+0000] {processor.py:161} INFO - Started process (PID=813) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:02:48.679+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:02:48.680+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:02:48.679+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:02:48.688+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:02:48.687+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 3, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:02:48.688+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:02:48.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.033 seconds
[2024-05-14T03:03:18.968+0000] {processor.py:161} INFO - Started process (PID=821) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:03:18.970+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:03:18.971+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:03:18.970+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:03:18.981+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:03:18.979+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 3, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:03:18.981+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:03:18.999+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.042 seconds
[2024-05-14T03:03:49.385+0000] {processor.py:161} INFO - Started process (PID=829) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:03:49.387+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:03:49.389+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:03:49.389+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:03:49.399+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:03:49.397+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 3, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:03:49.400+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:03:49.418+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.048 seconds
[2024-05-14T03:04:19.711+0000] {processor.py:161} INFO - Started process (PID=837) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:04:19.712+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:04:19.712+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:04:19.712+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:04:19.718+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:04:19.717+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 3, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:04:19.719+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:04:19.729+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.023 seconds
[2024-05-14T03:04:50.180+0000] {processor.py:161} INFO - Started process (PID=845) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:04:50.182+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:04:50.183+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:04:50.182+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:04:50.212+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:04:50.332+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:04:50.332+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:04:50.339+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:04:50.339+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:04:50.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.183 seconds
[2024-05-14T03:05:20.663+0000] {processor.py:161} INFO - Started process (PID=853) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:05:20.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:05:20.667+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:05:20.666+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:05:20.688+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:05:20.722+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:05:20.722+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:05:20.730+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:05:20.730+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:05:20.742+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.090 seconds
[2024-05-14T03:05:51.141+0000] {processor.py:161} INFO - Started process (PID=861) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:05:51.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:05:51.143+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:05:51.143+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:05:51.159+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:05:51.213+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:05:51.213+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:05:51.217+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:05:51.217+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:05:51.225+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.093 seconds
[2024-05-14T03:06:21.567+0000] {processor.py:161} INFO - Started process (PID=869) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:06:21.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:06:21.570+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:06:21.569+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:06:21.591+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:06:21.609+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:06:21.608+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:06:21.617+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:06:21.616+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:06:21.626+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.069 seconds
[2024-05-14T03:06:52.001+0000] {processor.py:161} INFO - Started process (PID=877) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:06:52.003+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:06:52.004+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:06:52.004+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:06:52.015+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:06:52.014+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T03:06:52.016+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:06:52.034+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.045 seconds
[2024-05-14T03:07:22.442+0000] {processor.py:161} INFO - Started process (PID=885) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:07:22.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:07:22.446+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:07:22.446+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:07:22.455+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:07:22.454+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T03:07:22.456+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:07:22.471+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.039 seconds
[2024-05-14T03:07:52.785+0000] {processor.py:161} INFO - Started process (PID=893) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:07:52.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:07:52.787+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:07:52.787+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:07:52.796+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:07:52.795+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T03:07:52.797+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:07:52.812+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.035 seconds
[2024-05-14T03:08:23.225+0000] {processor.py:161} INFO - Started process (PID=901) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:08:23.227+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:08:23.228+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:08:23.228+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:08:23.237+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:08:23.235+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T03:08:23.237+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:08:23.253+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.039 seconds
[2024-05-14T03:08:53.512+0000] {processor.py:161} INFO - Started process (PID=910) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:08:53.514+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:08:53.515+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:08:53.515+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:08:53.524+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:08:53.522+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T03:08:53.524+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:08:53.542+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.038 seconds
[2024-05-14T03:09:23.871+0000] {processor.py:161} INFO - Started process (PID=918) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:09:23.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:09:23.874+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:09:23.873+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:09:23.881+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:09:23.880+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T03:09:23.882+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:09:23.909+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.044 seconds
[2024-05-14T03:09:54.218+0000] {processor.py:161} INFO - Started process (PID=926) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:09:54.219+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:09:54.220+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:09:54.220+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:09:54.226+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:09:54.225+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T03:09:54.227+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:09:54.256+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.044 seconds
[2024-05-14T03:10:24.571+0000] {processor.py:161} INFO - Started process (PID=934) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:10:24.574+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:10:24.576+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:10:24.575+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:10:24.588+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:10:24.587+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T03:10:24.589+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:10:24.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.098 seconds
[2024-05-14T03:10:55.003+0000] {processor.py:161} INFO - Started process (PID=942) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:10:55.006+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:10:55.008+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:10:55.007+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:10:55.019+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:10:55.018+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T03:10:55.020+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:10:55.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.060 seconds
[2024-05-14T03:11:25.284+0000] {processor.py:161} INFO - Started process (PID=950) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:11:25.285+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:11:25.286+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:11:25.286+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:11:25.295+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:11:25.294+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T03:11:25.296+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:11:25.318+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.041 seconds
[2024-05-14T03:11:55.731+0000] {processor.py:161} INFO - Started process (PID=958) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:11:55.736+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:11:55.739+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:11:55.738+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:11:55.751+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:11:55.749+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T03:11:55.752+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:11:55.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.064 seconds
[2024-05-14T03:12:26.095+0000] {processor.py:161} INFO - Started process (PID=965) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:12:26.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:12:26.102+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:12:26.102+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:12:26.115+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:12:26.113+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T03:12:26.116+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:12:26.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.081 seconds
[2024-05-14T03:12:56.460+0000] {processor.py:161} INFO - Started process (PID=973) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:12:56.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:12:56.465+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:12:56.465+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:12:56.491+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:12:56.490+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T03:12:56.492+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:12:56.515+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.072 seconds
[2024-05-14T03:13:26.893+0000] {processor.py:161} INFO - Started process (PID=981) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:13:26.896+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:13:26.897+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:13:26.897+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:13:26.907+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:13:26.906+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 10, in <module>
    from tasks.main import data_crawler_list
  File "/opt/airflow/dags/tasks/main.py", line 1
    import imports *
                   ^
SyntaxError: invalid syntax
[2024-05-14T03:13:26.908+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:13:26.926+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.048 seconds
[2024-05-14T03:13:57.295+0000] {processor.py:161} INFO - Started process (PID=989) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:13:57.296+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:13:57.297+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:13:57.297+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:13:57.318+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:13:57.413+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:13:57.413+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:13:57.422+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:13:57.421+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:13:57.433+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.150 seconds
[2024-05-14T03:14:27.757+0000] {processor.py:161} INFO - Started process (PID=997) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:14:27.759+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:14:27.760+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:14:27.760+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:14:27.780+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:14:27.801+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:14:27.801+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:14:27.808+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:14:27.808+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:14:27.816+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.068 seconds
[2024-05-14T03:14:58.184+0000] {processor.py:161} INFO - Started process (PID=1005) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:14:58.185+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:14:58.187+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:14:58.186+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:14:58.204+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:14:58.260+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:14:58.260+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:14:58.264+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:14:58.264+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:14:58.274+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.100 seconds
[2024-05-14T03:15:25.565+0000] {processor.py:161} INFO - Started process (PID=1013) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:15:25.567+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:15:25.568+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:15:25.567+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:15:25.581+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:15:25.578+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 31, in <module>
    python_callable=data_crawler_list
                    ^^^^^^^^^^^^^^^^^
NameError: name 'data_crawler_list' is not defined
[2024-05-14T03:15:25.584+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:15:25.600+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.045 seconds
[2024-05-14T03:15:49.864+0000] {processor.py:161} INFO - Started process (PID=1021) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:15:49.865+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:15:49.867+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:15:49.867+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:15:49.878+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:15:49.877+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 15, in <module>
    from tasks.app import data_analysis
ModuleNotFoundError: No module named 'tasks.app'
[2024-05-14T03:15:49.878+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:15:49.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.037 seconds
[2024-05-14T03:15:53.951+0000] {processor.py:161} INFO - Started process (PID=1024) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:15:53.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:15:53.954+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:15:53.954+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:15:53.965+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:15:53.964+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 15, in <module>
    from tasks.app import data_analysis
ModuleNotFoundError: No module named 'tasks.app'
[2024-05-14T03:15:53.966+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:15:53.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.032 seconds
[2024-05-14T03:16:13.186+0000] {processor.py:161} INFO - Started process (PID=1031) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:16:13.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:16:13.187+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:16:13.187+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:16:13.209+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:16:13.317+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:16:13.316+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:16:13.333+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:16:13.333+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:16:13.351+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.170 seconds
[2024-05-14T03:16:43.683+0000] {processor.py:161} INFO - Started process (PID=1039) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:16:43.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:16:43.689+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:16:43.688+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:16:43.721+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:16:43.762+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:16:43.762+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:16:43.783+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:16:43.782+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:16:43.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.149 seconds
[2024-05-14T03:17:14.188+0000] {processor.py:161} INFO - Started process (PID=1047) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:17:14.190+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:17:14.192+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:17:14.191+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:17:14.219+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:17:14.324+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:17:14.324+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:17:14.330+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:17:14.330+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:17:14.338+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.165 seconds
[2024-05-14T03:18:58.209+0000] {processor.py:161} INFO - Started process (PID=30) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:18:58.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:18:58.212+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:18:58.212+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:18:58.224+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:18:58.324+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:18:58.324+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:18:58.339+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:18:58.339+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:18:58.359+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.163 seconds
[2024-05-14T03:19:28.701+0000] {processor.py:161} INFO - Started process (PID=38) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:19:28.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:19:28.707+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:19:28.707+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:19:28.728+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:19:28.758+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:19:28.758+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:19:28.779+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:19:28.778+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:19:28.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.102 seconds
[2024-05-14T03:19:59.118+0000] {processor.py:161} INFO - Started process (PID=46) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:19:59.120+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:19:59.123+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:19:59.123+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:19:59.143+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:19:59.209+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:19:59.209+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:19:59.214+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:19:59.214+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:19:59.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.116 seconds
[2024-05-14T03:20:29.477+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:20:29.481+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:20:29.485+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:20:29.484+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:20:29.509+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:20:29.530+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:20:29.530+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:20:29.539+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:20:29.539+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:20:29.549+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.083 seconds
[2024-05-14T03:20:59.880+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:20:59.882+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:20:59.884+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:20:59.884+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:20:59.906+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:20:59.973+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:20:59.972+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:20:59.977+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:20:59.977+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:20:59.985+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.113 seconds
[2024-05-14T03:21:30.325+0000] {processor.py:161} INFO - Started process (PID=70) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:21:30.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:21:30.330+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:21:30.330+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:21:30.351+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:21:30.372+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:21:30.372+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:21:30.380+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:21:30.380+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:21:30.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.075 seconds
[2024-05-14T03:22:00.648+0000] {processor.py:161} INFO - Started process (PID=78) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:22:00.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:22:00.651+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:22:00.651+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:22:00.661+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:22:00.723+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:22:00.723+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:22:00.729+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:22:00.728+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:22:00.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.094 seconds
[2024-05-14T03:22:31.022+0000] {processor.py:161} INFO - Started process (PID=85) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:22:31.025+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:22:31.028+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:22:31.027+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:22:31.047+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:22:31.071+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:22:31.070+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:22:31.079+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:22:31.079+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:22:31.089+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.075 seconds
[2024-05-14T03:23:01.426+0000] {processor.py:161} INFO - Started process (PID=92) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:23:01.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:23:01.430+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:23:01.429+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:23:01.450+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:23:01.522+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:23:01.521+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:23:01.526+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:23:01.526+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:23:01.534+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.117 seconds
[2024-05-14T03:23:31.804+0000] {processor.py:161} INFO - Started process (PID=100) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:23:31.806+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:23:31.809+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:23:31.808+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:23:31.826+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:23:31.848+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:23:31.847+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:23:31.855+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:23:31.855+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:23:31.864+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.070 seconds
[2024-05-14T03:24:02.231+0000] {processor.py:161} INFO - Started process (PID=108) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:24:02.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:24:02.236+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:24:02.235+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:24:02.254+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:24:02.318+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:24:02.318+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:24:02.322+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:24:02.322+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:24:02.330+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.108 seconds
[2024-05-14T03:24:32.616+0000] {processor.py:161} INFO - Started process (PID=116) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:24:32.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:24:32.621+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:24:32.620+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:24:32.644+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:24:32.666+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:24:32.666+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:24:32.675+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:24:32.675+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:24:32.686+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.084 seconds
[2024-05-14T03:25:03.016+0000] {processor.py:161} INFO - Started process (PID=124) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:25:03.018+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:25:03.023+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:25:03.022+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:25:03.041+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:25:03.156+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:25:03.156+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:25:03.161+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:25:03.161+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:25:03.171+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.171 seconds
[2024-05-14T03:25:33.365+0000] {processor.py:161} INFO - Started process (PID=132) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:25:33.365+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:25:33.367+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:25:33.367+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:25:33.376+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:25:33.393+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:25:33.393+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:25:33.401+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:25:33.400+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:25:33.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.054 seconds
[2024-05-14T03:26:03.682+0000] {processor.py:161} INFO - Started process (PID=140) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:26:03.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:26:03.686+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:26:03.685+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:26:03.699+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:26:03.766+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:26:03.766+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:26:03.772+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:26:03.771+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:26:03.780+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.103 seconds
[2024-05-14T03:26:34.030+0000] {processor.py:161} INFO - Started process (PID=148) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:26:34.033+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:26:34.036+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:26:34.035+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:26:34.049+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:26:34.070+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:26:34.069+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:26:34.076+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:26:34.076+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:26:34.085+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.067 seconds
[2024-05-14T03:27:04.376+0000] {processor.py:161} INFO - Started process (PID=156) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:27:04.378+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:27:04.381+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:27:04.381+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:27:04.397+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:27:04.456+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:27:04.456+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:27:04.460+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:27:04.460+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:27:04.468+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.105 seconds
[2024-05-14T03:27:34.734+0000] {processor.py:161} INFO - Started process (PID=163) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:27:34.735+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:27:34.740+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:27:34.739+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:27:34.760+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:27:34.784+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:27:34.784+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:27:34.794+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:27:34.794+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:27:34.804+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.080 seconds
[2024-05-14T03:28:05.135+0000] {processor.py:161} INFO - Started process (PID=171) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:28:05.138+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:28:05.149+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:28:05.146+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:28:05.176+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:28:05.244+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:28:05.244+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:28:05.249+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:28:05.249+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:28:05.257+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.137 seconds
[2024-05-14T03:28:35.550+0000] {processor.py:161} INFO - Started process (PID=178) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:28:35.554+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:28:35.557+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:28:35.557+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:28:35.572+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:28:35.597+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:28:35.596+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:28:35.605+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:28:35.605+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:28:35.615+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.072 seconds
[2024-05-14T03:29:06.004+0000] {processor.py:161} INFO - Started process (PID=186) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:29:06.005+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:29:06.008+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:29:06.008+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:29:06.025+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:29:06.122+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:29:06.121+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:29:06.127+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:29:06.127+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:29:06.136+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.147 seconds
[2024-05-14T03:29:36.416+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:29:36.417+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:29:36.422+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:29:36.421+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:29:36.442+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:29:36.465+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:29:36.465+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:29:36.474+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:29:36.474+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:29:36.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.083 seconds
[2024-05-14T03:30:06.807+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:30:06.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:30:06.812+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:30:06.811+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:30:06.830+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:30:06.891+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:30:06.891+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:30:06.897+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:30:06.896+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:30:06.907+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.110 seconds
[2024-05-14T03:30:37.213+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:30:37.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:30:37.217+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:30:37.217+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:30:37.231+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:30:37.251+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:30:37.251+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:30:37.259+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:30:37.259+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:30:37.268+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.066 seconds
[2024-05-14T03:31:07.584+0000] {processor.py:161} INFO - Started process (PID=218) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:31:07.585+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:31:07.589+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:31:07.589+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:31:07.609+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:31:07.679+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:31:07.679+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:31:07.684+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:31:07.684+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:31:07.695+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.123 seconds
[2024-05-14T03:31:38.008+0000] {processor.py:161} INFO - Started process (PID=226) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:31:38.010+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:31:38.014+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:31:38.014+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:31:38.032+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:31:38.055+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:31:38.055+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:31:38.064+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:31:38.064+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:31:38.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.079 seconds
[2024-05-14T03:32:08.438+0000] {processor.py:161} INFO - Started process (PID=233) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:32:08.440+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:32:08.448+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:32:08.448+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:32:08.468+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:32:08.574+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:32:08.574+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:32:08.583+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:32:08.582+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:32:08.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.182 seconds
[2024-05-14T03:32:38.867+0000] {processor.py:161} INFO - Started process (PID=241) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:32:38.869+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:32:38.873+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:32:38.872+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:32:38.895+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:32:38.920+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:32:38.920+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:32:38.929+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:32:38.929+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:32:38.940+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.082 seconds
[2024-05-14T03:33:09.255+0000] {processor.py:161} INFO - Started process (PID=249) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:33:09.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:33:09.260+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:33:09.260+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:33:09.274+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:33:09.338+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:33:09.338+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:33:09.343+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:33:09.343+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:33:09.350+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.101 seconds
[2024-05-14T03:33:39.612+0000] {processor.py:161} INFO - Started process (PID=256) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:33:39.615+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:33:39.619+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:33:39.618+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:33:39.638+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:33:39.659+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:33:39.659+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:33:39.667+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:33:39.667+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:33:39.676+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.073 seconds
[2024-05-14T03:34:10.083+0000] {processor.py:161} INFO - Started process (PID=264) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:34:10.085+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:34:10.088+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:34:10.088+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:34:10.104+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:34:10.188+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:34:10.187+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:34:10.194+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:34:10.194+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:34:10.205+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.131 seconds
[2024-05-14T03:34:40.497+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:34:40.500+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:34:40.514+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:34:40.509+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:34:40.549+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:34:40.578+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:34:40.578+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:34:40.588+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:34:40.588+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:34:40.602+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.113 seconds
[2024-05-14T03:35:11.025+0000] {processor.py:161} INFO - Started process (PID=280) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:35:11.033+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:35:11.044+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:35:11.043+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:35:11.062+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:35:11.169+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:35:11.168+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:35:11.175+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:35:11.175+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:35:11.186+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.180 seconds
[2024-05-14T03:35:41.509+0000] {processor.py:161} INFO - Started process (PID=287) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:35:41.512+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:35:41.516+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:35:41.516+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:35:41.546+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:35:41.584+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:35:41.584+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:35:41.608+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:35:41.608+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:35:41.620+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.133 seconds
[2024-05-14T03:36:11.951+0000] {processor.py:161} INFO - Started process (PID=295) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:36:11.953+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:36:11.957+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:36:11.956+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:36:11.975+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:36:12.044+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:36:12.044+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:36:12.049+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:36:12.049+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:36:12.057+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.122 seconds
[2024-05-14T03:36:42.345+0000] {processor.py:161} INFO - Started process (PID=303) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:36:42.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:36:42.352+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:36:42.352+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:36:42.369+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:36:42.393+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:36:42.393+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:36:42.402+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:36:42.402+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:36:42.413+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.081 seconds
[2024-05-14T03:37:12.819+0000] {processor.py:161} INFO - Started process (PID=311) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:37:12.821+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:37:12.825+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:37:12.824+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:37:12.842+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:37:12.937+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:37:12.937+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:37:12.942+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:37:12.942+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:37:12.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.148 seconds
[2024-05-14T03:37:43.265+0000] {processor.py:161} INFO - Started process (PID=319) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:37:43.267+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:37:43.272+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:37:43.271+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:37:43.287+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:37:43.310+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:37:43.310+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:37:43.320+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:37:43.320+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:37:43.330+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.080 seconds
[2024-05-14T03:37:50.432+0000] {processor.py:161} INFO - Started process (PID=321) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:37:50.433+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:37:50.434+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:37:50.434+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:37:50.444+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:37:50.453+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:37:50.453+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T03:37:50.461+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:37:50.461+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T03:37:50.472+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.044 seconds
[2024-05-14T03:38:09.669+0000] {processor.py:161} INFO - Started process (PID=328) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:38:09.671+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:38:09.673+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:38:09.673+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:38:09.680+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:38:09.678+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16
    from tasks.imports *
                       ^
SyntaxError: invalid syntax
[2024-05-14T03:38:09.680+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:38:09.697+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.036 seconds
[2024-05-14T03:38:40.138+0000] {processor.py:161} INFO - Started process (PID=336) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:38:40.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:38:40.146+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:38:40.146+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:38:40.153+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:38:40.152+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16
    from tasks.imports *
                       ^
SyntaxError: invalid syntax
[2024-05-14T03:38:40.154+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:38:40.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.060 seconds
[2024-05-14T03:39:10.564+0000] {processor.py:161} INFO - Started process (PID=344) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:39:10.567+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:39:10.571+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:39:10.571+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:39:10.577+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:39:10.576+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16
    from tasks.imports *
                       ^
SyntaxError: invalid syntax
[2024-05-14T03:39:10.578+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:39:10.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.048 seconds
[2024-05-14T03:39:35.895+0000] {processor.py:161} INFO - Started process (PID=352) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:39:35.898+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:39:35.900+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:39:35.899+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:39:35.907+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:39:35.905+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16
    from tasks.imports *
                       ^
SyntaxError: invalid syntax
[2024-05-14T03:39:35.907+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:39:35.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.039 seconds
[2024-05-14T03:40:06.250+0000] {processor.py:161} INFO - Started process (PID=360) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:40:06.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:40:06.256+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:40:06.255+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:40:06.263+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:40:06.262+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16
    from tasks.imports *
                       ^
SyntaxError: invalid syntax
[2024-05-14T03:40:06.264+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:40:06.282+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.043 seconds
[2024-05-14T03:40:21.614+0000] {processor.py:161} INFO - Started process (PID=362) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:40:21.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:40:21.618+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:40:21.618+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:40:21.658+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:40:21.657+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16, in <module>
    from tasks.imports import *
  File "/opt/airflow/dags/tasks/imports.py", line 1, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:40:21.659+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:40:21.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.106 seconds
[2024-05-14T03:40:51.955+0000] {processor.py:161} INFO - Started process (PID=370) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:40:51.958+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:40:51.959+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:40:51.959+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:40:51.969+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:40:51.968+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 11, in <module>
    from tasks.main import check_if_update
  File "/opt/airflow/dags/tasks/main.py", line 1, in <module>
    from imports import *
ModuleNotFoundError: No module named 'imports'
[2024-05-14T03:40:51.970+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:40:51.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.040 seconds
[2024-05-14T03:41:22.502+0000] {processor.py:161} INFO - Started process (PID=378) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:41:22.504+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:41:22.506+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:41:22.505+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:41:22.521+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:41:22.518+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 11, in <module>
    from tasks.main import check_if_update
  File "/opt/airflow/dags/tasks/main.py", line 1, in <module>
    from imports import *
ModuleNotFoundError: No module named 'imports'
[2024-05-14T03:41:22.521+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:41:22.542+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.054 seconds
[2024-05-14T03:41:52.875+0000] {processor.py:161} INFO - Started process (PID=385) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:41:52.876+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:41:52.877+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:41:52.877+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:41:52.888+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:41:52.886+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 11, in <module>
    from tasks.main import check_if_update
  File "/opt/airflow/dags/tasks/main.py", line 1, in <module>
    from imports import *
ModuleNotFoundError: No module named 'imports'
[2024-05-14T03:41:52.889+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:41:52.905+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.043 seconds
[2024-05-14T03:42:23.234+0000] {processor.py:161} INFO - Started process (PID=393) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:42:23.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:42:23.237+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:42:23.236+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:42:23.247+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:42:23.245+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 11, in <module>
    from tasks.main import check_if_update
  File "/opt/airflow/dags/tasks/main.py", line 1, in <module>
    from imports import *
ModuleNotFoundError: No module named 'imports'
[2024-05-14T03:42:23.248+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:42:23.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.046 seconds
[2024-05-14T03:42:53.583+0000] {processor.py:161} INFO - Started process (PID=401) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:42:53.585+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:42:53.586+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:42:53.586+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:42:53.597+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:42:53.595+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 11, in <module>
    from tasks.main import check_if_update
  File "/opt/airflow/dags/tasks/main.py", line 1, in <module>
    from imports import *
ModuleNotFoundError: No module named 'imports'
[2024-05-14T03:42:53.598+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:42:53.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.044 seconds
[2024-05-14T03:43:24.078+0000] {processor.py:161} INFO - Started process (PID=409) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:43:24.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:43:24.081+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:43:24.080+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:43:24.092+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:43:24.090+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 11, in <module>
    from tasks.main import check_if_update
  File "/opt/airflow/dags/tasks/main.py", line 1, in <module>
    from imports import *
ModuleNotFoundError: No module named 'imports'
[2024-05-14T03:43:24.093+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:43:24.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.043 seconds
[2024-05-14T03:43:54.386+0000] {processor.py:161} INFO - Started process (PID=416) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:43:54.388+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:43:54.389+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:43:54.389+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:43:54.401+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:43:54.399+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 11, in <module>
    from tasks.main import check_if_update
  File "/opt/airflow/dags/tasks/main.py", line 1, in <module>
    from imports import *
ModuleNotFoundError: No module named 'imports'
[2024-05-14T03:43:54.402+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:43:54.420+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.046 seconds
[2024-05-14T03:44:24.768+0000] {processor.py:161} INFO - Started process (PID=424) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:44:24.769+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:44:24.771+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:44:24.770+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:44:24.781+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:44:24.779+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 11, in <module>
    from tasks.main import check_if_update
  File "/opt/airflow/dags/tasks/main.py", line 1, in <module>
    from imports import *
ModuleNotFoundError: No module named 'imports'
[2024-05-14T03:44:24.782+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:44:24.798+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.040 seconds
[2024-05-14T03:44:55.204+0000] {processor.py:161} INFO - Started process (PID=437) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:44:55.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:44:55.212+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:44:55.212+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:44:55.227+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:44:55.225+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 11, in <module>
    from tasks.main import check_if_update
  File "/opt/airflow/dags/tasks/main.py", line 1, in <module>
    from imports import *
ModuleNotFoundError: No module named 'imports'
[2024-05-14T03:44:55.227+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:44:55.251+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.064 seconds
[2024-05-14T03:45:25.519+0000] {processor.py:161} INFO - Started process (PID=445) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:45:25.520+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:45:25.522+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:45:25.522+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:45:25.530+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:45:25.528+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 11, in <module>
    from tasks.main import check_if_update
  File "/opt/airflow/dags/tasks/main.py", line 1, in <module>
    from imports import *
ModuleNotFoundError: No module named 'imports'
[2024-05-14T03:45:25.531+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:45:25.547+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.035 seconds
[2024-05-14T03:45:55.870+0000] {processor.py:161} INFO - Started process (PID=453) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:45:55.872+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:45:55.873+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:45:55.873+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:45:55.886+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:45:55.884+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16, in <module>
    from tasks.imports import *
  File "/opt/airflow/dags/tasks/imports.py", line 1, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:45:55.886+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:45:55.904+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.044 seconds
[2024-05-14T03:46:26.258+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:46:26.259+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:46:26.261+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:46:26.260+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:46:26.287+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:46:26.285+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16, in <module>
    from tasks.imports import *
  File "/opt/airflow/dags/tasks/imports.py", line 1, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:46:26.288+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:46:26.304+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.056 seconds
[2024-05-14T03:46:56.581+0000] {processor.py:161} INFO - Started process (PID=469) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:46:56.583+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:46:56.585+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:46:56.584+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:46:56.598+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:46:56.596+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16, in <module>
    from tasks.imports import *
  File "/opt/airflow/dags/tasks/imports.py", line 1, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:46:56.599+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:46:56.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.045 seconds
[2024-05-14T03:47:26.950+0000] {processor.py:161} INFO - Started process (PID=477) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:47:26.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:47:26.953+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:47:26.952+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:47:26.968+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:47:26.966+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16, in <module>
    from tasks.imports import *
  File "/opt/airflow/dags/tasks/imports.py", line 1, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:47:26.969+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:47:26.987+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.049 seconds
[2024-05-14T03:47:57.253+0000] {processor.py:161} INFO - Started process (PID=485) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:47:57.255+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:47:57.257+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:47:57.256+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:47:57.270+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:47:57.268+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16, in <module>
    from tasks.imports import *
  File "/opt/airflow/dags/tasks/imports.py", line 1, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:47:57.271+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:47:57.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.043 seconds
[2024-05-14T03:48:27.560+0000] {processor.py:161} INFO - Started process (PID=493) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:48:27.561+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:48:27.562+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:48:27.562+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:48:27.572+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:48:27.571+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16, in <module>
    from tasks.imports import *
  File "/opt/airflow/dags/tasks/imports.py", line 1, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:48:27.573+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:48:27.586+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.034 seconds
[2024-05-14T03:48:57.858+0000] {processor.py:161} INFO - Started process (PID=501) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:48:57.860+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:48:57.861+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:48:57.861+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:48:57.875+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:48:57.873+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16, in <module>
    from tasks.imports import *
  File "/opt/airflow/dags/tasks/imports.py", line 1, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:48:57.877+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:48:57.895+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.049 seconds
[2024-05-14T03:49:28.238+0000] {processor.py:161} INFO - Started process (PID=509) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:49:28.239+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:49:28.240+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:49:28.239+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:49:28.247+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:49:28.246+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16, in <module>
    from tasks.imports import *
  File "/opt/airflow/dags/tasks/imports.py", line 1, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:49:28.248+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:49:28.260+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.027 seconds
[2024-05-14T03:49:58.518+0000] {processor.py:161} INFO - Started process (PID=516) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:49:58.519+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:49:58.519+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:49:58.519+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:49:58.527+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:49:58.526+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16, in <module>
    from tasks.imports import *
  File "/opt/airflow/dags/tasks/imports.py", line 1, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:49:58.527+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:49:58.538+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.023 seconds
[2024-05-14T03:50:28.838+0000] {processor.py:161} INFO - Started process (PID=524) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:50:28.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:50:28.841+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:50:28.840+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:50:28.851+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:50:28.848+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16, in <module>
    from tasks.imports import *
  File "/opt/airflow/dags/tasks/imports.py", line 1, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:50:28.852+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:50:28.869+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.038 seconds
[2024-05-14T03:50:59.121+0000] {processor.py:161} INFO - Started process (PID=531) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:50:59.122+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:50:59.124+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:50:59.124+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:50:59.140+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:50:59.137+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16, in <module>
    from tasks.imports import *
  File "/opt/airflow/dags/tasks/imports.py", line 1, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:50:59.141+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:50:59.160+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.050 seconds
[2024-05-14T03:51:29.469+0000] {processor.py:161} INFO - Started process (PID=539) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:51:29.473+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:51:29.474+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:51:29.474+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:51:29.487+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:51:29.485+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16, in <module>
    from tasks.imports import *
  File "/opt/airflow/dags/tasks/imports.py", line 1, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:51:29.488+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:51:29.506+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.047 seconds
[2024-05-14T03:51:59.851+0000] {processor.py:161} INFO - Started process (PID=547) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:51:59.852+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:51:59.854+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:51:59.853+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:51:59.864+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:51:59.863+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16, in <module>
    from tasks.imports import *
  File "/opt/airflow/dags/tasks/imports.py", line 1, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:51:59.865+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:51:59.881+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.041 seconds
[2024-05-14T03:52:30.232+0000] {processor.py:161} INFO - Started process (PID=555) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:52:30.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:52:30.236+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:52:30.235+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:52:30.254+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:52:30.252+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16, in <module>
    from tasks.imports import *
  File "/opt/airflow/dags/tasks/imports.py", line 1, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:52:30.255+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:52:30.272+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.054 seconds
[2024-05-14T03:53:00.583+0000] {processor.py:161} INFO - Started process (PID=563) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:53:00.585+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:53:00.587+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:53:00.586+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:53:00.599+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:53:00.597+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16, in <module>
    from tasks.imports import *
  File "/opt/airflow/dags/tasks/imports.py", line 1, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:53:00.600+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:53:00.619+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.053 seconds
[2024-05-14T03:53:30.915+0000] {processor.py:161} INFO - Started process (PID=571) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:53:30.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:53:30.919+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:53:30.918+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:53:30.930+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:53:30.928+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16, in <module>
    from tasks.imports import *
  File "/opt/airflow/dags/tasks/imports.py", line 1, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:53:30.931+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:53:30.944+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.037 seconds
[2024-05-14T03:54:01.279+0000] {processor.py:161} INFO - Started process (PID=579) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:54:01.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:54:01.280+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:54:01.280+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:54:01.285+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:54:01.284+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 16, in <module>
    from tasks.imports import *
  File "/opt/airflow/dags/tasks/imports.py", line 1, in <module>
    from crawler104 import Crawler104
ModuleNotFoundError: No module named 'crawler104'
[2024-05-14T03:54:01.286+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:54:01.297+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.022 seconds
[2024-05-14T03:54:08.357+0000] {processor.py:161} INFO - Started process (PID=581) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:54:08.359+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:54:08.359+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:54:08.359+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:54:09.309+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:54:09.308+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T03:54:09.310+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:54:09.322+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.970 seconds
[2024-05-14T03:54:39.716+0000] {processor.py:161} INFO - Started process (PID=591) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:54:39.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:54:39.719+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:54:39.719+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:54:40.075+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:54:40.073+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T03:54:40.076+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:54:40.085+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.381 seconds
[2024-05-14T03:55:10.446+0000] {processor.py:161} INFO - Started process (PID=601) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:55:10.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:55:10.449+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:55:10.449+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:55:10.830+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:55:10.829+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T03:55:10.831+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:55:10.842+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.407 seconds
[2024-05-14T03:55:41.163+0000] {processor.py:161} INFO - Started process (PID=611) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:55:41.165+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:55:41.167+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:55:41.166+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:55:41.485+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:55:41.483+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T03:55:41.485+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:55:41.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.346 seconds
[2024-05-14T03:56:11.762+0000] {processor.py:161} INFO - Started process (PID=621) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:56:11.764+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:56:11.765+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:56:11.765+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:56:12.201+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:56:12.199+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T03:56:12.202+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:56:12.213+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.463 seconds
[2024-05-14T03:56:42.489+0000] {processor.py:161} INFO - Started process (PID=630) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:56:42.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:56:42.494+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:56:42.493+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:56:42.747+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:56:42.746+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T03:56:42.748+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:56:42.757+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.279 seconds
[2024-05-14T03:57:13.036+0000] {processor.py:161} INFO - Started process (PID=640) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:57:13.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:57:13.039+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:57:13.039+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:57:13.410+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:57:13.408+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T03:57:13.410+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:57:13.421+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.394 seconds
[2024-05-14T03:57:43.710+0000] {processor.py:161} INFO - Started process (PID=650) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:57:43.711+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:57:43.713+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:57:43.712+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:57:44.058+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:57:44.056+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T03:57:44.059+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:57:44.088+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.388 seconds
[2024-05-14T03:58:14.403+0000] {processor.py:161} INFO - Started process (PID=660) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:58:14.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:58:14.408+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:58:14.407+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:58:14.689+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:58:14.687+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T03:58:14.689+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:58:14.697+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.306 seconds
[2024-05-14T03:58:44.984+0000] {processor.py:161} INFO - Started process (PID=670) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:58:44.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:58:44.989+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:58:44.989+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:58:45.337+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:58:45.336+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T03:58:45.338+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:58:45.347+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.375 seconds
[2024-05-14T03:59:15.705+0000] {processor.py:161} INFO - Started process (PID=680) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:59:15.707+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:59:15.708+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:59:15.708+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:59:15.979+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:59:15.977+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T03:59:15.979+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:59:15.988+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.294 seconds
[2024-05-14T03:59:46.264+0000] {processor.py:161} INFO - Started process (PID=690) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:59:46.266+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T03:59:46.268+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:59:46.267+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:59:46.566+0000] {logging_mixin.py:188} INFO - [2024-05-14T03:59:46.565+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T03:59:46.567+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T03:59:46.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.321 seconds
[2024-05-14T04:00:16.855+0000] {processor.py:161} INFO - Started process (PID=700) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:00:16.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:00:16.859+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:00:16.859+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:00:17.257+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:00:17.253+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:00:17.260+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:00:17.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.450 seconds
[2024-05-14T04:00:47.616+0000] {processor.py:161} INFO - Started process (PID=710) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:00:47.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:00:47.621+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:00:47.620+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:00:47.909+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:00:47.908+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:00:47.910+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:00:47.921+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.316 seconds
[2024-05-14T04:01:18.373+0000] {processor.py:161} INFO - Started process (PID=720) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:01:18.375+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:01:18.376+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:01:18.376+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:01:18.764+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:01:18.763+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:01:18.765+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:01:18.778+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.417 seconds
[2024-05-14T04:01:49.126+0000] {processor.py:161} INFO - Started process (PID=729) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:01:49.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:01:49.131+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:01:49.130+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:01:49.428+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:01:49.427+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:01:49.429+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:01:49.437+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.325 seconds
[2024-05-14T04:02:19.720+0000] {processor.py:161} INFO - Started process (PID=739) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:02:19.722+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:02:19.724+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:02:19.723+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:02:20.154+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:02:20.153+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:02:20.155+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:02:20.168+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.463 seconds
[2024-05-14T04:02:50.463+0000] {processor.py:161} INFO - Started process (PID=749) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:02:50.466+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:02:50.468+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:02:50.467+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:02:50.790+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:02:50.788+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:02:50.790+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:02:50.799+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.351 seconds
[2024-05-14T04:03:21.094+0000] {processor.py:161} INFO - Started process (PID=759) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:03:21.097+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:03:21.098+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:03:21.098+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:03:21.419+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:03:21.418+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:03:21.420+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:03:21.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.348 seconds
[2024-05-14T04:03:51.729+0000] {processor.py:161} INFO - Started process (PID=769) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:03:51.731+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:03:51.733+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:03:51.732+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:03:52.121+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:03:52.120+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:03:52.122+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:03:52.144+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.427 seconds
[2024-05-14T04:04:22.465+0000] {processor.py:161} INFO - Started process (PID=779) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:04:22.469+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:04:22.471+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:04:22.471+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:04:22.867+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:04:22.865+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:04:22.868+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:04:22.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.435 seconds
[2024-05-14T04:04:53.190+0000] {processor.py:161} INFO - Started process (PID=789) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:04:53.193+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:04:53.194+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:04:53.194+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:04:53.564+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:04:53.562+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:04:53.565+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:04:53.578+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.399 seconds
[2024-05-14T04:05:23.893+0000] {processor.py:161} INFO - Started process (PID=798) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:05:23.896+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:05:23.897+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:05:23.897+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:05:24.240+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:05:24.239+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:05:24.241+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:05:24.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.370 seconds
[2024-05-14T04:05:54.564+0000] {processor.py:161} INFO - Started process (PID=808) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:05:54.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:05:54.568+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:05:54.567+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:05:54.840+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:05:54.839+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:05:54.841+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:05:54.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.298 seconds
[2024-05-14T04:06:25.148+0000] {processor.py:161} INFO - Started process (PID=819) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:06:25.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:06:25.152+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:06:25.151+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:06:25.486+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:06:25.484+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:06:25.486+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:06:25.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.360 seconds
[2024-05-14T04:06:55.798+0000] {processor.py:161} INFO - Started process (PID=828) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:06:55.801+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:06:55.802+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:06:55.801+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:06:56.173+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:06:56.171+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:06:56.173+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:06:56.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.397 seconds
[2024-05-14T04:07:26.503+0000] {processor.py:161} INFO - Started process (PID=839) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:07:26.507+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:07:26.508+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:07:26.508+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:07:26.868+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:07:26.866+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:07:26.868+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:07:26.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.390 seconds
[2024-05-14T04:07:57.140+0000] {processor.py:161} INFO - Started process (PID=849) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:07:57.144+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:07:57.145+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:07:57.145+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:07:57.509+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:07:57.507+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:07:57.509+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:07:57.520+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.391 seconds
[2024-05-14T04:08:27.806+0000] {processor.py:161} INFO - Started process (PID=859) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:08:27.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:08:27.811+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:08:27.810+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:08:28.108+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:08:28.107+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:08:28.109+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:08:28.119+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.327 seconds
[2024-05-14T04:08:58.447+0000] {processor.py:161} INFO - Started process (PID=869) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:08:58.450+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:08:58.452+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:08:58.451+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:08:58.841+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:08:58.839+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:08:58.841+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:08:58.850+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.414 seconds
[2024-05-14T04:09:29.138+0000] {processor.py:161} INFO - Started process (PID=884) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:09:29.139+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:09:29.140+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:09:29.140+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:09:29.494+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:09:29.493+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:09:29.495+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:09:29.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.374 seconds
[2024-05-14T04:09:59.793+0000] {processor.py:161} INFO - Started process (PID=894) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:09:59.795+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:09:59.796+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:09:59.796+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:10:00.296+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:10:00.288+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:10:00.299+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:10:00.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.535 seconds
[2024-05-14T04:10:30.623+0000] {processor.py:161} INFO - Started process (PID=904) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:10:30.626+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:10:30.628+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:10:30.628+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:10:31.085+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:10:31.083+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:10:31.086+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:10:31.106+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.489 seconds
[2024-05-14T04:11:01.412+0000] {processor.py:161} INFO - Started process (PID=915) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:11:01.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:11:01.417+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:11:01.416+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:11:01.905+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:11:01.904+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:11:01.906+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:11:01.920+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.533 seconds
[2024-05-14T04:11:32.238+0000] {processor.py:161} INFO - Started process (PID=925) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:11:32.241+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:11:32.244+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:11:32.243+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:11:32.660+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:11:32.658+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:11:32.660+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:11:32.673+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.452 seconds
[2024-05-14T04:12:03.018+0000] {processor.py:161} INFO - Started process (PID=935) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:12:03.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:12:03.022+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:12:03.021+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:12:03.461+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:12:03.459+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:12:03.462+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:12:03.477+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.470 seconds
[2024-05-14T04:12:33.759+0000] {processor.py:161} INFO - Started process (PID=945) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:12:33.762+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:12:33.763+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:12:33.763+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:12:34.085+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:12:34.084+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:12:34.086+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:12:34.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.351 seconds
[2024-05-14T04:13:04.411+0000] {processor.py:161} INFO - Started process (PID=955) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:13:04.414+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:13:04.415+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:13:04.415+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:13:04.672+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:13:04.670+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:13:04.672+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:13:04.681+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.282 seconds
[2024-05-14T04:13:34.970+0000] {processor.py:161} INFO - Started process (PID=965) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:13:34.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:13:34.975+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:13:34.974+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:13:35.388+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:13:35.386+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:13:35.388+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:13:35.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.442 seconds
[2024-05-14T04:14:05.690+0000] {processor.py:161} INFO - Started process (PID=975) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:14:05.691+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:14:05.693+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:14:05.692+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:14:06.101+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:14:06.100+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:14:06.102+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:14:06.134+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.467 seconds
[2024-05-14T04:14:36.486+0000] {processor.py:161} INFO - Started process (PID=985) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:14:36.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:14:36.492+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:14:36.491+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:14:36.845+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:14:36.844+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:14:36.846+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:14:36.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.383 seconds
[2024-05-14T04:15:07.169+0000] {processor.py:161} INFO - Started process (PID=995) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:15:07.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:15:07.172+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:15:07.171+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:15:07.410+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:15:07.408+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:15:07.410+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:15:07.418+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.257 seconds
[2024-05-14T04:15:37.500+0000] {processor.py:161} INFO - Started process (PID=1005) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:15:37.503+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:15:37.505+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:15:37.504+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:15:37.985+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:15:37.984+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:15:37.986+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:15:37.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.507 seconds
[2024-05-14T04:16:08.343+0000] {processor.py:161} INFO - Started process (PID=1015) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:16:08.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:16:08.349+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:16:08.348+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:16:08.741+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:16:08.739+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:16:08.742+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:16:08.752+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.440 seconds
[2024-05-14T04:16:39.160+0000] {processor.py:161} INFO - Started process (PID=1024) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:16:39.162+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:16:39.164+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:16:39.163+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:16:39.549+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:16:39.548+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:16:39.550+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:16:39.561+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.417 seconds
[2024-05-14T04:17:09.904+0000] {processor.py:161} INFO - Started process (PID=1034) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:17:09.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:17:09.908+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:17:09.907+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:17:10.315+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:17:10.313+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:17:10.315+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:17:10.327+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.439 seconds
[2024-05-14T04:17:40.638+0000] {processor.py:161} INFO - Started process (PID=1044) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:17:40.640+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:17:40.644+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:17:40.643+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:17:41.052+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:17:41.051+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:17:41.053+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:17:41.065+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.441 seconds
[2024-05-14T04:18:11.445+0000] {processor.py:161} INFO - Started process (PID=1054) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:18:11.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:18:11.450+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:18:11.449+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:18:11.769+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:18:11.767+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:18:11.769+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:18:11.779+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.345 seconds
[2024-05-14T04:18:42.219+0000] {processor.py:161} INFO - Started process (PID=1064) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:18:42.222+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:18:42.225+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:18:42.224+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:18:42.637+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:18:42.635+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:18:42.637+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:18:42.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.446 seconds
[2024-05-14T04:19:12.942+0000] {processor.py:161} INFO - Started process (PID=1074) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:19:12.945+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:19:12.947+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:19:12.946+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:19:13.309+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:19:13.307+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:19:13.309+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:19:13.321+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.390 seconds
[2024-05-14T04:19:43.576+0000] {processor.py:161} INFO - Started process (PID=1084) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:19:43.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:19:43.580+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:19:43.579+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:19:43.919+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:19:43.917+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:19:43.920+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:19:43.934+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.371 seconds
[2024-05-14T04:20:23.649+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:20:23.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:20:23.654+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:20:23.653+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:20:24.291+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:20:24.287+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:20:24.292+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:20:24.320+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.678 seconds
[2024-05-14T04:20:54.650+0000] {processor.py:161} INFO - Started process (PID=39) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:20:54.652+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:20:54.669+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:20:54.665+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:20:55.080+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:20:55.078+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:20:55.081+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:20:55.093+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.454 seconds
[2024-05-14T04:21:25.324+0000] {processor.py:161} INFO - Started process (PID=49) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:21:25.325+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:21:25.329+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:21:25.328+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:21:25.718+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:21:25.716+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:21:25.719+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:21:25.728+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.415 seconds
[2024-05-14T04:21:55.998+0000] {processor.py:161} INFO - Started process (PID=59) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:21:56.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:21:56.002+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:21:56.002+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:21:56.336+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:21:56.335+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:21:56.337+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:21:56.347+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.355 seconds
[2024-05-14T04:22:26.433+0000] {processor.py:161} INFO - Started process (PID=68) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:22:26.435+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:22:26.438+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:22:26.437+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:22:26.773+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:22:26.772+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:22:26.775+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:22:26.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.364 seconds
[2024-05-14T04:22:57.351+0000] {processor.py:161} INFO - Started process (PID=78) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:22:57.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:22:57.355+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:22:57.355+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:22:57.657+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:22:57.656+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:22:57.658+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:22:57.666+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.323 seconds
[2024-05-14T04:23:27.972+0000] {processor.py:161} INFO - Started process (PID=88) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:23:27.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:23:27.979+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:23:27.978+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:23:28.295+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:23:28.293+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:23:28.295+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:23:28.303+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.343 seconds
[2024-05-14T04:23:58.635+0000] {processor.py:161} INFO - Started process (PID=98) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:23:58.637+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:23:58.641+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:23:58.640+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:23:58.962+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:23:58.961+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:23:58.963+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:23:58.971+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.348 seconds
[2024-05-14T04:24:29.240+0000] {processor.py:161} INFO - Started process (PID=108) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:24:29.241+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:24:29.242+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:24:29.241+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:24:29.639+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:24:29.638+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:24:29.640+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:24:29.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.415 seconds
[2024-05-14T04:25:00.051+0000] {processor.py:161} INFO - Started process (PID=118) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:25:00.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:25:00.068+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:25:00.067+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:25:00.728+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:25:00.722+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:25:00.732+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:25:00.798+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.760 seconds
[2024-05-14T04:25:31.190+0000] {processor.py:161} INFO - Started process (PID=128) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:25:31.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:25:31.195+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:25:31.194+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:25:31.600+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:25:31.598+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:25:31.600+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:25:31.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.436 seconds
[2024-05-14T04:26:01.903+0000] {processor.py:161} INFO - Started process (PID=138) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:26:01.908+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:26:01.912+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:26:01.911+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:26:02.352+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:26:02.351+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:26:02.353+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:26:02.364+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.475 seconds
[2024-05-14T04:26:32.696+0000] {processor.py:161} INFO - Started process (PID=147) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:26:32.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:26:32.702+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:26:32.702+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:26:33.480+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:26:33.478+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:26:33.481+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:26:33.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.810 seconds
[2024-05-14T04:27:03.562+0000] {processor.py:161} INFO - Started process (PID=157) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:27:03.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:27:03.567+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:27:03.567+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:27:04.044+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:27:04.035+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:27:04.045+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:27:04.079+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.525 seconds
[2024-05-14T04:27:34.345+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:27:34.347+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:27:34.351+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:27:34.350+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:27:34.768+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:27:34.766+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 5, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
[2024-05-14T04:27:34.768+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:27:34.779+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.445 seconds
[2024-05-14T04:28:27.416+0000] {processor.py:161} INFO - Started process (PID=30) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:28:27.436+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:28:27.440+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:28:27.439+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:28:29.664+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:28:29.657+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 8, in <module>
    from selenium import webdriver
ModuleNotFoundError: No module named 'selenium'
[2024-05-14T04:28:29.666+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:28:29.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 2.333 seconds
[2024-05-14T04:29:09.589+0000] {processor.py:161} INFO - Started process (PID=30) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:29:09.592+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:29:09.607+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:29:09.605+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:29:12.024+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:29:12.020+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 8, in <module>
    from selenium import webdriver
ModuleNotFoundError: No module named 'selenium'
[2024-05-14T04:29:12.025+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:29:12.085+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 2.512 seconds
[2024-05-14T04:29:42.528+0000] {processor.py:161} INFO - Started process (PID=46) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:29:42.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:29:42.543+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:29:42.542+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:29:43.716+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:29:43.714+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 8, in <module>
    from selenium import webdriver
ModuleNotFoundError: No module named 'selenium'
[2024-05-14T04:29:43.717+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:29:43.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 1.267 seconds
[2024-05-14T04:30:13.969+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:30:13.970+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:30:13.973+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:30:13.973+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:30:14.455+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:30:14.451+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 8, in <module>
    from selenium import webdriver
ModuleNotFoundError: No module named 'selenium'
[2024-05-14T04:30:14.455+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:30:14.479+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.516 seconds
[2024-05-14T04:31:56.493+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:31:56.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:31:56.498+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:31:56.498+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:31:57.436+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:31:57.434+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 8, in <module>
    from selenium import webdriver
ModuleNotFoundError: No module named 'selenium'
[2024-05-14T04:31:57.437+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:31:57.464+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.976 seconds
[2024-05-14T04:32:27.676+0000] {processor.py:161} INFO - Started process (PID=38) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:32:27.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:32:27.681+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:32:27.680+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:32:28.111+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:32:28.108+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 8, in <module>
    from selenium import webdriver
ModuleNotFoundError: No module named 'selenium'
[2024-05-14T04:32:28.112+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:32:28.132+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.462 seconds
[2024-05-14T04:32:58.594+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:32:58.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:32:58.603+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:32:58.602+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:32:59.254+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:32:59.251+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 8, in <module>
    from selenium import webdriver
ModuleNotFoundError: No module named 'selenium'
[2024-05-14T04:32:59.258+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:32:59.277+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.693 seconds
[2024-05-14T04:33:57.281+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:33:57.284+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:33:57.286+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:33:57.285+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:34:00.916+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:34:00.907+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T04:34:00.920+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:34:00.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 3.688 seconds
[2024-05-14T04:34:31.883+0000] {processor.py:161} INFO - Started process (PID=42) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:34:31.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:34:31.911+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:34:31.908+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:34:33.741+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:34:33.730+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T04:34:33.743+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:34:33.795+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 1.971 seconds
[2024-05-14T04:35:04.618+0000] {processor.py:161} INFO - Started process (PID=52) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:35:04.631+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:35:04.663+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:35:04.661+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:35:06.401+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:35:06.397+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T04:35:06.402+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:35:06.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 1.880 seconds
[2024-05-14T04:35:36.693+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:35:36.696+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:35:36.702+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:35:36.702+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:35:37.536+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:35:37.521+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T04:35:37.539+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:35:37.559+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.871 seconds
[2024-05-14T04:36:08.373+0000] {processor.py:161} INFO - Started process (PID=71) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:36:08.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:36:08.389+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:36:08.387+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:36:09.632+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:36:09.626+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T04:36:09.634+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:36:09.678+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 1.332 seconds
[2024-05-14T04:37:23.517+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:37:23.520+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T04:37:23.524+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:37:23.523+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:37:25.291+0000] {logging_mixin.py:188} INFO - [2024-05-14T04:37:25.289+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T04:37:25.291+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T04:37:25.307+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 1.804 seconds
[2024-05-14T05:19:24.598+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:19:24.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:19:24.604+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:19:24.604+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:19:25.211+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:19:25.210+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:19:25.212+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:19:25.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.641 seconds
[2024-05-14T05:19:55.972+0000] {processor.py:161} INFO - Started process (PID=50) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:19:55.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:19:55.980+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:19:55.979+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:19:56.487+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:19:56.484+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:19:56.487+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:19:56.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.548 seconds
[2024-05-14T05:20:26.742+0000] {processor.py:161} INFO - Started process (PID=59) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:20:26.744+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:20:26.750+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:20:26.749+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:20:27.309+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:20:27.306+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:20:27.310+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:20:27.435+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.701 seconds
[2024-05-14T05:20:57.926+0000] {processor.py:161} INFO - Started process (PID=68) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:20:57.929+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:20:57.941+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:20:57.940+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:20:59.362+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:20:59.359+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:20:59.362+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:20:59.381+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 1.489 seconds
[2024-05-14T05:21:29.721+0000] {processor.py:161} INFO - Started process (PID=78) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:21:29.725+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:21:29.740+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:21:29.738+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:21:30.971+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:21:30.966+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:21:30.973+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:21:31.007+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 1.314 seconds
[2024-05-14T05:22:01.051+0000] {processor.py:161} INFO - Started process (PID=88) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:22:01.052+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:22:01.054+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:22:01.054+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:22:01.446+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:22:01.444+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:22:01.446+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:22:01.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.410 seconds
[2024-05-14T05:23:05.431+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:23:05.436+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:23:05.447+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:23:05.446+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:23:08.189+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:23:08.179+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:23:08.202+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:23:08.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 3.004 seconds
[2024-05-14T05:23:39.172+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:23:39.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:23:39.205+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:23:39.198+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:23:43.886+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:23:43.876+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:23:43.887+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:23:43.938+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 4.834 seconds
[2024-05-14T05:24:14.698+0000] {processor.py:161} INFO - Started process (PID=57) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:24:14.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:24:14.714+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:24:14.712+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:24:16.102+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:24:16.100+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:24:16.102+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:24:16.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 1.449 seconds
[2024-05-14T05:24:46.351+0000] {processor.py:161} INFO - Started process (PID=67) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:24:46.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:24:46.357+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:24:46.357+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:24:47.192+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:24:47.189+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:24:47.193+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:24:47.211+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.868 seconds
[2024-05-14T05:25:17.442+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:25:17.452+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:25:17.459+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:25:17.458+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:25:18.014+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:25:18.011+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:25:18.015+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:25:18.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.602 seconds
[2024-05-14T05:25:48.519+0000] {processor.py:161} INFO - Started process (PID=86) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:25:48.531+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:25:48.556+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:25:48.550+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:25:54.450+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:25:54.404+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:25:54.458+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:25:54.735+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 6.334 seconds
[2024-05-14T05:26:25.234+0000] {processor.py:161} INFO - Started process (PID=96) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:26:25.238+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:26:25.250+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:26:25.248+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:26:26.646+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:26:26.644+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:26:26.647+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:26:26.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 1.507 seconds
[2024-05-14T05:26:57.099+0000] {processor.py:161} INFO - Started process (PID=106) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:26:57.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:26:57.107+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:26:57.105+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:26:57.939+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:26:57.938+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:26:57.940+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:26:58.207+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 1.123 seconds
[2024-05-14T05:27:28.353+0000] {processor.py:161} INFO - Started process (PID=116) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:27:28.357+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:27:28.363+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:27:28.362+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:27:30.127+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:27:30.109+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:27:30.133+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:27:30.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 1.860 seconds
[2024-05-14T05:28:00.891+0000] {processor.py:161} INFO - Started process (PID=126) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:28:00.897+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:28:00.909+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:28:00.904+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:28:01.927+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:28:01.921+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:28:01.931+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:28:01.968+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 1.149 seconds
[2024-05-14T05:28:32.384+0000] {processor.py:161} INFO - Started process (PID=136) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:28:32.386+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:28:32.389+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:28:32.389+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:28:32.776+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:28:32.775+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:28:32.777+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:28:32.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.415 seconds
[2024-05-14T05:29:03.073+0000] {processor.py:161} INFO - Started process (PID=146) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:29:03.074+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:29:03.077+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:29:03.076+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:29:03.407+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:29:03.405+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:29:03.407+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:29:03.416+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.353 seconds
[2024-05-14T05:29:33.682+0000] {processor.py:161} INFO - Started process (PID=156) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:29:33.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:29:33.685+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:29:33.684+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:29:33.993+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:29:33.992+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:29:33.994+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:29:34.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.324 seconds
[2024-05-14T05:30:04.313+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:30:04.314+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:30:04.317+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:30:04.316+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:30:04.336+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:30:04.332+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15
    import .threaded_async_job
           ^
SyntaxError: invalid syntax
[2024-05-14T05:30:04.337+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:30:04.353+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.046 seconds
[2024-05-14T05:30:34.581+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:30:34.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:30:34.588+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:30:34.587+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:30:34.600+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:30:34.598+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15
    import .threaded_async_job
           ^
SyntaxError: invalid syntax
[2024-05-14T05:30:34.602+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:30:34.618+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.042 seconds
[2024-05-14T05:31:04.907+0000] {processor.py:161} INFO - Started process (PID=182) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:31:04.908+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:31:04.910+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:31:04.909+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:31:04.918+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:31:04.917+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15
    import .threaded_async_job
           ^
SyntaxError: invalid syntax
[2024-05-14T05:31:04.918+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:31:04.931+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.029 seconds
[2024-05-14T05:31:35.256+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:31:35.257+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:31:35.261+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:31:35.260+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:31:35.771+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:31:35.770+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:31:35.772+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:31:35.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.539 seconds
[2024-05-14T05:32:06.057+0000] {processor.py:161} INFO - Started process (PID=198) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:32:06.059+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:32:06.063+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:32:06.062+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:32:06.388+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:32:06.386+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
  File "/opt/airflow/dags/tasks/crawler104.py", line 15, in <module>
    import threaded_async_job
ModuleNotFoundError: No module named 'threaded_async_job'
[2024-05-14T05:32:06.388+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:32:06.397+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.350 seconds
[2024-05-14T05:32:36.693+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:32:36.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:32:36.697+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:32:36.696+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:32:36.707+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:32:36.706+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from tasks.crawler104 import Crawler104
ModuleNotFoundError: No module named 'tasks.crawler104'
[2024-05-14T05:32:36.708+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:32:36.723+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.037 seconds
[2024-05-14T05:32:57.896+0000] {processor.py:161} INFO - Started process (PID=215) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:32:57.897+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:32:57.899+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:32:57.899+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:32:58.211+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:32:58.210+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 15, in <module>
    import threaded_async_job
  File "/opt/airflow/dags/threaded_async_job.py", line 3, in <module>
    import jobs104
ModuleNotFoundError: No module named 'jobs104'
[2024-05-14T05:32:58.211+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:32:58.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.331 seconds
[2024-05-14T05:33:28.626+0000] {processor.py:161} INFO - Started process (PID=225) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:33:28.628+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:33:28.632+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:33:28.631+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:33:29.084+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:33:29.082+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 15, in <module>
    import threaded_async_job
  File "/opt/airflow/dags/threaded_async_job.py", line 3, in <module>
    import jobs104
ModuleNotFoundError: No module named 'jobs104'
[2024-05-14T05:33:29.084+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:33:29.095+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.483 seconds
[2024-05-14T05:33:59.397+0000] {processor.py:161} INFO - Started process (PID=235) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:33:59.399+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:33:59.404+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:33:59.403+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:33:59.747+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:33:59.746+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 17, in <module>
    import xlsxwriter
ModuleNotFoundError: No module named 'xlsxwriter'
[2024-05-14T05:33:59.747+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:33:59.756+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.373 seconds
[2024-05-14T05:34:30.068+0000] {processor.py:161} INFO - Started process (PID=245) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:34:30.069+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:34:30.072+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:34:30.071+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:34:30.465+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:34:30.464+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 17, in <module>
    import xlsxwriter
ModuleNotFoundError: No module named 'xlsxwriter'
[2024-05-14T05:34:30.466+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:34:30.475+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.417 seconds
[2024-05-14T05:35:00.779+0000] {processor.py:161} INFO - Started process (PID=255) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:35:00.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:35:00.781+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:35:00.781+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:35:00.787+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:35:00.786+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 11, in <module>
    from tasks.main import check_if_update
ModuleNotFoundError: No module named 'tasks.main'
[2024-05-14T05:35:00.788+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:35:00.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.027 seconds
[2024-05-14T05:35:31.148+0000] {processor.py:161} INFO - Started process (PID=263) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:35:31.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:35:31.152+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:35:31.151+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:35:31.159+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:35:31.158+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 11, in <module>
    from tasks.main import check_if_update
ModuleNotFoundError: No module named 'tasks'
[2024-05-14T05:35:31.160+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:35:31.177+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.036 seconds
[2024-05-14T05:36:01.496+0000] {processor.py:161} INFO - Started process (PID=271) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:36:01.498+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:36:01.500+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:36:01.500+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:36:01.509+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:36:01.507+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 11, in <module>
    from tasks.main import check_if_update
ModuleNotFoundError: No module named 'tasks'
[2024-05-14T05:36:01.510+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:36:01.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.041 seconds
[2024-05-14T05:36:03.560+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:36:03.561+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:36:03.562+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:36:03.562+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:36:03.860+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:36:03.859+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 17, in <module>
    import xlsxwriter
ModuleNotFoundError: No module named 'xlsxwriter'
[2024-05-14T05:36:03.860+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:36:03.868+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.313 seconds
[2024-05-14T05:36:34.230+0000] {processor.py:161} INFO - Started process (PID=283) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:36:34.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:36:34.236+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:36:34.235+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:36:34.561+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:36:34.560+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 17, in <module>
    import xlsxwriter
ModuleNotFoundError: No module named 'xlsxwriter'
[2024-05-14T05:36:34.562+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:36:34.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.350 seconds
[2024-05-14T05:37:04.918+0000] {processor.py:161} INFO - Started process (PID=293) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:37:04.920+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:37:04.922+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:37:04.922+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:37:05.232+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:37:05.231+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 17, in <module>
    import xlsxwriter
ModuleNotFoundError: No module named 'xlsxwriter'
[2024-05-14T05:37:05.232+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:37:05.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.330 seconds
[2024-05-14T05:37:35.598+0000] {processor.py:161} INFO - Started process (PID=302) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:37:35.600+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:37:35.603+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:37:35.602+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:37:35.921+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:37:35.920+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 17, in <module>
    import xlsxwriter
ModuleNotFoundError: No module named 'xlsxwriter'
[2024-05-14T05:37:35.922+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:37:35.930+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.340 seconds
[2024-05-14T05:38:06.256+0000] {processor.py:161} INFO - Started process (PID=312) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:38:06.257+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:38:06.260+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:38:06.259+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:38:06.586+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:38:06.585+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 17, in <module>
    import xlsxwriter
ModuleNotFoundError: No module named 'xlsxwriter'
[2024-05-14T05:38:06.587+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:38:06.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.347 seconds
[2024-05-14T05:38:37.000+0000] {processor.py:161} INFO - Started process (PID=322) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:38:37.002+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:38:37.006+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:38:37.005+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:38:37.428+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:38:37.426+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 17, in <module>
    import xlsxwriter
ModuleNotFoundError: No module named 'xlsxwriter'
[2024-05-14T05:38:37.428+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:38:37.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.450 seconds
[2024-05-14T05:39:07.790+0000] {processor.py:161} INFO - Started process (PID=332) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:39:07.791+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:39:07.792+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:39:07.792+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:39:08.095+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:39:08.094+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 17, in <module>
    import xlsxwriter
ModuleNotFoundError: No module named 'xlsxwriter'
[2024-05-14T05:39:08.095+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:39:08.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.319 seconds
[2024-05-14T05:39:38.455+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:39:38.458+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:39:38.461+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:39:38.460+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:39:38.794+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:39:38.793+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 17, in <module>
    import xlsxwriter
ModuleNotFoundError: No module named 'xlsxwriter'
[2024-05-14T05:39:38.794+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:39:38.803+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.358 seconds
[2024-05-14T05:40:09.138+0000] {processor.py:161} INFO - Started process (PID=351) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:40:09.139+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:40:09.142+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:40:09.141+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:40:09.484+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:40:09.483+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 17, in <module>
    import xlsxwriter
ModuleNotFoundError: No module named 'xlsxwriter'
[2024-05-14T05:40:09.484+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:40:09.494+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.364 seconds
[2024-05-14T05:40:39.831+0000] {processor.py:161} INFO - Started process (PID=361) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:40:39.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:40:39.835+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:40:39.835+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:40:40.149+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:40:40.147+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 17, in <module>
    import xlsxwriter
ModuleNotFoundError: No module named 'xlsxwriter'
[2024-05-14T05:40:40.149+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:40:40.160+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.336 seconds
[2024-05-14T05:41:19.067+0000] {processor.py:161} INFO - Started process (PID=371) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:41:19.069+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:41:19.072+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:41:19.072+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:41:19.587+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:41:19.585+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 17, in <module>
    import xlsxwriter
ModuleNotFoundError: No module named 'xlsxwriter'
[2024-05-14T05:41:19.587+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:41:19.600+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.545 seconds
[2024-05-14T05:41:49.910+0000] {processor.py:161} INFO - Started process (PID=381) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:41:49.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:41:49.915+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:41:49.915+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:41:50.569+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:41:50.567+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 17, in <module>
    import xlsxwriter
ModuleNotFoundError: No module named 'xlsxwriter'
[2024-05-14T05:41:50.570+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:41:50.585+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.682 seconds
[2024-05-14T05:42:20.856+0000] {processor.py:161} INFO - Started process (PID=391) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:42:20.857+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:42:20.860+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:42:20.859+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:42:21.400+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:42:21.399+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 17, in <module>
    import xlsxwriter
ModuleNotFoundError: No module named 'xlsxwriter'
[2024-05-14T05:42:21.400+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:42:21.412+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.566 seconds
[2024-05-14T05:42:51.782+0000] {processor.py:161} INFO - Started process (PID=401) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:42:51.785+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:42:51.789+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:42:51.788+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:42:52.251+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:42:52.249+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 17, in <module>
    import xlsxwriter
ModuleNotFoundError: No module named 'xlsxwriter'
[2024-05-14T05:42:52.251+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:42:52.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.494 seconds
[2024-05-14T05:43:22.495+0000] {processor.py:161} INFO - Started process (PID=411) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:43:22.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:43:22.504+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:43:22.503+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:43:23.001+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:43:22.999+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 17, in <module>
    import xlsxwriter
ModuleNotFoundError: No module named 'xlsxwriter'
[2024-05-14T05:43:23.002+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:43:23.016+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.538 seconds
[2024-05-14T05:43:53.309+0000] {processor.py:161} INFO - Started process (PID=421) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:43:53.312+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:43:53.315+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:43:53.315+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:43:53.795+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:43:53.794+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 17, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 17, in <module>
    import xlsxwriter
ModuleNotFoundError: No module named 'xlsxwriter'
[2024-05-14T05:43:53.796+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:43:53.807+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.515 seconds
[2024-05-14T05:45:11.542+0000] {processor.py:161} INFO - Started process (PID=30) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:45:11.545+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:45:11.549+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:45:11.548+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:45:14.588+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:45:15.133+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:45:15.132+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T05:45:15.164+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:45:15.164+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T05:45:15.540+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:45:15.537+0000] {dagbag.py:654} ERROR - Failed to write serialized DAG: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 642, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 158, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(data_pipeline_jobs104) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'data_pipeline_jobs104', 'fileloc': '/opt/airflow/dags/data_pipeline_jobs104.py', 'fileloc_hash': 67140776701959873, 'data': '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (3530 characters truncated) ... onOperator", "_task_module": "airflow.operators.python", "_is_empty": false, "op_args": [], "op_kwargs": {}}], "dag_dependencies": [], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2024, 5, 14, 5, 45, 14, 803860, tzinfo=Timezone('UTC')), 'dag_hash': '7d9c1860cce936f7c19513af9ecdf61f', 'processor_subdir': '/opt/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-05-14T05:45:15.542+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:45:15.542+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T05:45:15.543+0000] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 859, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 895, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 664, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 314, in iter
    return fut.result()
           ^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 680, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3108, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(data_pipeline_jobs104) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'data_pipeline_jobs104', 'fileloc': '/opt/airflow/dags/data_pipeline_jobs104.py', 'fileloc_hash': 67140776701959873, 'data': '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (3530 characters truncated) ... onOperator", "_task_module": "airflow.operators.python", "_is_empty": false, "op_args": [], "op_kwargs": {}}], "dag_dependencies": [], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2024, 5, 14, 5, 45, 14, 803860, tzinfo=Timezone('UTC')), 'dag_hash': '7d9c1860cce936f7c19513af9ecdf61f', 'processor_subdir': '/opt/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-05-14T05:45:45.985+0000] {processor.py:161} INFO - Started process (PID=42) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:45:45.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:45:45.988+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:45:45.988+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:45:46.431+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:45:46.500+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:45:46.500+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T05:45:46.506+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:45:46.506+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T05:45:46.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.537 seconds
[2024-05-14T05:46:16.792+0000] {processor.py:161} INFO - Started process (PID=52) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:46:16.793+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:46:16.795+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:46:16.795+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:46:17.241+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:46:17.246+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:46:17.246+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T05:46:17.253+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:46:17.253+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T05:46:17.260+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.473 seconds
[2024-05-14T05:46:47.418+0000] {processor.py:161} INFO - Started process (PID=60) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:46:47.420+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:46:47.423+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:46:47.423+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:46:47.886+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:46:47.997+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:46:47.997+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T05:46:48.007+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:46:48.007+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T05:46:48.015+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.607 seconds
[2024-05-14T05:47:18.314+0000] {processor.py:161} INFO - Started process (PID=70) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:47:18.316+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:47:18.320+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:47:18.319+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:47:18.754+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:47:18.768+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:47:18.768+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T05:47:18.774+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:47:18.774+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T05:47:18.783+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.478 seconds
[2024-05-14T05:47:49.177+0000] {processor.py:161} INFO - Started process (PID=80) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:47:49.178+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:47:49.181+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:47:49.181+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:47:49.693+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:47:49.747+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:47:49.747+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T05:47:49.751+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:47:49.751+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T05:47:49.759+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.591 seconds
[2024-05-14T05:48:20.044+0000] {processor.py:161} INFO - Started process (PID=96) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:48:20.046+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:48:20.049+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:48:20.048+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:48:20.392+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:48:20.404+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:48:20.403+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T05:48:20.408+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:48:20.408+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T05:48:20.415+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.384 seconds
[2024-05-14T05:48:50.835+0000] {processor.py:161} INFO - Started process (PID=106) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:48:50.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:48:50.841+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:48:50.840+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:48:51.280+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:48:51.333+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:48:51.333+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T05:48:51.338+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:48:51.338+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T05:48:51.346+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.520 seconds
[2024-05-14T05:57:06.990+0000] {processor.py:161} INFO - Started process (PID=116) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:57:06.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:57:06.993+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:57:06.993+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:57:07.394+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:57:07.408+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:57:07.408+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T05:57:07.413+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:57:07.413+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T05:57:07.422+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.438 seconds
[2024-05-14T05:57:37.769+0000] {processor.py:161} INFO - Started process (PID=126) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:57:37.771+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:57:37.773+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:57:37.773+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:57:38.115+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:57:38.159+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:57:38.159+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T05:57:38.163+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:57:38.163+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T05:57:38.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.410 seconds
[2024-05-14T05:58:08.408+0000] {processor.py:161} INFO - Started process (PID=136) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:58:08.409+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:58:08.411+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:58:08.411+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:58:08.722+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:58:08.733+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:58:08.732+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T05:58:08.737+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:58:08.737+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T05:58:08.745+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.343 seconds
[2024-05-14T05:58:39.035+0000] {processor.py:161} INFO - Started process (PID=146) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:58:39.036+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:58:39.038+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:58:39.038+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:58:39.383+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:58:39.429+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:58:39.429+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T05:58:39.433+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:58:39.433+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T05:58:39.443+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.415 seconds
[2024-05-14T05:59:09.793+0000] {processor.py:161} INFO - Started process (PID=156) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:59:09.795+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:59:09.798+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:59:09.797+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:59:10.201+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:59:10.213+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:59:10.213+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T05:59:10.219+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:59:10.219+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T05:59:10.228+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.448 seconds
[2024-05-14T05:59:40.545+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:59:40.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T05:59:40.550+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:59:40.549+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:59:40.877+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T05:59:40.923+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:59:40.923+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T05:59:40.928+0000] {logging_mixin.py:188} INFO - [2024-05-14T05:59:40.928+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T05:59:40.936+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.404 seconds
[2024-05-14T06:00:11.250+0000] {processor.py:161} INFO - Started process (PID=176) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:00:11.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:00:11.253+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:00:11.253+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:00:11.629+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:00:11.642+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:00:11.641+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:00:11.648+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:00:11.648+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:00:11.656+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.411 seconds
[2024-05-14T06:00:41.973+0000] {processor.py:161} INFO - Started process (PID=186) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:00:41.974+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:00:41.977+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:00:41.976+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:00:42.301+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:00:42.345+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:00:42.345+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:00:42.349+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:00:42.349+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:00:42.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.391 seconds
[2024-05-14T06:01:12.637+0000] {processor.py:161} INFO - Started process (PID=196) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:01:12.640+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:01:12.643+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:01:12.643+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:01:12.994+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:01:13.007+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:01:13.006+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:01:13.020+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:01:13.020+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:01:13.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.403 seconds
[2024-05-14T06:01:43.312+0000] {processor.py:161} INFO - Started process (PID=206) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:01:43.314+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:01:43.315+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:01:43.315+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:01:43.653+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:01:43.703+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:01:43.703+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:01:43.708+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:01:43.707+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:01:43.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.410 seconds
[2024-05-14T06:02:14.011+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:02:14.013+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:02:14.016+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:02:14.015+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:02:14.362+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:02:14.372+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:02:14.372+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:02:14.378+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:02:14.377+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:02:14.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.385 seconds
[2024-05-14T06:02:44.690+0000] {processor.py:161} INFO - Started process (PID=226) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:02:44.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:02:44.695+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:02:44.695+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:02:45.039+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:02:45.088+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:02:45.088+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:02:45.093+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:02:45.093+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:02:45.101+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.420 seconds
[2024-05-14T06:03:15.406+0000] {processor.py:161} INFO - Started process (PID=236) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:03:15.408+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:03:15.410+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:03:15.410+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:03:15.845+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:03:15.861+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:03:15.860+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:03:15.868+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:03:15.868+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:03:15.877+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.479 seconds
[2024-05-14T06:03:46.209+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:03:46.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:03:46.212+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:03:46.212+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:03:46.796+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:03:46.860+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:03:46.860+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:03:46.866+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:03:46.866+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:03:46.877+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.674 seconds
[2024-05-14T06:04:17.175+0000] {processor.py:161} INFO - Started process (PID=256) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:04:17.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:04:17.178+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:04:17.178+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:04:17.689+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:04:17.704+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:04:17.704+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:04:17.711+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:04:17.711+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:04:17.720+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.552 seconds
[2024-05-14T06:04:48.064+0000] {processor.py:161} INFO - Started process (PID=266) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:04:48.065+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:04:48.067+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:04:48.067+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:04:48.390+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:04:48.444+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:04:48.443+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:04:48.449+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:04:48.449+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:04:48.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.402 seconds
[2024-05-14T06:05:18.753+0000] {processor.py:161} INFO - Started process (PID=276) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:05:18.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:05:18.760+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:05:18.759+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:05:19.154+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:05:19.169+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:05:19.169+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:05:19.177+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:05:19.176+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:05:19.186+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.444 seconds
[2024-05-14T06:05:49.512+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:05:49.513+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:05:49.514+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:05:49.514+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:05:49.896+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:05:49.947+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:05:49.946+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:05:49.952+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:05:49.952+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:05:49.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.451 seconds
[2024-05-14T06:06:20.266+0000] {processor.py:161} INFO - Started process (PID=296) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:06:20.269+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:06:20.274+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:06:20.273+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:06:20.701+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:06:20.714+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:06:20.713+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:06:20.720+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:06:20.720+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:06:20.728+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.478 seconds
[2024-05-14T06:06:51.023+0000] {processor.py:161} INFO - Started process (PID=306) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:06:51.025+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:06:51.028+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:06:51.028+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:06:51.384+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:06:51.433+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:06:51.432+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:06:51.436+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:06:51.436+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:06:51.444+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.433 seconds
[2024-05-14T06:07:21.798+0000] {processor.py:161} INFO - Started process (PID=316) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:07:21.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:07:21.802+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:07:21.801+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:07:22.186+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:07:22.202+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:07:22.202+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:07:22.208+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:07:22.207+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:07:22.215+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.426 seconds
[2024-05-14T06:10:23.608+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:10:23.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:10:23.618+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:10:23.616+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:10:25.332+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:10:25.645+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:10:25.644+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:10:25.654+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:10:25.654+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:10:25.681+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 2.082 seconds
[2024-05-14T06:10:56.001+0000] {processor.py:161} INFO - Started process (PID=39) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:10:56.003+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:10:56.007+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:10:56.007+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:10:56.453+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:10:56.467+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:10:56.467+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:10:56.473+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:10:56.473+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:10:56.481+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.493 seconds
[2024-05-14T06:11:26.756+0000] {processor.py:161} INFO - Started process (PID=49) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:11:26.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:11:26.760+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:11:26.759+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:11:27.192+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:11:27.243+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:11:27.242+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:11:27.247+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:11:27.247+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:11:27.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.504 seconds
[2024-05-14T06:11:57.525+0000] {processor.py:161} INFO - Started process (PID=59) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:11:57.527+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:11:57.531+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:11:57.531+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:11:57.909+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:11:57.926+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:11:57.925+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:11:57.932+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:11:57.932+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:11:57.940+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.426 seconds
[2024-05-14T06:12:28.272+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:12:28.273+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:12:28.277+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:12:28.276+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:12:28.940+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:12:29.010+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:12:29.009+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:12:29.015+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:12:29.015+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:12:29.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.768 seconds
[2024-05-14T06:12:59.276+0000] {processor.py:161} INFO - Started process (PID=78) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:12:59.277+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:12:59.280+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:12:59.279+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:12:59.621+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:12:59.635+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:12:59.634+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:12:59.640+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:12:59.640+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:12:59.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.384 seconds
[2024-05-14T06:13:29.951+0000] {processor.py:161} INFO - Started process (PID=88) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:13:29.953+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:13:29.957+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:13:29.956+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:13:30.300+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:13:30.342+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:13:30.342+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:13:30.346+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:13:30.346+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:13:30.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.415 seconds
[2024-05-14T06:14:00.615+0000] {processor.py:161} INFO - Started process (PID=98) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:14:00.616+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:14:00.618+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:14:00.618+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:14:00.943+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:14:00.954+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:14:00.954+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:14:00.959+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:14:00.959+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:14:00.967+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.360 seconds
[2024-05-14T06:14:31.303+0000] {processor.py:161} INFO - Started process (PID=108) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:14:31.304+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:14:31.308+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:14:31.308+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:14:31.606+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:14:31.646+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:14:31.646+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:14:31.650+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:14:31.650+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:14:31.657+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.364 seconds
[2024-05-14T06:14:32.665+0000] {processor.py:161} INFO - Started process (PID=112) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:14:32.667+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:14:32.669+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:14:32.668+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:14:32.990+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:14:32.995+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:14:32.995+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:14:33.007+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:14:33.007+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:14:33.014+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.357 seconds
[2024-05-14T06:15:03.272+0000] {processor.py:161} INFO - Started process (PID=121) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:15:03.273+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:15:03.275+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:15:03.274+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:15:03.660+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:15:03.673+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:15:03.672+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:15:03.679+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:15:03.679+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:15:03.690+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.425 seconds
[2024-05-14T06:15:34.033+0000] {processor.py:161} INFO - Started process (PID=131) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:15:34.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:15:34.038+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:15:34.037+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:15:34.376+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:15:34.418+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:15:34.418+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:15:34.422+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:15:34.421+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:15:34.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.406 seconds
[2024-05-14T06:16:04.709+0000] {processor.py:161} INFO - Started process (PID=141) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:16:04.710+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:16:04.712+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:16:04.712+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:16:05.037+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:16:05.048+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:16:05.047+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:16:05.053+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:16:05.053+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:16:05.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.361 seconds
[2024-05-14T06:16:35.388+0000] {processor.py:161} INFO - Started process (PID=151) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:16:35.389+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:16:35.392+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:16:35.391+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:16:35.709+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:16:35.750+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:16:35.750+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:16:35.754+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:16:35.754+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:16:35.761+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.383 seconds
[2024-05-14T06:17:06.036+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:17:06.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:17:06.040+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:17:06.040+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:17:06.345+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:17:06.356+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:17:06.356+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:17:06.362+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:17:06.362+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:17:06.371+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.344 seconds
[2024-05-14T06:17:36.696+0000] {processor.py:161} INFO - Started process (PID=177) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:17:36.697+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:17:36.699+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:17:36.698+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:17:37.023+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:17:37.065+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:17:37.065+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:17:37.070+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:17:37.070+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:17:37.076+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.385 seconds
[2024-05-14T06:18:07.365+0000] {processor.py:161} INFO - Started process (PID=187) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:18:07.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:18:07.369+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:18:07.368+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:18:07.678+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:18:07.689+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:18:07.688+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:18:07.694+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:18:07.694+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:18:07.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.347 seconds
[2024-05-14T06:18:38.014+0000] {processor.py:161} INFO - Started process (PID=197) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:18:38.016+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:18:38.021+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:18:38.019+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:18:38.334+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:18:38.373+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:18:38.373+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:18:38.377+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:18:38.377+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:18:38.384+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.378 seconds
[2024-05-14T06:18:54.527+0000] {processor.py:161} INFO - Started process (PID=201) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:18:54.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:18:54.531+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:18:54.530+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:18:54.885+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:18:54.892+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:18:54.891+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:18:54.903+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:18:54.902+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:18:54.911+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.392 seconds
[2024-05-14T06:19:25.210+0000] {processor.py:161} INFO - Started process (PID=211) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:19:25.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:19:25.212+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:19:25.212+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:19:25.515+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:19:25.526+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:19:25.526+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:19:25.531+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:19:25.531+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:19:25.539+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.335 seconds
[2024-05-14T06:19:29.619+0000] {processor.py:161} INFO - Started process (PID=215) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:19:29.621+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:19:29.623+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:19:29.623+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:19:29.935+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:19:29.940+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:19:29.940+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:19:29.945+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:19:29.945+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:19:29.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.345 seconds
[2024-05-14T06:20:00.235+0000] {processor.py:161} INFO - Started process (PID=225) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:20:00.246+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:20:00.250+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:20:00.249+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:20:00.728+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:20:00.778+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:20:00.778+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:20:00.782+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:20:00.782+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:20:00.791+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.562 seconds
[2024-05-14T06:20:31.065+0000] {processor.py:161} INFO - Started process (PID=235) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:20:31.068+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:20:31.071+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:20:31.070+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:20:31.510+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:20:31.523+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:20:31.523+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:20:31.530+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:20:31.529+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:20:31.538+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.480 seconds
[2024-05-14T06:21:01.855+0000] {processor.py:161} INFO - Started process (PID=245) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:21:01.856+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:21:01.858+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:21:01.858+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:21:02.175+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:21:02.219+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:21:02.218+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:21:02.222+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:21:02.222+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:21:02.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.382 seconds
[2024-05-14T06:21:32.540+0000] {processor.py:161} INFO - Started process (PID=255) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:21:32.541+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:21:32.546+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:21:32.545+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:21:32.894+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:21:32.906+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:21:32.906+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:21:32.911+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:21:32.911+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:21:32.919+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.389 seconds
[2024-05-14T06:22:03.247+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:22:03.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:22:03.252+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:22:03.251+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:22:03.597+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:22:03.642+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:22:03.642+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:22:03.646+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:22:03.646+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:22:03.653+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.419 seconds
[2024-05-14T06:22:33.945+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:22:33.947+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:22:33.949+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:22:33.949+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:22:34.268+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:22:34.279+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:22:34.278+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:22:34.284+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:22:34.284+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:22:34.295+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.360 seconds
[2024-05-14T06:23:04.611+0000] {processor.py:161} INFO - Started process (PID=284) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:23:04.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:23:04.613+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:23:04.613+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:23:04.920+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:23:04.962+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:23:04.961+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:23:04.966+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:23:04.966+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:23:04.973+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.368 seconds
[2024-05-14T06:23:35.320+0000] {processor.py:161} INFO - Started process (PID=294) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:23:35.321+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:23:35.325+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:23:35.324+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:23:35.719+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:23:35.731+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:23:35.731+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:23:35.738+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:23:35.737+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:23:35.744+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.437 seconds
[2024-05-14T06:25:37.921+0000] {processor.py:161} INFO - Started process (PID=303) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:25:37.923+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:25:37.932+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:25:37.932+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:25:38.519+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:25:38.566+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:25:38.566+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:25:38.572+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:25:38.572+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:25:38.579+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.682 seconds
[2024-05-14T06:26:08.881+0000] {processor.py:161} INFO - Started process (PID=313) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:26:08.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:26:08.892+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:26:08.891+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:26:09.293+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:26:09.307+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:26:09.307+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:26:09.314+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:26:09.314+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:26:09.322+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.453 seconds
[2024-05-14T06:26:39.674+0000] {processor.py:161} INFO - Started process (PID=323) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:26:39.676+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:26:39.678+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:26:39.678+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:26:40.002+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:26:40.044+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:26:40.044+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:26:40.049+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:26:40.049+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:26:40.057+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.394 seconds
[2024-05-14T06:27:10.355+0000] {processor.py:161} INFO - Started process (PID=333) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:27:10.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:27:10.361+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:27:10.361+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:27:10.756+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:27:10.768+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:27:10.768+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:27:10.774+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:27:10.774+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:27:10.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.441 seconds
[2024-05-14T06:27:41.098+0000] {processor.py:161} INFO - Started process (PID=343) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:27:41.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:27:41.104+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:27:41.103+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:27:41.497+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:27:41.545+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:27:41.545+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:27:41.549+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:27:41.549+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:27:41.557+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.476 seconds
[2024-05-14T06:28:11.802+0000] {processor.py:161} INFO - Started process (PID=353) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:28:11.803+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:28:11.805+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:28:11.805+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:28:12.130+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:28:12.145+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:28:12.144+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:28:12.152+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:28:12.151+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:28:12.161+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.368 seconds
[2024-05-14T06:28:42.453+0000] {processor.py:161} INFO - Started process (PID=363) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:28:42.455+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:28:42.457+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:28:42.457+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:28:42.862+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:28:42.918+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:28:42.918+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:28:42.922+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:28:42.922+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:28:42.931+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.488 seconds
[2024-05-14T06:29:13.184+0000] {processor.py:161} INFO - Started process (PID=373) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:29:13.185+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:29:13.188+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:29:13.187+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:29:13.694+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:29:13.709+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:29:13.708+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:29:13.715+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:29:13.715+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:29:13.723+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.550 seconds
[2024-05-14T06:29:44.075+0000] {processor.py:161} INFO - Started process (PID=389) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:29:44.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:29:44.081+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:29:44.080+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:29:44.533+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:29:44.587+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:29:44.587+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:29:44.591+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:29:44.591+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:29:44.600+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.537 seconds
[2024-05-14T06:30:14.892+0000] {processor.py:161} INFO - Started process (PID=399) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:30:14.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:30:14.898+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:30:14.897+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:30:15.256+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:30:15.268+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:30:15.268+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:30:15.274+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:30:15.273+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:30:15.282+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.403 seconds
[2024-05-14T06:30:45.682+0000] {processor.py:161} INFO - Started process (PID=409) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:30:45.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:30:45.685+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:30:45.684+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:30:46.002+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:30:46.051+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:30:46.051+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:30:46.055+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:30:46.055+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:30:46.064+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.392 seconds
[2024-05-14T06:31:16.324+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:31:16.325+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:31:16.327+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:31:16.327+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:31:16.842+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:31:16.854+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:31:16.854+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:31:16.861+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:31:16.861+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:31:16.868+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.553 seconds
[2024-05-14T06:31:47.157+0000] {processor.py:161} INFO - Started process (PID=429) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:31:47.159+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:31:47.163+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:31:47.162+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:31:47.586+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:31:47.639+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:31:47.639+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:31:47.643+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:31:47.643+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:31:47.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.508 seconds
[2024-05-14T06:32:17.985+0000] {processor.py:161} INFO - Started process (PID=439) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:32:17.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:32:17.989+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:32:17.989+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:32:18.351+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:32:18.363+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:32:18.363+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:32:18.369+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:32:18.369+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:32:18.377+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.403 seconds
[2024-05-14T06:32:48.703+0000] {processor.py:161} INFO - Started process (PID=449) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:32:48.705+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:32:48.707+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:32:48.706+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:32:49.046+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:32:49.098+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:32:49.098+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:32:49.102+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:32:49.102+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:32:49.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.419 seconds
[2024-05-14T06:33:19.374+0000] {processor.py:161} INFO - Started process (PID=459) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:33:19.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:33:19.380+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:33:19.379+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:33:19.751+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:33:19.763+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:33:19.763+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:33:19.769+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:33:19.768+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:33:19.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.414 seconds
[2024-05-14T06:33:50.129+0000] {processor.py:161} INFO - Started process (PID=469) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:33:50.131+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:33:50.133+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:33:50.133+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:33:50.470+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:33:50.516+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:33:50.516+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:33:50.521+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:33:50.521+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:33:50.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.411 seconds
[2024-05-14T06:34:20.887+0000] {processor.py:161} INFO - Started process (PID=479) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:34:20.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:34:20.894+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:34:20.893+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:34:21.401+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:34:21.417+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:34:21.417+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:34:21.425+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:34:21.425+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:34:21.435+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.562 seconds
[2024-05-14T06:47:01.040+0000] {processor.py:161} INFO - Started process (PID=483) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:47:01.042+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:47:01.045+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:47:01.045+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:47:01.504+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:47:01.561+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:47:01.561+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:47:01.565+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:47:01.565+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:47:01.572+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.558 seconds
[2024-05-14T06:47:31.892+0000] {processor.py:161} INFO - Started process (PID=493) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:47:31.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:47:31.899+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:47:31.898+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:47:32.302+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:47:32.315+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:47:32.315+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:47:32.321+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:47:32.321+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:47:32.330+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.453 seconds
[2024-05-14T06:48:02.697+0000] {processor.py:161} INFO - Started process (PID=503) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:48:02.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:48:02.703+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:48:02.703+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:48:03.196+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:48:03.248+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:48:03.248+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:48:03.252+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:48:03.252+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:48:03.260+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.575 seconds
[2024-05-14T06:48:33.537+0000] {processor.py:161} INFO - Started process (PID=513) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:48:33.537+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:48:33.540+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:48:33.540+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:48:33.980+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:48:33.993+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:48:33.992+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:48:33.998+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:48:33.998+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:48:34.006+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.477 seconds
[2024-05-14T06:49:04.326+0000] {processor.py:161} INFO - Started process (PID=522) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:49:04.328+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:49:04.333+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:49:04.332+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:49:04.757+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:49:04.805+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:49:04.804+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:49:04.810+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:49:04.810+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:49:04.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.509 seconds
[2024-05-14T06:49:35.123+0000] {processor.py:161} INFO - Started process (PID=532) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:49:35.126+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:49:35.132+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:49:35.131+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:49:35.608+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:49:35.624+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:49:35.624+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:49:35.632+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:49:35.631+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:49:35.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.534 seconds
[2024-05-14T06:50:05.978+0000] {processor.py:161} INFO - Started process (PID=541) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:50:05.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:50:05.988+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:50:05.987+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:50:06.434+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:50:06.485+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:50:06.485+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:50:06.489+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:50:06.489+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:50:06.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.536 seconds
[2024-05-14T06:50:36.772+0000] {processor.py:161} INFO - Started process (PID=551) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:50:36.773+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:50:36.777+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:50:36.776+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:50:37.241+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:50:37.255+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:50:37.254+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:50:37.260+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:50:37.260+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:50:37.269+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.509 seconds
[2024-05-14T06:51:07.593+0000] {processor.py:161} INFO - Started process (PID=561) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:51:07.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:51:07.617+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:51:07.617+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:51:08.215+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:51:08.266+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:51:08.265+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:51:08.270+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:51:08.270+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:51:08.277+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.699 seconds
[2024-05-14T06:51:38.521+0000] {processor.py:161} INFO - Started process (PID=577) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:51:38.524+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:51:38.528+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:51:38.528+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:51:38.547+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:51:38.544+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 11, in <module>
    from app import check_if_update
  File "/opt/airflow/dags/app.py", line 4, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 399
    
    ^
IndentationError: expected an indented block after function definition on line 397
[2024-05-14T06:51:38.548+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:51:38.567+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.060 seconds
[2024-05-14T06:52:08.892+0000] {processor.py:161} INFO - Started process (PID=585) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:52:08.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:52:08.898+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:52:08.897+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:52:08.921+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:52:08.919+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 11, in <module>
    from app import check_if_update
  File "/opt/airflow/dags/app.py", line 4, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 399
    
    ^
IndentationError: expected an indented block after function definition on line 397
[2024-05-14T06:52:08.922+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:52:08.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.062 seconds
[2024-05-14T06:52:39.231+0000] {processor.py:161} INFO - Started process (PID=593) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:52:39.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:52:39.235+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:52:39.234+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:52:39.246+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:52:39.244+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 11, in <module>
    from app import check_if_update
  File "/opt/airflow/dags/app.py", line 4, in <module>
    from crawler104 import Crawler104
  File "/opt/airflow/dags/crawler104.py", line 399
    
    ^
IndentationError: expected an indented block after function definition on line 397
[2024-05-14T06:52:39.247+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:52:39.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.043 seconds
[2024-05-14T06:53:09.519+0000] {processor.py:161} INFO - Started process (PID=601) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:53:09.521+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:53:09.523+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:53:09.522+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:53:09.963+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:53:10.011+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:53:10.011+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:53:10.016+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:53:10.016+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:53:10.024+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.515 seconds
[2024-05-14T06:53:40.319+0000] {processor.py:161} INFO - Started process (PID=611) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:53:40.322+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:53:40.324+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:53:40.323+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:53:40.692+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:53:40.703+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:53:40.703+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:53:40.708+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:53:40.708+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:53:40.717+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.408 seconds
[2024-05-14T06:54:11.049+0000] {processor.py:161} INFO - Started process (PID=621) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:54:11.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:54:11.052+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:54:11.052+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:54:11.443+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:54:11.495+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:54:11.494+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:54:11.500+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:54:11.500+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:54:11.510+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.471 seconds
[2024-05-14T06:54:41.824+0000] {processor.py:161} INFO - Started process (PID=631) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:54:41.826+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:54:41.827+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:54:41.827+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:54:42.165+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:54:42.176+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:54:42.176+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:54:42.182+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:54:42.182+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:54:42.191+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.378 seconds
[2024-05-14T06:54:56.367+0000] {processor.py:161} INFO - Started process (PID=635) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:54:56.368+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:54:56.370+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:54:56.369+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:54:56.765+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:54:56.771+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:54:56.771+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:54:56.777+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:54:56.777+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:54:56.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.432 seconds
[2024-05-14T06:55:02.861+0000] {processor.py:161} INFO - Started process (PID=639) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:55:02.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:55:02.864+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:55:02.864+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:55:03.215+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:55:03.220+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:55:03.220+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:55:03.231+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:55:03.230+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:55:03.239+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.388 seconds
[2024-05-14T06:55:33.553+0000] {processor.py:161} INFO - Started process (PID=649) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:55:33.555+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:55:33.556+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:55:33.556+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:55:33.959+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:55:34.007+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:55:34.007+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:55:34.012+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:55:34.012+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:55:34.020+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.473 seconds
[2024-05-14T06:56:04.344+0000] {processor.py:161} INFO - Started process (PID=659) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:56:04.346+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:56:04.347+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:56:04.347+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:56:04.856+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:56:04.913+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:56:04.912+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:56:04.917+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:56:04.917+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:56:04.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.586 seconds
[2024-05-14T06:56:35.216+0000] {processor.py:161} INFO - Started process (PID=669) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:56:35.218+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:56:35.220+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:56:35.219+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:56:35.854+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:56:35.871+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:56:35.870+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:56:35.877+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:56:35.877+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:56:35.886+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.679 seconds
[2024-05-14T06:57:06.252+0000] {processor.py:161} INFO - Started process (PID=679) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:57:06.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:57:06.255+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:57:06.255+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:57:06.791+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:57:06.852+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:57:06.851+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:57:06.857+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:57:06.857+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:57:06.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.623 seconds
[2024-05-14T06:57:37.147+0000] {processor.py:161} INFO - Started process (PID=688) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:57:37.149+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:57:37.150+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:57:37.150+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:57:37.682+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:57:37.723+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:57:37.723+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:57:37.731+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:57:37.731+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:57:37.743+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.604 seconds
[2024-05-14T06:58:08.086+0000] {processor.py:161} INFO - Started process (PID=698) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:58:08.089+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:58:08.091+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:58:08.090+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:58:08.520+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:58:08.568+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:58:08.568+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:58:08.572+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:58:08.572+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:58:08.579+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.507 seconds
[2024-05-14T06:58:38.867+0000] {processor.py:161} INFO - Started process (PID=708) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:58:38.872+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:58:38.874+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:58:38.874+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:58:39.372+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:58:39.410+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:58:39.410+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:58:39.416+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:58:39.416+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:58:39.424+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.575 seconds
[2024-05-14T06:59:09.768+0000] {processor.py:161} INFO - Started process (PID=724) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:59:09.773+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:59:09.776+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:59:09.775+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:59:10.221+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:59:10.269+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:59:10.269+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:59:10.273+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:59:10.273+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:59:10.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.529 seconds
[2024-05-14T06:59:40.618+0000] {processor.py:161} INFO - Started process (PID=734) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:59:40.621+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T06:59:40.623+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:59:40.622+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:59:41.034+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T06:59:41.047+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:59:41.047+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T06:59:41.053+0000] {logging_mixin.py:188} INFO - [2024-05-14T06:59:41.053+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T06:59:41.061+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.459 seconds
[2024-05-14T07:00:11.460+0000] {processor.py:161} INFO - Started process (PID=744) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:00:35.787+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:00:35.788+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:00:35.791+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:00:35.790+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:00:37.587+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:00:37.809+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:00:37.809+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:00:37.826+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:00:37.826+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:00:38.298+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:00:38.296+0000] {dagbag.py:654} ERROR - Failed to write serialized DAG: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 642, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 158, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(data_pipeline_jobs104) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'data_pipeline_jobs104', 'fileloc': '/opt/airflow/dags/data_pipeline_jobs104.py', 'fileloc_hash': 67140776701959873, 'data': '{"__version": 1, "dag": {"_dag_id": "data_pipeline_jobs104", "_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": " ... (3524 characters truncated) ... onOperator", "_task_module": "airflow.operators.python", "_is_empty": false, "op_args": [], "op_kwargs": {}}], "dag_dependencies": [], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2024, 5, 14, 7, 0, 37, 615057, tzinfo=Timezone('UTC')), 'dag_hash': '59b8533e0eeecc98f82360cf1e317f67', 'processor_subdir': '/opt/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-05-14T07:00:38.299+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:00:38.299+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:00:38.300+0000] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 859, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 895, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 664, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 314, in iter
    return fut.result()
           ^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 680, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3108, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(data_pipeline_jobs104) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'data_pipeline_jobs104', 'fileloc': '/opt/airflow/dags/data_pipeline_jobs104.py', 'fileloc_hash': 67140776701959873, 'data': '{"__version": 1, "dag": {"_dag_id": "data_pipeline_jobs104", "_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": " ... (3524 characters truncated) ... onOperator", "_task_module": "airflow.operators.python", "_is_empty": false, "op_args": [], "op_kwargs": {}}], "dag_dependencies": [], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2024, 5, 14, 7, 0, 37, 615057, tzinfo=Timezone('UTC')), 'dag_hash': '59b8533e0eeecc98f82360cf1e317f67', 'processor_subdir': '/opt/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-05-14T07:01:08.534+0000] {processor.py:161} INFO - Started process (PID=43) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:01:08.536+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:01:08.539+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:01:08.539+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:01:08.907+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:01:08.949+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:01:08.949+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:01:08.953+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:01:08.953+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:01:08.961+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.432 seconds
[2024-05-14T07:01:39.103+0000] {processor.py:161} INFO - Started process (PID=51) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:01:39.105+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:01:39.114+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:01:39.113+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:01:39.522+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:01:39.535+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:01:39.535+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:01:39.542+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:01:39.542+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:01:39.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.459 seconds
[2024-05-14T07:02:09.887+0000] {processor.py:161} INFO - Started process (PID=61) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:02:09.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:02:09.894+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:02:09.893+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:02:10.310+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:02:10.360+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:02:10.359+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:02:10.363+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:02:10.363+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:02:10.371+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.496 seconds
[2024-05-14T07:02:40.703+0000] {processor.py:161} INFO - Started process (PID=71) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:02:40.706+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:02:40.710+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:02:40.709+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:02:41.138+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:02:41.154+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:02:41.153+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:02:41.160+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:02:41.160+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:02:41.168+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.475 seconds
[2024-05-14T07:03:11.521+0000] {processor.py:161} INFO - Started process (PID=80) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:03:11.523+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:03:11.527+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:03:11.527+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:03:11.923+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:03:11.971+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:03:11.971+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:03:11.975+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:03:11.975+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:03:11.982+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.470 seconds
[2024-05-14T07:03:42.282+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:03:42.284+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:03:42.287+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:03:42.287+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:03:42.839+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:03:42.854+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:03:42.853+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:03:42.859+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:03:42.859+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:03:42.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.591 seconds
[2024-05-14T07:04:13.216+0000] {processor.py:161} INFO - Started process (PID=100) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:04:13.219+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:04:13.223+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:04:13.223+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:04:13.645+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:04:13.692+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:04:13.692+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:04:13.697+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:04:13.696+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:04:13.705+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.498 seconds
[2024-05-14T07:04:44.011+0000] {processor.py:161} INFO - Started process (PID=109) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:04:44.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:04:44.022+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:04:44.019+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:04:44.475+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:04:44.488+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:04:44.488+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:04:44.495+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:04:44.495+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:04:44.503+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.499 seconds
[2024-05-14T07:05:14.847+0000] {processor.py:161} INFO - Started process (PID=119) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:05:14.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:05:14.853+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:05:14.853+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:05:15.255+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:05:15.307+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:05:15.306+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:05:15.311+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:05:15.311+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:05:15.319+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.480 seconds
[2024-05-14T07:05:45.678+0000] {processor.py:161} INFO - Started process (PID=129) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:05:45.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:05:45.683+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:05:45.682+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:05:46.120+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:05:46.133+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:05:46.133+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:05:46.138+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:05:46.138+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:05:46.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.476 seconds
[2024-05-14T07:06:16.538+0000] {processor.py:161} INFO - Started process (PID=139) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:06:16.541+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:06:16.546+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:06:16.546+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:06:16.968+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:06:17.014+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:06:17.014+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:06:17.018+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:06:17.018+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:06:17.025+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.501 seconds
[2024-05-14T07:06:47.310+0000] {processor.py:161} INFO - Started process (PID=148) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:06:47.311+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:06:47.315+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:06:47.315+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:06:47.689+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:06:47.700+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:06:47.699+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:06:47.705+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:06:47.705+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:06:47.712+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.413 seconds
[2024-05-14T07:07:18.095+0000] {processor.py:161} INFO - Started process (PID=158) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:07:18.098+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:07:18.102+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:07:18.101+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:07:18.509+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:07:18.555+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:07:18.554+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:07:18.559+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:07:18.559+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:07:18.566+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.485 seconds
[2024-05-14T07:07:48.904+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:07:48.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:07:48.910+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:07:48.909+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:07:49.289+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:07:49.302+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:07:49.302+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:07:49.308+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:07:49.308+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:07:49.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.421 seconds
[2024-05-14T07:11:29.465+0000] {processor.py:161} INFO - Started process (PID=178) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:11:29.466+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:11:29.470+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:11:29.469+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:11:29.952+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:11:30.004+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:11:30.004+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:11:30.008+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:11:30.008+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:11:30.015+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.573 seconds
[2024-05-14T07:12:00.350+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:12:00.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:12:00.359+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:12:00.358+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:12:00.800+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:12:00.822+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:12:00.822+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:12:00.828+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:12:00.828+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:12:00.840+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.502 seconds
[2024-05-14T07:12:31.193+0000] {processor.py:161} INFO - Started process (PID=198) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:12:31.197+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:12:31.200+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:12:31.200+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:12:31.590+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:12:31.636+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:12:31.636+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:12:31.640+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:12:31.640+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:12:31.647+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.464 seconds
[2024-05-14T07:13:02.007+0000] {processor.py:161} INFO - Started process (PID=208) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:13:02.008+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:13:02.012+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:13:02.011+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:13:02.463+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:13:02.478+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:13:02.478+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:13:02.484+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:13:02.484+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:13:02.495+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.506 seconds
[2024-05-14T07:13:32.891+0000] {processor.py:161} INFO - Started process (PID=217) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:13:32.893+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:13:32.895+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:13:32.895+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:13:33.308+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:13:33.365+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:13:33.365+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:13:33.371+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:13:33.371+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:13:33.379+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.500 seconds
[2024-05-14T07:14:03.702+0000] {processor.py:161} INFO - Started process (PID=227) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:14:03.704+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:14:03.707+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:14:03.707+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:14:04.109+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:14:04.123+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:14:04.123+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:14:04.129+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:14:04.129+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:14:04.137+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.451 seconds
[2024-05-14T07:14:34.552+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:14:34.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:14:34.555+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:14:34.555+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:14:35.106+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:14:35.164+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:14:35.163+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:14:35.168+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:14:35.168+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:14:35.177+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.632 seconds
[2024-05-14T07:15:05.491+0000] {processor.py:161} INFO - Started process (PID=247) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:15:05.493+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:15:05.504+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:15:05.503+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:15:05.906+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:15:05.917+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:15:05.917+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:15:05.924+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:15:05.924+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:15:05.932+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.450 seconds
[2024-05-14T07:15:36.269+0000] {processor.py:161} INFO - Started process (PID=257) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:15:36.271+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:15:36.274+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:15:36.273+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:15:36.718+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:15:36.795+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:15:36.795+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:15:36.800+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:15:36.799+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:15:36.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.545 seconds
[2024-05-14T07:16:07.062+0000] {processor.py:161} INFO - Started process (PID=267) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:16:07.066+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:16:07.070+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:16:07.069+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:16:07.496+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:16:07.509+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:16:07.508+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:16:07.514+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:16:07.514+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:16:07.522+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.472 seconds
[2024-05-14T07:16:37.897+0000] {processor.py:161} INFO - Started process (PID=278) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:16:37.899+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:16:37.905+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:16:37.904+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:16:38.287+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:16:38.332+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:16:38.331+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:16:38.336+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:16:38.336+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:16:38.343+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.459 seconds
[2024-05-14T07:17:08.698+0000] {processor.py:161} INFO - Started process (PID=288) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:17:08.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:17:08.706+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:17:08.706+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:17:09.110+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:17:09.122+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:17:09.121+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:17:09.130+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:17:09.130+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:17:09.137+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.450 seconds
[2024-05-14T07:17:39.458+0000] {processor.py:161} INFO - Started process (PID=297) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:17:39.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:17:39.463+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:17:39.463+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:17:39.917+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:17:39.969+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:17:39.968+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:17:39.974+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:17:39.974+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:17:39.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.532 seconds
[2024-05-14T07:18:10.290+0000] {processor.py:161} INFO - Started process (PID=307) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:18:10.294+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:18:10.297+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:18:10.297+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:18:10.688+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:18:10.701+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:18:10.700+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:18:10.706+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:18:10.706+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:18:10.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.432 seconds
[2024-05-14T07:18:41.058+0000] {processor.py:161} INFO - Started process (PID=317) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:18:41.060+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:18:41.063+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:18:41.063+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:18:41.400+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:18:41.445+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:18:41.444+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:18:41.448+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:18:41.448+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:18:41.455+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.405 seconds
[2024-05-14T07:19:11.797+0000] {processor.py:161} INFO - Started process (PID=327) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:19:11.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:19:11.803+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:19:11.802+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:19:12.297+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:19:12.311+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:19:12.311+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:19:12.318+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:19:12.318+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:19:12.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.540 seconds
[2024-05-14T07:19:15.396+0000] {processor.py:161} INFO - Started process (PID=331) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:19:15.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:19:15.399+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:19:15.399+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:19:15.734+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:19:15.741+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:19:15.740+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:19:15.751+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:19:15.751+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:19:15.760+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.373 seconds
[2024-05-14T07:19:46.092+0000] {processor.py:161} INFO - Started process (PID=341) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:19:46.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:19:46.099+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:19:46.099+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:19:46.517+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:19:46.566+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:19:46.565+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:19:46.571+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:19:46.570+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:19:46.578+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.499 seconds
[2024-05-14T07:20:16.866+0000] {processor.py:161} INFO - Started process (PID=351) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:20:16.867+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:20:16.871+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:20:16.870+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:20:17.274+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:20:17.286+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:20:17.286+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:20:17.294+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:20:17.294+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:20:17.302+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.445 seconds
[2024-05-14T07:20:47.611+0000] {processor.py:161} INFO - Started process (PID=361) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:20:47.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:20:47.616+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:20:47.615+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:20:48.021+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:20:48.067+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:20:48.067+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:20:48.071+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:20:48.071+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:20:48.078+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.473 seconds
[2024-05-14T07:21:15.391+0000] {processor.py:161} INFO - Started process (PID=371) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:21:15.393+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:21:15.395+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:21:15.395+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:21:15.725+0000] {logging_mixin.py:188} INFO - test
[2024-05-14T07:21:15.727+0000] {logging_mixin.py:188} INFO - 44
[2024-05-14T07:21:15.729+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:21:15.735+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:21:15.735+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:21:15.739+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:21:15.739+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:21:15.747+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.366 seconds
[2024-05-14T07:21:46.136+0000] {processor.py:161} INFO - Started process (PID=381) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:21:46.138+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:21:46.142+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:21:46.141+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:21:46.508+0000] {logging_mixin.py:188} INFO - test
[2024-05-14T07:21:46.510+0000] {logging_mixin.py:188} INFO - 44
[2024-05-14T07:21:46.513+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:21:46.519+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:21:46.519+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:21:46.524+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:21:46.524+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:21:46.531+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.409 seconds
[2024-05-14T07:22:16.876+0000] {processor.py:161} INFO - Started process (PID=391) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:22:16.878+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:22:16.883+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:22:16.882+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:22:17.271+0000] {logging_mixin.py:188} INFO - test
[2024-05-14T07:22:17.273+0000] {logging_mixin.py:188} INFO - 44
[2024-05-14T07:22:17.275+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:22:17.317+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:22:17.317+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:22:17.321+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:22:17.321+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:22:17.329+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.467 seconds
[2024-05-14T07:22:47.536+0000] {processor.py:161} INFO - Started process (PID=401) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:22:47.539+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:22:47.543+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:22:47.542+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:22:47.920+0000] {logging_mixin.py:188} INFO - test
[2024-05-14T07:22:47.923+0000] {logging_mixin.py:188} INFO - 44
[2024-05-14T07:22:47.925+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:22:47.937+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:22:47.937+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:22:47.941+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:22:47.941+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:22:47.949+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.426 seconds
[2024-05-14T07:23:14.801+0000] {processor.py:161} INFO - Started process (PID=411) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:23:14.802+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:23:14.803+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:23:14.803+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:23:15.151+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:23:15.149+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 44, in <module>
    crawler.run(job_keywords, company_exclude)
    ^^^^^^^
NameError: name 'crawler' is not defined
[2024-05-14T07:23:15.152+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:23:15.163+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.366 seconds
[2024-05-14T07:23:45.483+0000] {processor.py:161} INFO - Started process (PID=421) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:23:45.484+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:23:45.488+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:23:45.487+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:23:45.878+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:23:45.877+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 44, in <module>
    crawler.run(job_keywords, company_exclude)
    ^^^^^^^
NameError: name 'crawler' is not defined
[2024-05-14T07:23:45.879+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:23:45.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.416 seconds
[2024-05-14T07:24:04.076+0000] {processor.py:161} INFO - Started process (PID=431) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:24:04.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:24:04.081+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:24:04.081+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:24:04.442+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:24:04.440+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 44, in <module>
    crawler.run(job_keywords, company_exclude)
    ^^^^^^^
NameError: name 'crawler' is not defined
[2024-05-14T07:24:04.443+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:24:04.452+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.384 seconds
[2024-05-14T07:24:10.497+0000] {processor.py:161} INFO - Started process (PID=435) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:24:10.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:24:10.504+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:24:10.504+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:24:10.913+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:24:10.912+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 44, in <module>
    crawler.run(job_keywords, company_exclude)
    ^^^^^^^
NameError: name 'crawler' is not defined
[2024-05-14T07:24:10.914+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:24:10.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.437 seconds
[2024-05-14T07:24:41.241+0000] {processor.py:161} INFO - Started process (PID=445) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:24:41.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:24:41.247+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:24:41.246+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:24:41.651+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:24:41.650+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/data_pipeline_jobs104.py", line 44, in <module>
    crawler.run(job_keywords, company_exclude)
    ^^^^^^^
NameError: name 'crawler' is not defined
[2024-05-14T07:24:41.652+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:24:41.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.430 seconds
[2024-05-14T07:24:53.776+0000] {processor.py:161} INFO - Started process (PID=451) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:24:53.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:24:53.778+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:24:53.778+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:24:54.102+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:24:54.108+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:24:54.107+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:24:54.113+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:24:54.113+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:24:54.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.352 seconds
[2024-05-14T07:25:02.916+0000] {processor.py:161} INFO - Started process (PID=459) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:25:02.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:25:02.919+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:25:02.919+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:25:03.293+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:25:03.300+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:25:03.299+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:25:03.306+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:25:03.305+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:25:03.316+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.409 seconds
[2024-05-14T07:25:33.683+0000] {processor.py:161} INFO - Started process (PID=468) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:25:33.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:25:33.690+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:25:33.690+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:25:34.340+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:25:34.391+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:25:34.391+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:25:34.396+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:25:34.395+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:25:34.406+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.739 seconds
[2024-05-14T07:26:04.705+0000] {processor.py:161} INFO - Started process (PID=477) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:26:04.707+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:26:04.710+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:26:04.710+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:26:05.172+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:26:05.185+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:26:05.184+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:26:05.191+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:26:05.191+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:26:05.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.510 seconds
[2024-05-14T07:26:28.480+0000] {processor.py:161} INFO - Started process (PID=487) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:26:28.482+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:26:28.486+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:26:28.485+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:26:28.924+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:26:28.930+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:26:28.930+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:26:28.944+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:26:28.944+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:26:28.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.486 seconds
[2024-05-14T07:26:59.365+0000] {processor.py:161} INFO - Started process (PID=497) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:26:59.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:26:59.371+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:26:59.370+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:26:59.905+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:26:59.960+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:26:59.959+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:26:59.964+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:26:59.964+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:26:59.972+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.621 seconds
[2024-05-14T07:27:25.210+0000] {processor.py:161} INFO - Started process (PID=501) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:27:25.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:27:25.219+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:27:25.218+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:27:25.222+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:27:25.222+0000] {dagbag.py:334} INFO - File /opt/airflow/dags/data_pipeline_jobs104.py assumed to contain no DAGs. Skipping.
[2024-05-14T07:27:25.222+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:27:25.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.042 seconds
[2024-05-14T07:27:55.557+0000] {processor.py:161} INFO - Started process (PID=510) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:27:55.560+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:27:55.564+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:27:55.563+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:27:56.024+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:27:56.071+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:27:56.071+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:27:56.076+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:27:56.076+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:27:56.085+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.539 seconds
[2024-05-14T07:28:26.433+0000] {processor.py:161} INFO - Started process (PID=519) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:28:26.435+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:28:26.438+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:28:26.438+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:28:26.876+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:28:26.892+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:28:26.891+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:28:26.898+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:28:26.897+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:28:26.907+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.485 seconds
[2024-05-14T07:28:57.280+0000] {processor.py:161} INFO - Started process (PID=535) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:28:57.283+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:28:57.287+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:28:57.286+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:28:57.703+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:28:57.711+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:28:57.711+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:28:57.717+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:28:57.717+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:28:57.724+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.455 seconds
[2024-05-14T07:29:07.828+0000] {processor.py:161} INFO - Started process (PID=539) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:29:07.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:29:07.830+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:29:07.830+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:29:08.153+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:29:08.198+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:29:08.198+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:29:08.203+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:29:08.203+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:29:08.212+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.391 seconds
[2024-05-14T07:29:38.521+0000] {processor.py:161} INFO - Started process (PID=549) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:29:38.523+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:29:38.525+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:29:38.525+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:29:39.031+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:29:39.046+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:29:39.045+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:29:39.053+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:29:39.052+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:29:39.061+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.556 seconds
[2024-05-14T07:30:09.238+0000] {processor.py:161} INFO - Started process (PID=559) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:30:09.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:30:09.259+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:30:09.258+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:30:09.769+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:30:09.775+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:30:09.775+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:30:09.780+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:30:09.780+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:30:09.788+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.573 seconds
[2024-05-14T07:30:40.113+0000] {processor.py:161} INFO - Started process (PID=569) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:30:40.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:30:40.121+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:30:40.120+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:30:40.552+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:30:40.602+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:30:40.601+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:30:40.606+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:30:40.606+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:30:40.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.513 seconds
[2024-05-14T07:31:10.961+0000] {processor.py:161} INFO - Started process (PID=579) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:31:10.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:31:10.967+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:31:10.966+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:31:11.362+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:31:11.374+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:31:11.374+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:31:11.379+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:31:11.379+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:31:11.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.438 seconds
[2024-05-14T07:31:41.429+0000] {processor.py:161} INFO - Started process (PID=589) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:31:41.432+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:31:41.434+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:31:41.433+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:31:41.764+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:31:41.769+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:31:41.769+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:31:41.773+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:31:41.773+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:31:41.780+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.358 seconds
[2024-05-14T07:32:12.092+0000] {processor.py:161} INFO - Started process (PID=599) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:32:12.093+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:32:12.097+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:32:12.096+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:32:12.473+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:32:12.516+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:32:12.516+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:32:12.520+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:32:12.520+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:32:12.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.445 seconds
[2024-05-14T07:32:42.897+0000] {processor.py:161} INFO - Started process (PID=609) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:32:42.899+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:32:42.903+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:32:42.903+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:32:43.371+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:32:43.384+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:32:43.384+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:32:43.389+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:32:43.389+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:32:43.396+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.513 seconds
[2024-05-14T07:39:10.950+0000] {processor.py:161} INFO - Started process (PID=618) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:39:10.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:39:10.954+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:39:10.953+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:39:11.436+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:39:11.487+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:39:11.487+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:39:11.492+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:39:11.491+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:39:11.500+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.555 seconds
[2024-05-14T07:39:41.841+0000] {processor.py:161} INFO - Started process (PID=628) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:39:41.845+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:39:41.850+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:39:41.849+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:39:42.316+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:39:42.330+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:39:42.330+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:39:42.336+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:39:42.336+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:39:42.344+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.514 seconds
[2024-05-14T07:40:12.696+0000] {processor.py:161} INFO - Started process (PID=638) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:40:12.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:40:12.703+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:40:12.702+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:40:13.102+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:40:13.146+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:40:13.146+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:40:13.150+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:40:13.150+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:40:13.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.475 seconds
[2024-05-14T07:40:43.438+0000] {processor.py:161} INFO - Started process (PID=648) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:40:43.439+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:40:43.442+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:40:43.442+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:40:43.840+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:40:43.852+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:40:43.852+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:40:43.861+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:40:43.860+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:40:43.870+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.439 seconds
[2024-05-14T07:41:14.200+0000] {processor.py:161} INFO - Started process (PID=657) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:41:14.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:41:14.204+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:41:14.204+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:41:14.585+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:41:14.627+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:41:14.627+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:41:14.631+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:41:14.631+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:41:14.639+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.447 seconds
[2024-05-14T07:41:44.945+0000] {processor.py:161} INFO - Started process (PID=667) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:41:44.946+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:41:44.948+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:41:44.948+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:41:45.322+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:41:45.335+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:41:45.335+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:41:45.340+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:41:45.340+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:41:45.348+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.409 seconds
[2024-05-14T07:41:46.370+0000] {processor.py:161} INFO - Started process (PID=671) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:41:46.371+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:41:46.373+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:41:46.373+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:41:46.693+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:41:46.698+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:41:46.698+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:41:46.708+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:41:46.708+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:41:46.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.351 seconds
[2024-05-14T07:42:17.046+0000] {processor.py:161} INFO - Started process (PID=681) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:42:17.048+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:42:17.051+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:42:17.051+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:42:17.471+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:42:17.517+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:42:17.517+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:42:17.522+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:42:17.522+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:42:17.529+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.494 seconds
[2024-05-14T07:42:47.865+0000] {processor.py:161} INFO - Started process (PID=691) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:42:47.866+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:42:47.869+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:42:47.869+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:42:48.285+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:42:48.298+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:42:48.298+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:42:48.304+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:42:48.304+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:42:48.312+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.454 seconds
[2024-05-14T07:43:18.721+0000] {processor.py:161} INFO - Started process (PID=701) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:43:18.722+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:43:18.726+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:43:18.725+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:43:19.136+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:43:19.181+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:43:19.181+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:43:19.185+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:43:19.184+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:43:19.193+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.482 seconds
[2024-05-14T07:43:46.438+0000] {processor.py:161} INFO - Started process (PID=711) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:43:46.439+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:43:46.442+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:43:46.441+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:43:46.941+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:43:46.949+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:43:46.949+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:43:46.956+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:43:46.955+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:43:46.969+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.537 seconds
[2024-05-14T07:43:54.900+0000] {processor.py:161} INFO - Started process (PID=715) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:43:54.901+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:43:54.904+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:43:54.903+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:43:55.230+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:43:55.235+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:43:55.235+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:43:55.240+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:43:55.240+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:43:55.254+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.364 seconds
[2024-05-14T07:43:56.968+0000] {processor.py:161} INFO - Started process (PID=719) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:43:56.970+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:43:56.974+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:43:56.973+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:43:57.359+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:43:57.367+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:43:57.367+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:43:57.381+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:43:57.381+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:43:57.391+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.436 seconds
[2024-05-14T07:44:00.461+0000] {processor.py:161} INFO - Started process (PID=723) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:44:00.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:44:00.468+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:44:00.467+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:44:00.857+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:44:00.863+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:44:00.862+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:44:00.876+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:44:00.876+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:44:00.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.443 seconds
[2024-05-14T07:44:31.294+0000] {processor.py:161} INFO - Started process (PID=733) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:44:31.296+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:44:31.299+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:44:31.298+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:44:31.787+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:44:31.835+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:44:31.835+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:44:31.839+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:44:31.839+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:44:31.846+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.565 seconds
[2024-05-14T07:45:02.169+0000] {processor.py:161} INFO - Started process (PID=743) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:45:02.172+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:45:02.178+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:45:02.177+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:45:02.610+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:45:02.623+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:45:02.622+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:45:02.629+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:45:02.629+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:45:02.637+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.486 seconds
[2024-05-14T07:45:21.852+0000] {processor.py:161} INFO - Started process (PID=753) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:45:21.853+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:45:21.855+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:45:21.854+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:45:22.244+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:45:22.252+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:45:22.252+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:45:22.258+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:45:22.258+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:45:22.268+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.422 seconds
[2024-05-14T07:45:28.369+0000] {processor.py:161} INFO - Started process (PID=757) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:45:28.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:45:28.372+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:45:28.372+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:45:28.718+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:45:28.723+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:45:28.723+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:45:28.728+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:45:28.728+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:45:28.735+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.375 seconds
[2024-05-14T07:45:59.044+0000] {processor.py:161} INFO - Started process (PID=767) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:45:59.047+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:45:59.052+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:45:59.051+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:45:59.538+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:45:59.585+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:45:59.585+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:45:59.590+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:45:59.590+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:45:59.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.567 seconds
[2024-05-14T07:46:29.952+0000] {processor.py:161} INFO - Started process (PID=777) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:46:29.955+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:46:29.959+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:46:29.959+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:46:30.392+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:46:30.406+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:46:30.406+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:46:30.413+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:46:30.413+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:46:30.421+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.480 seconds
[2024-05-14T07:46:36.545+0000] {processor.py:161} INFO - Started process (PID=781) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:46:36.547+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:46:36.551+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:46:36.550+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:46:37.003+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:46:37.009+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:46:37.009+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:46:37.024+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:46:37.023+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:46:37.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.503 seconds
[2024-05-14T07:46:47.163+0000] {processor.py:161} INFO - Started process (PID=790) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:46:47.165+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:46:47.169+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:46:47.168+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:46:47.578+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:46:47.588+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:46:47.588+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:46:47.602+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:46:47.602+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:46:47.611+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.459 seconds
[2024-05-14T07:47:17.918+0000] {processor.py:161} INFO - Started process (PID=800) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:47:17.920+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:47:17.924+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:47:17.923+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:47:18.531+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:47:18.592+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:47:18.591+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:47:18.596+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:47:18.596+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:47:18.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.700 seconds
[2024-05-14T07:47:48.903+0000] {processor.py:161} INFO - Started process (PID=809) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:47:48.907+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:47:48.912+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:47:48.911+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:47:49.414+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:47:49.426+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:47:49.426+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:47:49.434+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:47:49.434+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:47:49.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.553 seconds
[2024-05-14T07:48:19.812+0000] {processor.py:161} INFO - Started process (PID=818) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:48:19.813+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:48:19.817+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:48:19.816+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:48:20.218+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:48:20.266+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:48:20.266+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:48:20.270+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:48:20.270+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:48:20.277+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.479 seconds
[2024-05-14T07:48:27.385+0000] {processor.py:161} INFO - Started process (PID=822) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:48:27.388+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:48:27.392+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:48:27.392+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:48:27.722+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:48:27.728+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:48:27.728+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:48:27.733+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:48:27.733+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:48:27.741+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.369 seconds
[2024-05-14T07:48:32.818+0000] {processor.py:161} INFO - Started process (PID=826) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:48:32.824+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:48:32.838+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:48:32.834+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:48:33.362+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:48:33.371+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:48:33.370+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:48:33.378+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:48:33.378+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:48:33.398+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.586 seconds
[2024-05-14T07:49:03.726+0000] {processor.py:161} INFO - Started process (PID=836) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:49:03.731+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:49:03.736+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:49:03.736+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:49:04.253+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:49:04.271+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:49:04.270+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:49:04.280+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:49:04.280+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:49:04.295+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.580 seconds
[2024-05-14T07:49:34.778+0000] {processor.py:161} INFO - Started process (PID=846) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:49:34.780+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:49:34.786+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:49:34.785+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:49:35.331+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:49:35.388+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:49:35.388+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:49:35.392+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:49:35.392+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:49:35.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.636 seconds
[2024-05-14T07:50:05.756+0000] {processor.py:161} INFO - Started process (PID=856) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:50:05.758+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:50:05.767+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:50:05.766+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:50:06.235+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:50:06.250+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:50:06.250+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:50:06.256+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:50:06.255+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:50:06.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.524 seconds
[2024-05-14T07:50:36.587+0000] {processor.py:161} INFO - Started process (PID=866) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:50:36.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:50:36.594+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:50:36.593+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:50:37.082+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:50:37.139+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:50:37.139+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:50:37.143+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:50:37.143+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:50:37.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.580 seconds
[2024-05-14T07:51:07.445+0000] {processor.py:161} INFO - Started process (PID=876) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:51:07.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:51:07.452+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:51:07.451+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:51:07.874+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:51:07.889+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:51:07.889+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:51:07.895+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:51:07.895+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:51:07.904+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.474 seconds
[2024-05-14T07:51:38.223+0000] {processor.py:161} INFO - Started process (PID=886) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:51:38.226+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:51:38.230+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:51:38.230+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:51:38.669+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:51:38.720+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:51:38.719+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:51:38.724+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:51:38.724+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:51:38.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.525 seconds
[2024-05-14T07:52:09.057+0000] {processor.py:161} INFO - Started process (PID=896) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:52:09.058+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:52:09.062+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:52:09.061+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:52:09.499+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:52:09.513+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:52:09.513+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:52:09.520+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:52:09.520+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:52:09.529+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.485 seconds
[2024-05-14T07:52:39.936+0000] {processor.py:161} INFO - Started process (PID=906) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:52:39.975+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:52:39.985+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:52:39.984+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:52:40.431+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:52:40.484+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:52:40.484+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:52:40.488+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:52:40.488+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:52:40.499+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.578 seconds
[2024-05-14T07:53:10.810+0000] {processor.py:161} INFO - Started process (PID=916) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:53:10.813+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:53:10.817+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:53:10.816+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:53:11.332+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:53:11.346+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:53:11.346+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:53:11.352+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:53:11.352+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:53:11.360+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.565 seconds
[2024-05-14T07:53:41.719+0000] {processor.py:161} INFO - Started process (PID=932) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:53:41.723+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:53:41.727+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:53:41.726+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:53:42.190+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:53:42.241+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:53:42.241+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:53:42.245+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:53:42.245+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:53:42.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.546 seconds
[2024-05-14T07:54:12.564+0000] {processor.py:161} INFO - Started process (PID=942) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:54:12.565+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:54:12.568+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:54:12.567+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:54:13.086+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:54:13.102+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:54:13.102+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:54:13.109+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:54:13.109+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:54:13.118+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.570 seconds
[2024-05-14T07:54:43.446+0000] {processor.py:161} INFO - Started process (PID=952) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:54:43.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:54:43.452+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:54:43.451+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:54:43.960+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:54:44.022+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:54:44.022+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:54:44.029+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:54:44.028+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:54:44.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.604 seconds
[2024-05-14T07:55:14.355+0000] {processor.py:161} INFO - Started process (PID=962) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:55:14.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:55:14.362+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:55:14.361+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:55:14.782+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:55:14.795+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:55:14.795+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:55:14.802+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:55:14.802+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:55:14.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.467 seconds
[2024-05-14T07:55:45.183+0000] {processor.py:161} INFO - Started process (PID=972) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:55:45.185+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:55:45.190+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:55:45.189+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:55:45.791+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:55:45.848+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:55:45.848+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:55:45.852+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:55:45.852+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:55:45.860+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.717 seconds
[2024-05-14T07:56:16.186+0000] {processor.py:161} INFO - Started process (PID=982) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:56:16.188+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:56:16.192+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:56:16.192+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:56:16.623+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:56:16.636+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:56:16.636+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:56:16.642+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:56:16.642+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:56:16.650+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.475 seconds
[2024-05-14T07:56:46.990+0000] {processor.py:161} INFO - Started process (PID=992) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:56:46.992+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:56:46.996+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:56:46.995+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:56:47.460+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:56:47.527+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:56:47.526+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:56:47.531+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:56:47.531+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:56:47.538+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.558 seconds
[2024-05-14T07:57:17.848+0000] {processor.py:161} INFO - Started process (PID=1002) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:57:17.850+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:57:17.853+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:57:17.852+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:57:18.290+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:57:18.305+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:57:18.305+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:57:18.313+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:57:18.312+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:57:18.325+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.488 seconds
[2024-05-14T07:57:48.653+0000] {processor.py:161} INFO - Started process (PID=1012) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:57:48.655+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:57:48.659+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:57:48.658+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:57:49.073+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:57:49.147+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:57:49.146+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:57:49.151+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:57:49.151+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:57:49.159+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.518 seconds
[2024-05-14T07:58:19.448+0000] {processor.py:161} INFO - Started process (PID=1021) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:58:19.450+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:58:19.454+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:58:19.453+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:58:19.900+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:58:19.921+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:58:19.921+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:58:19.929+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:58:19.928+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:58:19.937+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.505 seconds
[2024-05-14T07:58:50.298+0000] {processor.py:161} INFO - Started process (PID=1031) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:58:50.300+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:58:50.304+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:58:50.303+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:58:50.721+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:58:50.782+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:58:50.782+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:58:50.786+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:58:50.786+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:58:50.794+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.512 seconds
[2024-05-14T07:59:21.171+0000] {processor.py:161} INFO - Started process (PID=1041) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:59:21.190+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:59:21.206+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:59:21.206+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:59:22.051+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:59:22.077+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:59:22.076+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:59:22.086+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:59:22.086+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:59:22.100+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.967 seconds
[2024-05-14T07:59:54.609+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:59:54.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T07:59:54.617+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:59:54.617+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:59:56.272+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T07:59:56.447+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:59:56.446+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:59:56.473+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:59:56.473+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T07:59:56.979+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:59:56.956+0000] {dagbag.py:654} ERROR - Failed to write serialized DAG: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 642, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 158, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(data_pipeline_jobs104) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'data_pipeline_jobs104', 'fileloc': '/opt/airflow/dags/data_pipeline_jobs104.py', 'fileloc_hash': 67140776701959873, 'data': '{"__version": 1, "dag": {"start_date": 1714521600.0, "timezone": "UTC", "fileloc": "/opt/airflow/dags/data_pipeline_jobs104.py", "edge_info": {}, "_t ... (3530 characters truncated) ... onOperator", "_task_module": "airflow.operators.python", "_is_empty": false, "op_args": [], "op_kwargs": {}}], "dag_dependencies": [], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2024, 5, 14, 7, 59, 56, 290714, tzinfo=Timezone('UTC')), 'dag_hash': '7d9c1860cce936f7c19513af9ecdf61f', 'processor_subdir': '/opt/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-05-14T07:59:56.985+0000] {logging_mixin.py:188} INFO - [2024-05-14T07:59:56.984+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T07:59:56.999+0000] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 859, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 895, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 664, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 314, in iter
    return fut.result()
           ^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 680, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3108, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(data_pipeline_jobs104) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'data_pipeline_jobs104', 'fileloc': '/opt/airflow/dags/data_pipeline_jobs104.py', 'fileloc_hash': 67140776701959873, 'data': '{"__version": 1, "dag": {"start_date": 1714521600.0, "timezone": "UTC", "fileloc": "/opt/airflow/dags/data_pipeline_jobs104.py", "edge_info": {}, "_t ... (3530 characters truncated) ... onOperator", "_task_module": "airflow.operators.python", "_is_empty": false, "op_args": [], "op_kwargs": {}}], "dag_dependencies": [], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2024, 5, 14, 7, 59, 56, 290714, tzinfo=Timezone('UTC')), 'dag_hash': '7d9c1860cce936f7c19513af9ecdf61f', 'processor_subdir': '/opt/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-05-14T08:00:27.221+0000] {processor.py:161} INFO - Started process (PID=43) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:00:27.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:00:27.224+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:00:27.224+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:00:27.668+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:00:27.718+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:00:27.717+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:00:27.722+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:00:27.722+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:00:27.729+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.511 seconds
[2024-05-14T08:00:57.922+0000] {processor.py:161} INFO - Started process (PID=51) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:00:57.926+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:00:57.935+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:00:57.934+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:00:58.533+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:00:58.558+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:00:58.558+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:00:58.565+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:00:58.565+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:00:58.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.674 seconds
[2024-05-14T08:01:28.919+0000] {processor.py:161} INFO - Started process (PID=61) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:01:28.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:01:28.927+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:01:28.926+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:01:29.340+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:01:29.412+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:01:29.411+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:01:29.416+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:01:29.416+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:01:29.424+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.518 seconds
[2024-05-14T08:01:45.571+0000] {processor.py:161} INFO - Started process (PID=71) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:01:45.573+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:01:45.576+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:01:45.576+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:01:45.971+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:01:45.976+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:01:45.976+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:01:45.986+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:01:45.986+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:01:45.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.428 seconds
[2024-05-14T08:01:47.038+0000] {processor.py:161} INFO - Started process (PID=75) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:01:47.039+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:01:47.041+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:01:47.041+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:01:47.381+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:01:47.387+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:01:47.386+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:01:47.397+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:01:47.397+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:01:47.406+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.377 seconds
[2024-05-14T08:02:17.773+0000] {processor.py:161} INFO - Started process (PID=85) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:02:17.776+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:02:17.779+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:02:17.778+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:02:18.255+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:02:18.269+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:02:18.268+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:02:18.278+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:02:18.278+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:02:18.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.523 seconds
[2024-05-14T08:02:48.610+0000] {processor.py:161} INFO - Started process (PID=95) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:02:48.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:02:48.618+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:02:48.618+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:02:49.129+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:02:49.186+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:02:49.186+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:02:49.190+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:02:49.190+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:02:49.201+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.603 seconds
[2024-05-14T08:03:19.506+0000] {processor.py:161} INFO - Started process (PID=105) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:03:19.508+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:03:19.510+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:03:19.510+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:03:20.044+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:03:20.060+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:03:20.060+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:03:20.067+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:03:20.067+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:03:20.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.577 seconds
[2024-05-14T08:03:50.410+0000] {processor.py:161} INFO - Started process (PID=115) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:03:50.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:03:50.417+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:03:50.416+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:03:50.831+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:03:50.882+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:03:50.882+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:03:50.886+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:03:50.886+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:03:50.895+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.494 seconds
[2024-05-14T08:04:21.190+0000] {processor.py:161} INFO - Started process (PID=125) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:04:21.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:04:21.195+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:04:21.195+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:04:21.655+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:04:21.670+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:04:21.670+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:04:21.676+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:04:21.676+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:04:21.684+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.507 seconds
[2024-05-14T08:04:52.025+0000] {processor.py:161} INFO - Started process (PID=135) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:04:52.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:04:52.031+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:04:52.030+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:04:52.456+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:04:52.508+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:04:52.508+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:04:52.513+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:04:52.513+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:04:52.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.507 seconds
[2024-05-14T08:05:22.864+0000] {processor.py:161} INFO - Started process (PID=144) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:05:22.865+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:05:22.868+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:05:22.868+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:05:23.445+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:05:23.460+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:05:23.460+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:05:23.467+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:05:23.467+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:05:23.477+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.621 seconds
[2024-05-14T08:05:53.840+0000] {processor.py:161} INFO - Started process (PID=154) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:05:53.844+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:05:53.847+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:05:53.846+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:05:54.410+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:05:54.547+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:05:54.547+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:05:54.557+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:05:54.557+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:05:54.571+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.743 seconds
[2024-05-14T08:06:24.884+0000] {processor.py:161} INFO - Started process (PID=164) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:06:24.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:06:24.891+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:06:24.890+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:06:25.339+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:06:25.356+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:06:25.356+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:06:25.363+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:06:25.363+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:06:25.371+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.503 seconds
[2024-05-14T08:06:55.753+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:06:55.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:06:55.757+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:06:55.757+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:06:56.188+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:06:56.238+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:06:56.238+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:06:56.242+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:06:56.242+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:06:56.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.505 seconds
[2024-05-14T08:07:50.953+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:07:50.955+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:07:50.959+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:07:50.958+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:07:52.681+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:07:52.889+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:07:52.889+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:07:52.899+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:07:52.899+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:07:52.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 1.967 seconds
[2024-05-14T08:08:23.228+0000] {processor.py:161} INFO - Started process (PID=40) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:08:23.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:08:23.232+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:08:23.231+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:08:23.969+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:08:23.986+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:08:23.986+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:08:23.993+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:08:23.993+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:08:24.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.780 seconds
[2024-05-14T08:08:54.345+0000] {processor.py:161} INFO - Started process (PID=50) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:08:54.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:08:54.351+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:08:54.351+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:08:54.803+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:08:54.852+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:08:54.851+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:08:54.856+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:08:54.855+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:08:54.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.531 seconds
[2024-05-14T08:09:25.240+0000] {processor.py:161} INFO - Started process (PID=60) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:09:25.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:09:25.247+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:09:25.246+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:09:25.683+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:09:25.708+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:09:25.708+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:09:25.713+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:09:25.713+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:09:25.722+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.492 seconds
[2024-05-14T08:09:56.090+0000] {processor.py:161} INFO - Started process (PID=70) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:09:56.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:09:56.098+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:09:56.098+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:09:56.578+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:09:56.645+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:09:56.645+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:09:56.649+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:09:56.649+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:09:56.656+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.603 seconds
[2024-05-14T08:10:26.946+0000] {processor.py:161} INFO - Started process (PID=80) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:10:26.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:10:26.950+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:10:26.949+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:10:27.416+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:10:27.440+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:10:27.439+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:10:27.447+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:10:27.447+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:10:27.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.517 seconds
[2024-05-14T08:10:57.802+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:10:57.804+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:10:57.808+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:10:57.807+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:10:58.187+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:10:58.235+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:10:58.235+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:10:58.239+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:10:58.239+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:10:58.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.456 seconds
[2024-05-14T08:11:28.587+0000] {processor.py:161} INFO - Started process (PID=100) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:11:28.590+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:11:28.593+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:11:28.593+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:11:28.974+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:11:28.986+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:11:28.986+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:11:28.993+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:11:28.993+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:11:29.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.425 seconds
[2024-05-14T08:11:59.353+0000] {processor.py:161} INFO - Started process (PID=110) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:11:59.356+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:11:59.359+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:11:59.359+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:11:59.741+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:11:59.788+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:11:59.788+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:11:59.794+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:11:59.794+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:11:59.801+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.457 seconds
[2024-05-14T08:12:30.076+0000] {processor.py:161} INFO - Started process (PID=120) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:12:30.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:12:30.082+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:12:30.081+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:12:30.470+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:12:30.487+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:12:30.486+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:12:30.492+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:12:30.492+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:12:30.500+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.434 seconds
[2024-05-14T08:13:03.463+0000] {processor.py:161} INFO - Started process (PID=30) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:13:03.464+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:13:03.467+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:13:03.466+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:13:04.909+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:13:05.061+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:13:05.060+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:13:05.081+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:13:05.080+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:13:05.114+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:13:05.112+0000] {dagbag.py:654} ERROR - Failed to write serialized DAG: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 642, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 158, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(data_pipeline_jobs104) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'data_pipeline_jobs104', 'fileloc': '/opt/airflow/dags/data_pipeline_jobs104.py', 'fileloc_hash': 67140776701959873, 'data': '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "fileloc": "/opt/airflow/dags/data_pipeline_jobs104.py", "_task_group": {"_group_id": nu ... (3530 characters truncated) ... onOperator", "_task_module": "airflow.operators.python", "_is_empty": false, "op_args": [], "op_kwargs": {}}], "dag_dependencies": [], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2024, 5, 14, 8, 13, 4, 929601, tzinfo=Timezone('UTC')), 'dag_hash': '7d9c1860cce936f7c19513af9ecdf61f', 'processor_subdir': '/opt/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-05-14T08:13:05.114+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:13:05.114+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:13:05.115+0000] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 859, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 895, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 664, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 314, in iter
    return fut.result()
           ^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 680, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3108, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(data_pipeline_jobs104) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'data_pipeline_jobs104', 'fileloc': '/opt/airflow/dags/data_pipeline_jobs104.py', 'fileloc_hash': 67140776701959873, 'data': '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "fileloc": "/opt/airflow/dags/data_pipeline_jobs104.py", "_task_group": {"_group_id": nu ... (3530 characters truncated) ... onOperator", "_task_module": "airflow.operators.python", "_is_empty": false, "op_args": [], "op_kwargs": {}}], "dag_dependencies": [], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2024, 5, 14, 8, 13, 4, 929601, tzinfo=Timezone('UTC')), 'dag_hash': '7d9c1860cce936f7c19513af9ecdf61f', 'processor_subdir': '/opt/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-05-14T08:13:35.426+0000] {processor.py:161} INFO - Started process (PID=40) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:13:35.428+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:13:35.441+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:13:35.438+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:13:36.002+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:13:36.053+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:13:36.052+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:13:36.057+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:13:36.057+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:13:36.064+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.652 seconds
[2024-05-14T08:14:06.367+0000] {processor.py:161} INFO - Started process (PID=49) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:14:06.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:14:06.373+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:14:06.373+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:14:06.764+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:14:06.779+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:14:06.777+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:14:06.784+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:14:06.784+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:14:06.793+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.437 seconds
[2024-05-14T08:14:37.127+0000] {processor.py:161} INFO - Started process (PID=59) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:14:37.130+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:14:37.134+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:14:37.133+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:14:37.563+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:14:37.626+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:14:37.626+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:14:37.631+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:14:37.631+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:14:37.638+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.525 seconds
[2024-05-14T08:15:07.937+0000] {processor.py:161} INFO - Started process (PID=68) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:15:07.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:15:07.942+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:15:07.941+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:15:08.340+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:15:08.353+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:15:08.353+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:15:08.360+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:15:08.359+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:15:08.370+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.442 seconds
[2024-05-14T08:15:38.756+0000] {processor.py:161} INFO - Started process (PID=78) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:15:38.758+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:15:38.761+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:15:38.761+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:15:39.288+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:15:39.339+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:15:39.338+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:15:39.343+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:15:39.342+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:15:39.350+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.608 seconds
[2024-05-14T08:16:09.646+0000] {processor.py:161} INFO - Started process (PID=88) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:16:09.649+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:16:09.653+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:16:09.653+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:16:10.337+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:16:10.364+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:16:10.364+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:16:10.371+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:16:10.371+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:16:10.381+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.743 seconds
[2024-05-14T08:16:40.792+0000] {processor.py:161} INFO - Started process (PID=98) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:16:40.795+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:16:40.806+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:16:40.803+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:16:41.212+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:16:41.261+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:16:41.261+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:16:41.266+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:16:41.266+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:16:41.274+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.494 seconds
[2024-05-14T08:17:11.603+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:17:11.605+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:17:11.609+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:17:11.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:17:12.048+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:17:12.061+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:17:12.060+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:17:12.067+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:17:12.066+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:17:12.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.480 seconds
[2024-05-14T08:17:42.423+0000] {processor.py:161} INFO - Started process (PID=117) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:17:42.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:17:42.429+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:17:42.429+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:17:42.812+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:17:42.862+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:17:42.861+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:17:42.866+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:17:42.866+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:17:42.874+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.459 seconds
[2024-05-14T08:18:13.235+0000] {processor.py:161} INFO - Started process (PID=127) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:18:13.238+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:18:13.242+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:18:13.241+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:18:13.640+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:18:13.653+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:18:13.652+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:18:13.659+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:18:13.659+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:18:13.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.443 seconds
[2024-05-14T08:18:43.968+0000] {processor.py:161} INFO - Started process (PID=137) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:18:43.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:18:43.976+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:18:43.976+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:18:44.380+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:18:44.426+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:18:44.425+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:18:44.430+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:18:44.429+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:18:44.437+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.480 seconds
[2024-05-14T08:19:14.703+0000] {processor.py:161} INFO - Started process (PID=147) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:19:14.704+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:19:14.707+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:19:14.707+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:19:15.113+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:19:15.127+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:19:15.127+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:19:15.133+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:19:15.133+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:19:15.143+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.450 seconds
[2024-05-14T08:19:45.409+0000] {processor.py:161} INFO - Started process (PID=156) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:19:45.412+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:19:45.415+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:19:45.414+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:19:46.024+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:19:46.097+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:19:46.097+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:19:46.104+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:19:46.104+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:19:46.116+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.715 seconds
[2024-05-14T08:20:16.409+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:20:16.412+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:20:16.416+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:20:16.416+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:20:17.009+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:20:17.029+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:20:17.028+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:20:17.037+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:20:17.037+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:20:17.052+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.652 seconds
[2024-05-14T08:20:47.432+0000] {processor.py:161} INFO - Started process (PID=177) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:20:47.435+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:20:47.439+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:20:47.439+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:20:47.942+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:20:47.999+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:20:47.999+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:20:48.004+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:20:48.004+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:20:48.013+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.601 seconds
[2024-05-14T08:21:18.324+0000] {processor.py:161} INFO - Started process (PID=187) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:21:18.330+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:21:18.338+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:21:18.337+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:21:18.961+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:21:18.982+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:21:18.981+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:21:18.990+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:21:18.990+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:21:19.000+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.692 seconds
[2024-05-14T08:21:49.325+0000] {processor.py:161} INFO - Started process (PID=197) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:21:49.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:21:49.330+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:21:49.329+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:21:50.208+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:21:50.395+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:21:50.394+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:21:50.402+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:21:50.402+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:21:50.422+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 1.126 seconds
[2024-05-14T08:22:20.660+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:22:20.667+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:22:20.678+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:22:20.678+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:22:21.239+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:22:21.260+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:22:21.259+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:22:21.267+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:22:21.267+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:22:21.293+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.643 seconds
[2024-05-14T08:22:51.662+0000] {processor.py:161} INFO - Started process (PID=217) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:22:51.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:22:51.695+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:22:51.693+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:22:52.860+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:22:52.969+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:22:52.968+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:22:52.974+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:22:52.974+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:22:52.983+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 1.452 seconds
[2024-05-14T08:28:52.538+0000] {processor.py:161} INFO - Started process (PID=226) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:28:52.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:28:52.545+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:28:52.544+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:28:53.062+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:28:53.081+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:28:53.080+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:28:53.086+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:28:53.086+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:28:53.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.654 seconds
[2024-05-14T08:29:23.471+0000] {processor.py:161} INFO - Started process (PID=236) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:29:23.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:29:23.481+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:29:23.480+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:29:23.956+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:29:24.019+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:29:24.019+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:29:24.025+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:29:24.025+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:29:24.032+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.571 seconds
[2024-05-14T08:29:54.307+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:29:54.309+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:29:54.314+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:29:54.313+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:29:54.729+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:29:54.743+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:29:54.743+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:29:54.750+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:29:54.749+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:29:54.763+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.469 seconds
[2024-05-14T08:30:25.045+0000] {processor.py:161} INFO - Started process (PID=255) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:30:25.047+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:30:25.049+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:30:25.049+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:30:25.399+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:30:25.442+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:30:25.442+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:30:25.446+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:30:25.446+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:30:25.454+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.419 seconds
[2024-05-14T08:30:55.730+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:30:55.732+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:30:55.733+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:30:55.733+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:30:56.038+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:30:56.049+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:30:56.048+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:30:56.053+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:30:56.053+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:30:56.062+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.339 seconds
[2024-05-14T08:31:26.350+0000] {processor.py:161} INFO - Started process (PID=275) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:31:26.351+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:31:26.354+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:31:26.353+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:31:26.669+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:31:26.711+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:31:26.710+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:31:26.715+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:31:26.715+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:31:26.722+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.380 seconds
[2024-05-14T08:31:56.979+0000] {processor.py:161} INFO - Started process (PID=285) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:31:56.980+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:31:56.984+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:31:56.983+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:31:57.422+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:31:57.442+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:31:57.441+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:31:57.449+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:31:57.449+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:31:57.461+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.492 seconds
[2024-05-14T08:32:27.728+0000] {processor.py:161} INFO - Started process (PID=295) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:32:27.729+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:32:27.730+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:32:27.730+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:32:28.047+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:32:28.091+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:32:28.091+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:32:28.095+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:32:28.095+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:32:28.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.380 seconds
[2024-05-14T08:32:58.357+0000] {processor.py:161} INFO - Started process (PID=305) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:32:58.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:32:58.359+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:32:58.359+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:32:58.669+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:32:58.680+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:32:58.680+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:32:58.685+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:32:58.685+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:32:58.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.342 seconds
[2024-05-14T08:33:28.975+0000] {processor.py:161} INFO - Started process (PID=315) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:33:28.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:33:28.977+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:33:28.977+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:33:29.336+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:33:29.378+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:33:29.378+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:33:29.382+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:33:29.382+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:33:29.390+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.419 seconds
[2024-05-14T08:33:59.691+0000] {processor.py:161} INFO - Started process (PID=325) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:33:59.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:33:59.693+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:33:59.693+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:34:00.071+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:34:00.082+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:34:00.082+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:34:00.087+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:34:00.087+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:34:00.095+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.413 seconds
[2024-05-14T08:34:30.368+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:34:30.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:34:30.371+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:34:30.371+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:34:30.676+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:34:30.719+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:34:30.718+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:34:30.723+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:34:30.723+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:34:30.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.367 seconds
[2024-05-14T08:35:00.930+0000] {processor.py:161} INFO - Started process (PID=345) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:35:00.931+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:35:00.932+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:35:00.932+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:35:01.318+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:35:01.329+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:35:01.329+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:35:01.334+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:35:01.334+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:35:01.342+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.417 seconds
[2024-05-14T08:35:31.639+0000] {processor.py:161} INFO - Started process (PID=355) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:35:31.640+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:35:31.642+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:35:31.642+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:35:32.021+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:35:32.069+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:35:32.069+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:35:32.074+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:35:32.074+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:35:32.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.448 seconds
[2024-05-14T08:36:02.333+0000] {processor.py:161} INFO - Started process (PID=364) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:36:02.333+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:36:02.334+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:36:02.334+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:36:02.684+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:36:02.696+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:36:02.696+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:36:02.702+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:36:02.702+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:36:02.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.384 seconds
[2024-05-14T08:36:33.048+0000] {processor.py:161} INFO - Started process (PID=374) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:36:33.049+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:36:33.053+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:36:33.052+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:36:33.453+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:36:33.516+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:36:33.516+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:36:33.521+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:36:33.521+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:36:33.529+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.487 seconds
[2024-05-14T08:37:03.790+0000] {processor.py:161} INFO - Started process (PID=383) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:37:03.793+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:37:03.796+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:37:03.795+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:37:04.142+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:37:04.153+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:37:04.153+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:37:04.159+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:37:04.159+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:37:04.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.392 seconds
[2024-05-14T08:37:34.453+0000] {processor.py:161} INFO - Started process (PID=393) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:37:34.455+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:37:34.458+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:37:34.457+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:37:34.801+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:37:34.844+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:37:34.844+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:37:34.849+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:37:34.849+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:37:34.856+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.412 seconds
[2024-05-14T08:38:05.059+0000] {processor.py:161} INFO - Started process (PID=409) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:38:05.060+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:38:05.062+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:38:05.062+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:38:05.459+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:38:05.475+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:38:05.474+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:38:05.481+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:38:05.481+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:38:05.490+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.436 seconds
[2024-05-14T08:38:35.818+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:38:35.819+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:38:35.820+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:38:35.820+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:38:36.268+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:38:36.326+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:38:36.326+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:38:36.332+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:38:36.331+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:38:36.344+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.530 seconds
[2024-05-14T08:39:06.664+0000] {processor.py:161} INFO - Started process (PID=429) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:39:06.664+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:39:06.665+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:39:06.665+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:39:07.003+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:39:07.015+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:39:07.015+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:39:07.020+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:39:07.020+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:39:07.028+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.369 seconds
[2024-05-14T08:39:37.323+0000] {processor.py:161} INFO - Started process (PID=439) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:39:37.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:39:37.327+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:39:37.327+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:39:37.657+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:39:37.704+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:39:37.704+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:39:37.708+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:39:37.708+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:39:37.718+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.402 seconds
[2024-05-14T08:40:08.294+0000] {processor.py:161} INFO - Started process (PID=449) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:40:08.297+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:40:08.301+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:40:08.301+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:40:08.745+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:40:08.757+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:40:08.757+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:40:08.765+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:40:08.765+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:40:08.773+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.493 seconds
[2024-05-14T08:40:39.082+0000] {processor.py:161} INFO - Started process (PID=459) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:40:39.083+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:40:39.085+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:40:39.085+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:40:39.421+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:40:39.479+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:40:39.479+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:40:39.483+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:40:39.483+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:40:39.490+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.414 seconds
[2024-05-14T08:41:09.813+0000] {processor.py:161} INFO - Started process (PID=469) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:41:09.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:41:09.817+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:41:09.816+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:41:10.247+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:41:10.263+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:41:10.263+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:41:10.269+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:41:10.269+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:41:10.278+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.474 seconds
[2024-05-14T08:41:40.595+0000] {processor.py:161} INFO - Started process (PID=479) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:41:40.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:41:40.598+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:41:40.597+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:41:40.948+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:41:40.995+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:41:40.995+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:41:40.999+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:41:40.999+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:41:41.006+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.419 seconds
[2024-05-14T08:42:11.285+0000] {processor.py:161} INFO - Started process (PID=489) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:42:11.286+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:42:11.288+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:42:11.288+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:42:11.651+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:42:11.662+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:42:11.662+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:42:11.667+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:42:11.667+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:42:11.676+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.403 seconds
[2024-05-14T08:42:41.981+0000] {processor.py:161} INFO - Started process (PID=498) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:42:41.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:42:41.987+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:42:41.986+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:42:42.410+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:42:42.458+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:42:42.458+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:42:42.462+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:42:42.462+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:42:42.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.501 seconds
[2024-05-14T08:43:12.753+0000] {processor.py:161} INFO - Started process (PID=508) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:43:12.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:43:12.758+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:43:12.758+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:43:13.140+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:43:13.152+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:43:13.152+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:43:13.160+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:43:13.160+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:43:13.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.428 seconds
[2024-05-14T08:43:43.430+0000] {processor.py:161} INFO - Started process (PID=518) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:43:43.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:43:43.434+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:43:43.434+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:43:43.858+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:43:43.908+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:43:43.908+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:43:43.912+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:43:43.912+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:43:43.920+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.498 seconds
[2024-05-14T08:44:14.219+0000] {processor.py:161} INFO - Started process (PID=528) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:44:14.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:44:14.224+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:44:14.223+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:44:14.617+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:44:14.632+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:44:14.632+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:44:14.638+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:44:14.638+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:44:14.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.441 seconds
[2024-05-14T08:44:44.931+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:44:44.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:44:44.935+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:44:44.935+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:44:45.299+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:44:45.355+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:44:45.355+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:44:45.361+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:44:45.361+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:44:45.370+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.449 seconds
[2024-05-14T08:45:15.630+0000] {processor.py:161} INFO - Started process (PID=548) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:45:15.632+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:45:15.636+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:45:15.635+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:45:16.011+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:45:16.022+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:45:16.021+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:45:16.026+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:45:16.026+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:45:16.034+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.415 seconds
[2024-05-14T08:45:46.301+0000] {processor.py:161} INFO - Started process (PID=558) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:45:46.303+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:45:46.304+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:45:46.304+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:45:46.720+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:45:46.776+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:45:46.776+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:45:46.782+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:45:46.782+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:45:46.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.497 seconds
[2024-05-14T08:46:17.094+0000] {processor.py:161} INFO - Started process (PID=567) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:46:17.096+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:46:17.098+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:46:17.097+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:46:17.485+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:46:17.496+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:46:17.496+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:46:17.503+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:46:17.502+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:46:17.511+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.428 seconds
[2024-05-14T08:46:47.801+0000] {processor.py:161} INFO - Started process (PID=577) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:46:47.803+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:46:47.804+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:46:47.804+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:46:48.185+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:46:48.234+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:46:48.234+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:46:48.238+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:46:48.238+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:46:48.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.452 seconds
[2024-05-14T08:47:18.542+0000] {processor.py:161} INFO - Started process (PID=587) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:47:18.545+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:47:18.549+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:47:18.548+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:47:18.974+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:47:18.988+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:47:18.988+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:47:18.994+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:47:18.994+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:47:19.002+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.472 seconds
[2024-05-14T08:47:49.296+0000] {processor.py:161} INFO - Started process (PID=596) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:47:49.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:47:49.302+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:47:49.302+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:47:49.674+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:47:49.720+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:47:49.719+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:47:49.724+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:47:49.724+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:47:49.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.445 seconds
[2024-05-14T08:48:20.052+0000] {processor.py:161} INFO - Started process (PID=606) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:48:20.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:48:20.055+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:48:20.054+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:48:20.431+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:48:20.444+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:48:20.444+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:48:20.450+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:48:20.450+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:48:20.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.416 seconds
[2024-05-14T08:48:59.978+0000] {processor.py:161} INFO - Started process (PID=30) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:48:59.982+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:48:59.986+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:48:59.985+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:49:01.774+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:49:02.061+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:49:02.061+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:49:02.077+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:49:02.076+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:49:02.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 2.138 seconds
[2024-05-14T08:49:32.474+0000] {processor.py:161} INFO - Started process (PID=40) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:49:32.477+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:49:32.481+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:49:32.480+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:49:32.896+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:49:32.909+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:49:32.909+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:49:32.915+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:49:32.915+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:49:32.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.460 seconds
[2024-05-14T08:50:03.204+0000] {processor.py:161} INFO - Started process (PID=50) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:50:03.206+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:50:03.208+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:50:03.207+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:50:03.650+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:50:03.717+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:50:03.717+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:50:03.724+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:50:03.724+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:50:03.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.537 seconds
[2024-05-14T08:50:34.075+0000] {processor.py:161} INFO - Started process (PID=60) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:50:34.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:50:34.081+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:50:34.080+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:50:34.525+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:50:34.539+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:50:34.539+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:50:34.545+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:50:34.545+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:50:34.555+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.490 seconds
[2024-05-14T08:51:04.897+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:51:04.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:51:04.903+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:51:04.903+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:51:05.529+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:51:05.625+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:51:05.625+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:51:05.632+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:51:05.632+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:51:05.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.754 seconds
[2024-05-14T08:51:35.917+0000] {processor.py:161} INFO - Started process (PID=79) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:51:35.920+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:51:35.925+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:51:35.924+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:51:36.365+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:51:36.378+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:51:36.378+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:51:36.384+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:51:36.384+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:51:36.393+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.487 seconds
[2024-05-14T08:52:06.776+0000] {processor.py:161} INFO - Started process (PID=88) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:52:06.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:52:06.817+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:52:06.816+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:52:07.310+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:52:07.358+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:52:07.358+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:52:07.363+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:52:07.363+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:52:07.372+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.604 seconds
[2024-05-14T08:52:51.523+0000] {processor.py:161} INFO - Started process (PID=30) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:52:51.528+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:52:51.532+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:52:51.531+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:52:53.384+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:52:53.610+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:52:53.609+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:52:53.624+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:52:53.624+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:52:53.642+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 2.126 seconds
[2024-05-14T08:53:24.014+0000] {processor.py:161} INFO - Started process (PID=40) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:53:24.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:53:24.024+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:53:24.024+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:53:24.593+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:53:24.667+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:53:24.667+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:53:24.678+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:53:24.678+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:53:24.703+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.696 seconds
[2024-05-14T08:53:55.020+0000] {processor.py:161} INFO - Started process (PID=49) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:53:55.022+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:53:55.025+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:53:55.024+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:53:55.434+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:53:55.484+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:53:55.484+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:53:55.488+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:53:55.488+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:53:55.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.483 seconds
[2024-05-14T08:54:25.771+0000] {processor.py:161} INFO - Started process (PID=59) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:54:25.773+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:54:25.777+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:54:25.776+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:54:26.163+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:54:26.177+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:54:26.177+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:54:26.183+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:54:26.183+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:54:26.191+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.433 seconds
[2024-05-14T08:54:56.582+0000] {processor.py:161} INFO - Started process (PID=68) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:54:56.584+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:54:56.586+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:54:56.586+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:54:56.981+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:54:57.031+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:54:57.031+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:54:57.037+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:54:57.037+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:54:57.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.469 seconds
[2024-05-14T08:55:27.351+0000] {processor.py:161} INFO - Started process (PID=79) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:55:27.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:55:27.358+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:55:27.357+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:55:27.743+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:55:27.756+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:55:27.756+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:55:27.761+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:55:27.761+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:55:27.769+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.428 seconds
[2024-05-14T08:56:05.881+0000] {processor.py:161} INFO - Started process (PID=30) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:56:05.883+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:56:05.889+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:56:05.888+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:56:07.417+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:56:07.608+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:56:07.607+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:56:07.627+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:56:07.627+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:56:07.974+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:56:07.971+0000] {dagbag.py:654} ERROR - Failed to write serialized DAG: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 642, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 158, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(data_pipeline_jobs104) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'data_pipeline_jobs104', 'fileloc': '/opt/airflow/dags/data_pipeline_jobs104.py', 'fileloc_hash': 67140776701959873, 'data': '{"__version": 1, "dag": {"_dag_id": "data_pipeline_jobs104", "schedule_interval": null, "timezone": "UTC", "edge_info": {}, "_task_group": {"_group_i ... (3530 characters truncated) ... onOperator", "_task_module": "airflow.operators.python", "_is_empty": false, "op_args": [], "op_kwargs": {}}], "dag_dependencies": [], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2024, 5, 14, 8, 56, 7, 449984, tzinfo=Timezone('UTC')), 'dag_hash': '7d9c1860cce936f7c19513af9ecdf61f', 'processor_subdir': '/opt/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-05-14T08:56:07.979+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:56:07.979+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:56:07.980+0000] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 859, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 895, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 664, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 314, in iter
    return fut.result()
           ^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 680, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3108, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(data_pipeline_jobs104) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'data_pipeline_jobs104', 'fileloc': '/opt/airflow/dags/data_pipeline_jobs104.py', 'fileloc_hash': 67140776701959873, 'data': '{"__version": 1, "dag": {"_dag_id": "data_pipeline_jobs104", "schedule_interval": null, "timezone": "UTC", "edge_info": {}, "_task_group": {"_group_i ... (3530 characters truncated) ... onOperator", "_task_module": "airflow.operators.python", "_is_empty": false, "op_args": [], "op_kwargs": {}}], "dag_dependencies": [], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2024, 5, 14, 8, 56, 7, 449984, tzinfo=Timezone('UTC')), 'dag_hash': '7d9c1860cce936f7c19513af9ecdf61f', 'processor_subdir': '/opt/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-05-14T08:56:38.215+0000] {processor.py:161} INFO - Started process (PID=40) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:56:38.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:56:38.219+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:56:38.219+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:56:38.598+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:56:38.649+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:56:38.649+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:56:38.654+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:56:38.654+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:56:38.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.456 seconds
[2024-05-14T08:57:09.003+0000] {processor.py:161} INFO - Started process (PID=50) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:57:09.006+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:57:09.009+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:57:09.009+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:57:09.374+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:57:09.387+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:57:09.386+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:57:09.393+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:57:09.393+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:57:09.406+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.415 seconds
[2024-05-14T08:57:39.721+0000] {processor.py:161} INFO - Started process (PID=60) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:57:39.723+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:57:39.726+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:57:39.725+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:57:40.214+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:57:40.269+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:57:40.269+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:57:40.273+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:57:40.273+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:57:40.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.575 seconds
[2024-05-14T08:58:10.601+0000] {processor.py:161} INFO - Started process (PID=70) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:58:10.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:58:10.606+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:58:10.605+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:58:11.084+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:58:11.099+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:58:11.098+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:58:11.105+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:58:11.105+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:58:11.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.522 seconds
[2024-05-14T08:59:08.318+0000] {processor.py:161} INFO - Started process (PID=30) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:59:08.319+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:59:08.321+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:59:08.321+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:59:10.256+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:59:10.441+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:59:10.441+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:59:10.458+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:59:10.458+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:59:10.675+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:59:10.673+0000] {dagbag.py:654} ERROR - Failed to write serialized DAG: /opt/airflow/dags/data_pipeline_jobs104.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 642, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 158, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(data_pipeline_jobs104) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'data_pipeline_jobs104', 'fileloc': '/opt/airflow/dags/data_pipeline_jobs104.py', 'fileloc_hash': 67140776701959873, 'data': '{"__version": 1, "dag": {"start_date": 1714521600.0, "schedule_interval": null, "edge_info": {}, "_task_group": {"_group_id": null, "prefix_group_id" ... (3530 characters truncated) ... onOperator", "_task_module": "airflow.operators.python", "_is_empty": false, "op_args": [], "op_kwargs": {}}], "dag_dependencies": [], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2024, 5, 14, 8, 59, 10, 281611, tzinfo=Timezone('UTC')), 'dag_hash': '7d9c1860cce936f7c19513af9ecdf61f', 'processor_subdir': '/opt/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-05-14T08:59:10.676+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:59:10.676+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:59:10.677+0000] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 859, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 895, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 664, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 314, in iter
    return fut.result()
           ^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 680, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3108, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(data_pipeline_jobs104) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'data_pipeline_jobs104', 'fileloc': '/opt/airflow/dags/data_pipeline_jobs104.py', 'fileloc_hash': 67140776701959873, 'data': '{"__version": 1, "dag": {"start_date": 1714521600.0, "schedule_interval": null, "edge_info": {}, "_task_group": {"_group_id": null, "prefix_group_id" ... (3530 characters truncated) ... onOperator", "_task_module": "airflow.operators.python", "_is_empty": false, "op_args": [], "op_kwargs": {}}], "dag_dependencies": [], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2024, 5, 14, 8, 59, 10, 281611, tzinfo=Timezone('UTC')), 'dag_hash': '7d9c1860cce936f7c19513af9ecdf61f', 'processor_subdir': '/opt/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-05-14T08:59:40.784+0000] {processor.py:161} INFO - Started process (PID=40) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:59:40.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T08:59:40.789+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:59:40.789+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:59:41.180+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T08:59:41.227+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:59:41.227+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T08:59:41.232+0000] {logging_mixin.py:188} INFO - [2024-05-14T08:59:41.231+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T08:59:41.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.464 seconds
[2024-05-14T09:00:11.530+0000] {processor.py:161} INFO - Started process (PID=49) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:00:11.531+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:00:11.535+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:00:11.534+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:00:11.922+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:00:11.936+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:00:11.935+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:00:11.943+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:00:11.943+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:00:11.957+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.434 seconds
[2024-05-14T09:00:42.244+0000] {processor.py:161} INFO - Started process (PID=59) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:00:42.246+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:00:42.250+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:00:42.250+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:00:42.622+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:00:42.684+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:00:42.683+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:00:42.688+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:00:42.688+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:00:42.696+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.463 seconds
[2024-05-14T09:01:13.047+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:01:13.049+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:01:13.052+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:01:13.051+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:01:13.436+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:01:13.450+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:01:13.449+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:01:13.455+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:01:13.455+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:01:13.463+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.426 seconds
[2024-05-14T09:01:43.664+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:01:43.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:01:43.675+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:01:43.675+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:01:45.206+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:01:45.365+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:01:45.364+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:01:45.373+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:01:45.372+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:01:45.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 1.734 seconds
[2024-05-14T09:02:15.734+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:02:15.735+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:02:15.738+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:02:15.737+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:02:16.454+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:02:16.470+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:02:16.469+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:02:16.477+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:02:16.477+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:02:16.489+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.761 seconds
[2024-05-14T09:02:46.832+0000] {processor.py:161} INFO - Started process (PID=51) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:02:46.833+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:02:46.837+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:02:46.836+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:02:47.256+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:02:47.305+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:02:47.304+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:02:47.309+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:02:47.309+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:02:47.316+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.493 seconds
[2024-05-14T09:03:17.680+0000] {processor.py:161} INFO - Started process (PID=61) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:03:17.682+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:03:17.686+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:03:17.685+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:03:18.099+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:03:18.112+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:03:18.112+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:03:18.119+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:03:18.119+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:03:18.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.471 seconds
[2024-05-14T09:03:48.499+0000] {processor.py:161} INFO - Started process (PID=71) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:03:48.501+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:03:48.505+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:03:48.504+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:03:48.883+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:03:48.930+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:03:48.930+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:03:48.934+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:03:48.934+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:03:48.941+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.453 seconds
[2024-05-14T09:04:19.259+0000] {processor.py:161} INFO - Started process (PID=81) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:04:19.261+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:04:19.264+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:04:19.264+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:04:19.687+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:04:19.702+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:04:19.702+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:04:19.708+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:04:19.708+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:04:19.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.468 seconds
[2024-05-14T09:04:50.052+0000] {processor.py:161} INFO - Started process (PID=91) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:04:50.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:04:50.055+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:04:50.055+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:04:50.448+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:04:50.495+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:04:50.494+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:04:50.499+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:04:50.499+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:04:50.507+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.460 seconds
[2024-05-14T09:05:20.863+0000] {processor.py:161} INFO - Started process (PID=101) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:05:20.864+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:05:20.867+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:05:20.867+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:05:21.247+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:05:21.259+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:05:21.259+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:05:21.265+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:05:21.265+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:05:21.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.421 seconds
[2024-05-14T09:05:51.590+0000] {processor.py:161} INFO - Started process (PID=111) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:05:51.591+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:05:51.594+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:05:51.594+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:05:51.980+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:05:52.030+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:05:52.030+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:05:52.034+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:05:52.034+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:05:52.042+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.463 seconds
[2024-05-14T09:06:22.381+0000] {processor.py:161} INFO - Started process (PID=121) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:06:22.383+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:06:22.387+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:06:22.387+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:06:22.758+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:06:22.771+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:06:22.771+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:06:22.776+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:06:22.776+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:06:22.784+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.415 seconds
[2024-05-14T09:06:53.183+0000] {processor.py:161} INFO - Started process (PID=131) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:06:53.186+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:06:53.189+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:06:53.189+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:06:53.580+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:06:53.630+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:06:53.630+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:06:53.634+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:06:53.634+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:06:53.642+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.469 seconds
[2024-05-14T09:07:23.947+0000] {processor.py:161} INFO - Started process (PID=141) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:07:23.949+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:07:23.951+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:07:23.950+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:07:24.410+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:07:24.424+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:07:24.424+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:07:24.430+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:07:24.430+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:07:24.437+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.496 seconds
[2024-05-14T09:07:54.778+0000] {processor.py:161} INFO - Started process (PID=151) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:07:54.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:07:54.781+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:07:54.781+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:07:55.189+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:07:55.237+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:07:55.237+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:07:55.242+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:07:55.242+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:07:55.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.478 seconds
[2024-05-14T09:08:26.171+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:08:26.173+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:08:26.177+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:08:26.176+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:08:26.706+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:08:26.742+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:08:26.740+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:08:26.776+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:08:26.775+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:08:26.794+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.633 seconds
[2024-05-14T09:08:57.219+0000] {processor.py:161} INFO - Started process (PID=171) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:08:57.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:08:57.223+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:08:57.223+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:08:57.647+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:08:57.703+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:08:57.703+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:08:57.707+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:08:57.707+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:08:57.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.507 seconds
[2024-05-14T09:09:27.998+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:09:27.999+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:09:28.001+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:09:28.001+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:09:28.408+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:09:28.422+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:09:28.421+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:09:28.428+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:09:28.428+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:09:28.436+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.447 seconds
[2024-05-14T09:09:58.765+0000] {processor.py:161} INFO - Started process (PID=191) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:09:58.766+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:09:58.770+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:09:58.769+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:09:59.139+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:09:59.181+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:09:59.181+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:09:59.185+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:09:59.185+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:09:59.192+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.439 seconds
[2024-05-14T09:10:29.482+0000] {processor.py:161} INFO - Started process (PID=201) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:10:29.483+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:10:29.486+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:10:29.485+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:10:29.916+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:10:29.927+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:10:29.927+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:10:29.936+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:10:29.936+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:10:29.945+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.475 seconds
[2024-05-14T09:11:00.249+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:11:00.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:11:00.251+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:11:00.250+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:11:00.594+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:11:00.643+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:11:00.643+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:11:00.648+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:11:00.648+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:11:00.657+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.413 seconds
[2024-05-14T09:11:30.951+0000] {processor.py:161} INFO - Started process (PID=219) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:11:30.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:11:30.954+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:11:30.954+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:11:31.415+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:11:31.430+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:11:31.430+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:11:31.437+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:11:31.437+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:11:31.446+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.503 seconds
[2024-05-14T09:12:01.867+0000] {processor.py:161} INFO - Started process (PID=229) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:12:01.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:12:01.872+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:12:01.871+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:12:02.213+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:12:02.256+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:12:02.256+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:12:02.260+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:12:02.260+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:12:02.267+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.410 seconds
[2024-05-14T09:12:32.513+0000] {processor.py:161} INFO - Started process (PID=238) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:12:32.514+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:12:32.517+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:12:32.516+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:12:32.886+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:12:32.899+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:12:32.898+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:12:32.904+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:12:32.904+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:12:32.912+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.409 seconds
[2024-05-14T09:13:03.244+0000] {processor.py:161} INFO - Started process (PID=249) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:13:03.245+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:13:03.250+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:13:03.249+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:13:03.635+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:13:03.681+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:13:03.680+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:13:03.684+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:13:03.684+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:13:03.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.459 seconds
[2024-05-14T09:13:33.967+0000] {processor.py:161} INFO - Started process (PID=259) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:13:33.969+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:13:33.971+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:13:33.971+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:13:34.370+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:13:34.383+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:13:34.383+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:13:34.388+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:13:34.388+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:13:34.396+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.439 seconds
[2024-05-14T09:14:04.763+0000] {processor.py:161} INFO - Started process (PID=269) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:14:04.764+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:14:04.768+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:14:04.767+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:14:05.127+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:14:05.176+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:14:05.175+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:14:05.180+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:14:05.180+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:14:05.188+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.434 seconds
[2024-05-14T09:14:44.901+0000] {processor.py:161} INFO - Started process (PID=30) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:14:44.903+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:14:44.908+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:14:44.907+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:14:46.429+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:14:46.597+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:14:46.597+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:14:46.605+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:14:46.604+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:14:46.623+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 1.726 seconds
[2024-05-14T09:15:17.279+0000] {processor.py:161} INFO - Started process (PID=40) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:15:17.281+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:15:17.284+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:15:17.284+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:15:17.822+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:15:17.846+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:15:17.845+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:15:17.854+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:15:17.853+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:15:17.864+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.609 seconds
[2024-05-14T09:15:48.184+0000] {processor.py:161} INFO - Started process (PID=49) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:15:48.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:15:48.190+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:15:48.190+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:15:48.641+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:15:48.711+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:15:48.711+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:15:48.715+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:15:48.715+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:15:48.723+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.549 seconds
[2024-05-14T09:16:18.967+0000] {processor.py:161} INFO - Started process (PID=59) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:16:18.970+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:16:18.973+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:16:18.972+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:16:19.371+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:16:19.383+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:16:19.382+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:16:19.392+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:16:19.392+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:16:19.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.440 seconds
[2024-05-14T09:16:49.807+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:16:49.808+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:16:49.811+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:16:49.810+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:16:50.265+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:16:50.317+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:16:50.317+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:16:50.321+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:16:50.321+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:16:50.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.531 seconds
[2024-05-14T09:17:20.609+0000] {processor.py:161} INFO - Started process (PID=79) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:17:20.611+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:17:20.614+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:17:20.613+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:17:21.009+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:17:21.023+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:17:21.022+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:17:21.030+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:17:21.030+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:17:21.041+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.440 seconds
[2024-05-14T09:17:51.425+0000] {processor.py:161} INFO - Started process (PID=89) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:17:51.426+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:17:51.428+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:17:51.428+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:17:51.817+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:17:51.863+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:17:51.862+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:17:51.866+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:17:51.866+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:17:51.874+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.462 seconds
[2024-05-14T09:18:22.161+0000] {processor.py:161} INFO - Started process (PID=99) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:18:22.164+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:18:22.167+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:18:22.166+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:18:22.554+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:18:22.566+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:18:22.566+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:18:22.572+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:18:22.572+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:18:22.580+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.428 seconds
[2024-05-14T09:18:52.965+0000] {processor.py:161} INFO - Started process (PID=109) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:18:52.967+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:18:52.971+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:18:52.970+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:18:53.341+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:18:53.389+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:18:53.389+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:18:53.393+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:18:53.393+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:18:53.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.445 seconds
[2024-05-14T09:19:23.759+0000] {processor.py:161} INFO - Started process (PID=119) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:19:23.761+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:19:23.764+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:19:23.764+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:19:24.148+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:19:24.161+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:19:24.161+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:19:24.167+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:19:24.167+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:19:24.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.427 seconds
[2024-05-14T09:19:54.517+0000] {processor.py:161} INFO - Started process (PID=129) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:19:54.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:19:54.522+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:19:54.521+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:19:54.898+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:19:54.949+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:19:54.949+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:19:54.953+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:19:54.953+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:19:54.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.454 seconds
[2024-05-14T09:20:25.286+0000] {processor.py:161} INFO - Started process (PID=139) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:20:25.289+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:20:25.292+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:20:25.292+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:20:25.724+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:20:25.736+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:20:25.736+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:20:25.741+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:20:25.741+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:20:25.749+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.473 seconds
[2024-05-14T09:20:56.084+0000] {processor.py:161} INFO - Started process (PID=148) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:20:56.085+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:20:56.089+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:20:56.089+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:20:56.602+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:20:56.657+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:20:56.656+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:20:56.662+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:20:56.662+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:20:56.673+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.599 seconds
[2024-05-14T09:21:26.937+0000] {processor.py:161} INFO - Started process (PID=159) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:21:26.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:21:26.943+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:21:26.943+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:21:27.513+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:21:27.531+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:21:27.531+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:21:27.539+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:21:27.539+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:21:27.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.619 seconds
[2024-05-14T09:21:57.964+0000] {processor.py:161} INFO - Started process (PID=169) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:21:57.967+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:21:57.971+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:21:57.970+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:21:58.503+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:21:58.583+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:21:58.582+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:21:58.589+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:21:58.589+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:21:58.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.677 seconds
[2024-05-14T09:22:28.930+0000] {processor.py:161} INFO - Started process (PID=179) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:22:28.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:22:28.935+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:22:28.935+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:22:29.589+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:22:29.619+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:22:29.619+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:22:29.632+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:22:29.632+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:22:29.643+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.723 seconds
[2024-05-14T09:23:00.019+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:23:00.021+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:23:00.024+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:23:00.024+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:23:00.476+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:23:00.530+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:23:00.530+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:23:00.534+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:23:00.534+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:23:00.542+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.532 seconds
[2024-05-14T09:23:30.875+0000] {processor.py:161} INFO - Started process (PID=198) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:23:30.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:23:30.880+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:23:30.880+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:23:31.332+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:23:31.347+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:23:31.347+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:23:31.353+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:23:31.353+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:23:31.361+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.499 seconds
[2024-05-14T09:24:01.751+0000] {processor.py:161} INFO - Started process (PID=208) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:24:01.753+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:24:01.758+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:24:01.757+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:24:02.262+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:24:02.326+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:24:02.326+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:24:02.333+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:24:02.333+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:24:02.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.604 seconds
[2024-05-14T09:24:32.648+0000] {processor.py:161} INFO - Started process (PID=217) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:24:32.652+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:24:32.657+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:24:32.656+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:24:33.212+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:24:33.232+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:24:33.231+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:24:33.239+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:24:33.239+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:24:33.248+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.610 seconds
[2024-05-14T09:25:03.640+0000] {processor.py:161} INFO - Started process (PID=226) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:25:03.643+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:25:03.647+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:25:03.647+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:25:04.103+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:25:04.159+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:25:04.159+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:25:04.164+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:25:04.164+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:25:04.172+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.541 seconds
[2024-05-14T09:25:34.478+0000] {processor.py:161} INFO - Started process (PID=236) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:25:34.481+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:25:34.484+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:25:34.483+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:25:34.974+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:25:34.992+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:25:34.991+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:25:35.012+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:25:35.012+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:25:35.022+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.554 seconds
[2024-05-14T09:26:05.488+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:26:05.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:26:05.493+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:26:05.493+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:26:06.011+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:26:06.083+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:26:06.083+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:26:06.089+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:26:06.089+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:26:06.101+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.624 seconds
[2024-05-14T09:26:36.394+0000] {processor.py:161} INFO - Started process (PID=262) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:26:36.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:26:36.401+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:26:36.400+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:26:36.947+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:26:36.963+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:26:36.963+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:26:36.970+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:26:36.970+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:26:36.979+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.600 seconds
[2024-05-14T09:27:07.352+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:27:07.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:27:07.357+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:27:07.356+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:27:07.782+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:27:07.836+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:27:07.836+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:27:07.841+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:27:07.841+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:27:07.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.507 seconds
[2024-05-14T09:27:38.206+0000] {processor.py:161} INFO - Started process (PID=282) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:27:38.208+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:27:38.212+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:27:38.212+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:27:38.686+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:27:38.700+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:27:38.700+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:27:38.708+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:27:38.708+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:27:38.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.524 seconds
[2024-05-14T09:28:09.049+0000] {processor.py:161} INFO - Started process (PID=292) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:28:09.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:28:09.051+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:28:09.051+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:28:09.416+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:28:09.462+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:28:09.462+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:28:09.467+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:28:09.466+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:28:09.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.430 seconds
[2024-05-14T09:28:39.894+0000] {processor.py:161} INFO - Started process (PID=302) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:28:39.896+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T09:28:39.899+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:28:39.899+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:28:40.373+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T09:28:40.386+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:28:40.385+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T09:28:40.393+0000] {logging_mixin.py:188} INFO - [2024-05-14T09:28:40.393+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T09:28:40.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.523 seconds
[2024-05-14T10:12:04.540+0000] {processor.py:161} INFO - Started process (PID=306) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T10:12:04.541+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T10:12:04.543+0000] {logging_mixin.py:188} INFO - [2024-05-14T10:12:04.543+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T10:12:04.913+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T10:12:04.955+0000] {logging_mixin.py:188} INFO - [2024-05-14T10:12:04.955+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T10:12:04.959+0000] {logging_mixin.py:188} INFO - [2024-05-14T10:12:04.959+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T10:12:04.968+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.434 seconds
[2024-05-14T11:29:25.995+0000] {processor.py:161} INFO - Started process (PID=316) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T11:29:25.996+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T11:29:25.998+0000] {logging_mixin.py:188} INFO - [2024-05-14T11:29:25.998+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T11:29:26.595+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T11:29:26.611+0000] {logging_mixin.py:188} INFO - [2024-05-14T11:29:26.610+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T11:29:26.622+0000] {logging_mixin.py:188} INFO - [2024-05-14T11:29:26.622+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T11:29:26.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.645 seconds
[2024-05-14T12:46:36.953+0000] {processor.py:161} INFO - Started process (PID=326) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T12:46:36.954+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T12:46:36.956+0000] {logging_mixin.py:188} INFO - [2024-05-14T12:46:36.956+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T12:46:37.388+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T12:46:37.439+0000] {logging_mixin.py:188} INFO - [2024-05-14T12:46:37.438+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T12:46:37.444+0000] {logging_mixin.py:188} INFO - [2024-05-14T12:46:37.443+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T12:46:37.451+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.505 seconds
[2024-05-14T13:19:44.060+0000] {processor.py:161} INFO - Started process (PID=336) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T13:19:44.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T13:19:44.066+0000] {logging_mixin.py:188} INFO - [2024-05-14T13:19:44.065+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T13:19:44.534+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T13:19:44.547+0000] {logging_mixin.py:188} INFO - [2024-05-14T13:19:44.546+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T13:19:44.553+0000] {logging_mixin.py:188} INFO - [2024-05-14T13:19:44.553+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T13:19:44.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.508 seconds
[2024-05-14T13:56:19.873+0000] {processor.py:161} INFO - Started process (PID=346) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T13:56:19.874+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T13:56:19.878+0000] {logging_mixin.py:188} INFO - [2024-05-14T13:56:19.878+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T13:56:20.314+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T13:56:20.367+0000] {logging_mixin.py:188} INFO - [2024-05-14T13:56:20.367+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T13:56:20.371+0000] {logging_mixin.py:188} INFO - [2024-05-14T13:56:20.371+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T13:56:20.380+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.515 seconds
[2024-05-14T14:27:06.261+0000] {processor.py:161} INFO - Started process (PID=355) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:27:06.263+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T14:27:06.265+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:27:06.265+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:27:06.686+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:27:06.699+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:27:06.699+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T14:27:06.705+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:27:06.705+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T14:27:06.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.460 seconds
[2024-05-14T14:27:12.808+0000] {processor.py:161} INFO - Started process (PID=359) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:27:12.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T14:27:12.813+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:27:12.813+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:27:13.154+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:27:13.159+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:27:13.159+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T14:27:13.164+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:27:13.164+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T14:27:13.172+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.373 seconds
[2024-05-14T14:27:43.562+0000] {processor.py:161} INFO - Started process (PID=369) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:27:43.565+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T14:27:43.568+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:27:43.567+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:27:44.008+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:27:44.060+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:27:44.059+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T14:27:44.064+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:27:44.064+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T14:27:44.072+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.520 seconds
[2024-05-14T14:28:14.364+0000] {processor.py:161} INFO - Started process (PID=379) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:28:14.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T14:28:14.370+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:28:14.369+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:28:14.773+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:28:14.787+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:28:14.786+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T14:28:14.794+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:28:14.794+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T14:28:14.802+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.449 seconds
[2024-05-14T14:28:45.160+0000] {processor.py:161} INFO - Started process (PID=389) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:28:45.161+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T14:28:45.165+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:28:45.165+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:28:45.563+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:28:45.611+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:28:45.611+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T14:28:45.615+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:28:45.615+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T14:28:45.623+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.477 seconds
[2024-05-14T14:29:15.995+0000] {processor.py:161} INFO - Started process (PID=399) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:29:15.996+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T14:29:16.000+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:29:15.999+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:29:16.430+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:29:16.443+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:29:16.443+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T14:29:16.450+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:29:16.449+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T14:29:16.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.474 seconds
[2024-05-14T14:29:46.810+0000] {processor.py:161} INFO - Started process (PID=409) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:29:46.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T14:29:46.823+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:29:46.822+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:29:47.251+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:29:47.304+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:29:47.304+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T14:29:47.309+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:29:47.308+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T14:29:47.316+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.526 seconds
[2024-05-14T14:30:17.677+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:30:17.679+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T14:30:17.682+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:30:17.681+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:30:18.110+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:30:18.126+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:30:18.126+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T14:30:18.132+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:30:18.132+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T14:30:18.141+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.475 seconds
[2024-05-14T14:30:48.519+0000] {processor.py:161} INFO - Started process (PID=429) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:30:48.521+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T14:30:48.524+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:30:48.523+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:30:48.959+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:30:49.012+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:30:49.012+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T14:30:49.017+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:30:49.017+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T14:30:49.025+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.516 seconds
[2024-05-14T14:31:19.324+0000] {processor.py:161} INFO - Started process (PID=439) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:31:19.331+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T14:31:19.336+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:31:19.336+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:31:19.843+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:31:19.859+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:31:19.859+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T14:31:19.866+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:31:19.866+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T14:31:19.874+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.560 seconds
[2024-05-14T14:31:50.217+0000] {processor.py:161} INFO - Started process (PID=449) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:31:50.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T14:31:50.222+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:31:50.222+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:31:50.783+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:31:50.853+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:31:50.853+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T14:31:50.858+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:31:50.858+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T14:31:50.866+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.655 seconds
[2024-05-14T14:32:21.209+0000] {processor.py:161} INFO - Started process (PID=459) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:32:21.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T14:32:21.215+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:32:21.214+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:32:21.633+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:32:21.648+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:32:21.647+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T14:32:21.654+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:32:21.654+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T14:32:21.700+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.502 seconds
[2024-05-14T14:32:52.059+0000] {processor.py:161} INFO - Started process (PID=474) to work on /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:32:52.061+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/data_pipeline_jobs104.py for tasks to queue
[2024-05-14T14:32:52.063+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:32:52.063+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:32:52.450+0000] {processor.py:840} INFO - DAG(s) 'data_pipeline_jobs104' retrieved from /opt/airflow/dags/data_pipeline_jobs104.py
[2024-05-14T14:32:52.501+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:32:52.500+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-14T14:32:52.505+0000] {logging_mixin.py:188} INFO - [2024-05-14T14:32:52.505+0000] {dag.py:3954} INFO - Setting next_dagrun for data_pipeline_jobs104 to None, run_after=None
[2024-05-14T14:32:52.514+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/data_pipeline_jobs104.py took 0.461 seconds
