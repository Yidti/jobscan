{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1d4b84-ce72-4871-8366-dc78a7fb17fb",
   "metadata": {},
   "source": [
    "# Step 1. Reload files & Import Modules - 匯入模組"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c984bd7-9a31-4d81-91c4-aeba6791b17e",
   "metadata": {},
   "source": [
    "## 1-1. Reload files - 重讀檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1141b824-fa82-4335-a02d-00bed81a491a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_lake' from 'C:\\\\Users\\\\Rekam\\\\Documents\\\\Jobscan\\\\data_lake.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload file if you eaited them\n",
    "import crawler104, config.search_params, async_example, threaded_async_job, jobs104\n",
    "import data_lake\n",
    "import importlib\n",
    "importlib.reload(crawler104)\n",
    "importlib.reload(async_example)\n",
    "importlib.reload(threaded_async_job)\n",
    "importlib.reload(jobs104)\n",
    "importlib.reload(config.search_params)\n",
    "importlib.reload(data_lake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f121df8-16a3-4c1b-8ef7-e3d220a52006",
   "metadata": {},
   "source": [
    "## 1-2. Import Modules - 匯入模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a236b8-7ccd-4cd6-be4e-2b64a7b8e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from crawler104 import Crawler104\n",
    "from config.search_params import get_filter_params\n",
    "from data_lake import DataLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24777e1b-41d4-46bf-aad7-f9db3acbebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速執行 reload & import\n",
    "%run main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9919d95d-b673-4216-99ce-107226faf946",
   "metadata": {},
   "source": [
    "# Step 2. Data Source - 爬蟲抓資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f2ac55-a1a1-43d7-b10c-7b0a45d15125",
   "metadata": {},
   "source": [
    "## 2-1. Web Crawler - 抓取Jobs清單"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7582c23b-cd00-4645-99c3-49cd4208a305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://www.104.com.tw/jobs/search/?ro=1&keyword=%E5%BE%8C%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%AB+python&isnew=3&jobexp=1%2C3&mode=l&order=16&asc=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|██████████| 53/53 [01:12<00:00,  1.37s/page]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "載入53頁 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "載入1558筆資料 | 過濾剩1202筆資料 | 花費 88.03 秒\n"
     ]
    }
   ],
   "source": [
    "# custom filter params for search - for yidti\n",
    "role = {'ro':'全職'}\n",
    "keyword = {'keyword':\"後端工程師 python\"}\n",
    "# area = {'area':['新北市', '台北市', '桃園市', '台中市']}\n",
    "isnew = {'isnew':'三日內'}\n",
    "jobexp = {'jobexp':['1年以下', '1-3年']}\n",
    "# 預設\n",
    "mode = {'mode':'列表'}  # 一次能呈現比較多筆資料\n",
    "order = {'order':'日期排序'}\n",
    "asc = {'asc':'遞減'}\n",
    "# filter_params = get_filter_params(role, keyword, area, isnew, jobexp, mode, order, asc)\n",
    "filter_params = get_filter_params(role, keyword, isnew, jobexp, mode, order, asc)\n",
    "\n",
    "# keywords for filter job again\n",
    "job_keywords = ('工程','資料','python','data','數據','後端')\n",
    "# exclude keyword for filter company (about gambling)\n",
    "company_exclude = ('新加坡商冕創有限公司','新博軟體開發股份有限公司','現觀科技股份有限公司')\n",
    "# -------------------------------------------\n",
    "# 根據過濾參數開始爬蟲 & 再次根據keyword過濾jobs與company & 在爬取細節\n",
    "user = \"yidti\"\n",
    "crawler = Crawler104(filter_params, user)\n",
    "crawler.run(job_keywords, company_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fb4d88-569f-479a-8744-83b657f2fd1d",
   "metadata": {},
   "source": [
    "## 2-2. Web Scraper - 抓取Jobs內容(異步&多線程)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a93bc8-1f3d-4d8c-85e1-452099853e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jobs: 100%|██████████| 1202/1202 [03:20<00:00,  5.99job/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Details for 1202 Jobs | 花費 200.73 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "crawler.detail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aee73d-a6df-4196-b1c5-255be9e3d291",
   "metadata": {},
   "source": [
    "## 2-3. Export Flie - 輸出至Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e8e103c-3cee-4eff-a52d-aa307d19f80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV文件保存成功: output/yidti_2024-02-05.xlsx\n"
     ]
    }
   ],
   "source": [
    "crawler.export_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c20eb7f-7c49-41fb-9220-64c4ccdbd6fc",
   "metadata": {},
   "source": [
    "# Step 3. Data Lake - 資料存入NoSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b36ca7d2-ffd9-4443-86d5-898a131f4a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速執行 reload & import\n",
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4dc71e9b-0209-4000-b095-6472c2961224",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m user \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myidti\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# output to excel file (job)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mcrawler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# ouput to noSQL (job, company, industry)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# data_Lake = DataLake()\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# data_Lake.upload_nosql(user, crawler)\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Jobscan\\crawler104.py:309\u001b[0m, in \u001b[0;36mCrawler104.export_excel\u001b[1;34m(self, user)\u001b[0m\n\u001b[0;32m    307\u001b[0m column_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m公司_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m產業_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column_to_drop \u001b[38;5;129;01min\u001b[39;00m column_list:\n\u001b[1;32m--> 309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m column_to_drop \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m    310\u001b[0m         df_jobs_output \u001b[38;5;241m=\u001b[39m df_jobs_output\u001b[38;5;241m.\u001b[39mdrop(column_to_drop,axis\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    313\u001b[0m current_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mdate()    \n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# output to excel file (job)\n",
    "# ouput to noSQL (job, company, industry)\n",
    "# data_Lake = DataLake()\n",
    "# data_Lake.upload_nosql(user, crawler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd23b65-8333-4cec-8337-5b9612cf4615",
   "metadata": {},
   "source": [
    "# Step 4 - Data Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "972a76e5-1630-4797-86c3-3f84e9febcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('information_schema',)\n",
      "('job_db',)\n",
      "('mysql',)\n",
      "('performance_schema',)\n",
      "('sakila',)\n",
      "('sys',)\n",
      "('world',)\n"
     ]
    }
   ],
   "source": [
    "# create db\n",
    "import mysql.connector\n",
    "\n",
    "def createDB():\n",
    "    db = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user = \"root\",\n",
    "        password = \"Sql@1031\",\n",
    "        port = 3306\n",
    "    )\n",
    "    db_name = \"job_db\"\n",
    "    cursor = db.cursor()\n",
    "    cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {db_name}\")\n",
    "    cursor.execute(\"SHOW DATABASES\")\n",
    "    \n",
    "    for x in cursor:\n",
    "      print(x)\n",
    "\n",
    "    db.commit()\n",
    "    db.close()\n",
    "\n",
    "createDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bead213b-240a-4a21-893f-fa5da5c85c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test OK\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.getenv(\"MODE\")\n",
    "from sqlalchemy import create_engine, text\n",
    "from urllib.parse import quote\n",
    "\n",
    "# 對密碼進行 URL 編碼\n",
    "user = \"root\"\n",
    "password = quote(\"Sql@1031\")\n",
    "host = \"localhost\"\n",
    "port = 3306\n",
    "db_name = \"job_db\"\n",
    "# 構建 MySQL 數據庫連接 URL\n",
    "connector_url = f\"mysql+mysqlconnector://{user}:{password}@{host}:{port}/{db_name}\"\n",
    "# print(connector_url)\n",
    "# 創建引擎object\n",
    "engine = create_engine(connector_url, future = True)\n",
    "\n",
    "# SQL 語句範例\n",
    "# sql_statement = \"SELECT * FROM your_table\"  # 替換成實際的表格名稱\n",
    "sql_job_table =  \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS JobsInfo  (\n",
    "            `更新日期` DATE,\n",
    "            `職缺名稱` VARCHAR(100),\n",
    "            `公司名稱` VARCHAR(100),\n",
    "            `工作內容` TEXT,\n",
    "            `職務類別` INT,\n",
    "            `工作待遇` VARCHAR(100),\n",
    "            `工作性質` INT,\n",
    "            `縣市` INT,\n",
    "            `上班地點` VARCHAR(100),\n",
    "            `管理責任` INT,\n",
    "            `出差外派` INT,\n",
    "            `上班時段` VARCHAR(100),\n",
    "            `休假制度` INT,\n",
    "            `可上班日` INT,\n",
    "            `需求人數` VARCHAR(50),\n",
    "            `工作經歷` INT,\n",
    "            `學歷要求` INT,\n",
    "            `科系要求` VARCHAR(50),\n",
    "            `語文條件` VARCHAR(50),\n",
    "            `擅長工具` VARCHAR(500),\n",
    "            `工作技能` VARCHAR(500),\n",
    "            `其他要求` TEXT,\n",
    "            `連結` TEXT,\n",
    "            PRIMARY KEY (`連結`(255))\n",
    ");\n",
    "        \"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    print(\"test OK\")\n",
    "    connection.execute(text(sql_job_table))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7137cbdc-5d82-4170-b450-9fd24551955f",
   "metadata": {},
   "source": [
    "# Step 5 - Data Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470f8917-6fb6-4b01-94ff-098a746f5938",
   "metadata": {},
   "source": [
    "# Step 99. Test Area - 測試區域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d90682b-1ada-4761-8eb0-54c64d0f4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom filter params for search - simon\n",
    "# role = {'ro':'全職'}\n",
    "# zone = {'zone': '4,5'}\n",
    "# indcat = {'indcat':'1001000000,1002000000,1012000000,1014000000'}\n",
    "# exclude = {'excludeJobKeyword': '軟體,會計,文件整理,行政,百貨,資訊,品管,財務,守衛,技術員,法務,品檢,登打,輪班,無經驗,客戶'}\n",
    "# mode = {'mode':'列表'}  # 一次能呈現比較多筆資料\n",
    "# order = {'order':'日期排序'}\n",
    "# asc = {'asc':'遞減'}\n",
    "# filter_params = get_filter_params(role, zone, indcat, exclude, mode, order, asc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e7b2d4-a954-4452-98fc-833e3e40e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果你在一個 Python script 中執行這樣的程式碼，你可能需要使用 asyncio.run() 函數。\n",
    "# 在異步程式碼中，如果你使用 asyncio.gather 函數收集異步任務的結果，而這些任務沒有顯式返回值，\n",
    "# gather 函數將返回一個包含每個異步任務結果的列表，而這些結果通常是 None。\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def async_example(i):\n",
    "    print(f\"Start asynchronous task {i}\")\n",
    "    await asyncio.sleep(1)\n",
    "    print(f\"End asynchronous task {i}\")\n",
    "    return f\"Result of task {i}\"\n",
    "\n",
    "# 直接在 Jupyter cell 中執行\n",
    "tasks = [async_example(i) for i in range(5)]\n",
    "results = await asyncio.gather(*tasks)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
