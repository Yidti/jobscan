{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1d4b84-ce72-4871-8366-dc78a7fb17fb",
   "metadata": {},
   "source": [
    "# Step 1. Reload files & Import Modules - 匯入模組"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c984bd7-9a31-4d81-91c4-aeba6791b17e",
   "metadata": {},
   "source": [
    "## 1-1. Reload files - 重讀檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d407f79-bd35-4d4c-8bbd-114212527717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1141b824-fa82-4335-a02d-00bed81a491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload file if you eaited them\n",
    "import crawler, crawler104, config.search_params, async_example, threaded_async_job, jobs104\n",
    "import data_lake, data_warehouse, translation, data_analysis\n",
    "\n",
    "import importlib\n",
    "importlib.reload(crawler)\n",
    "importlib.reload(crawler104)\n",
    "importlib.reload(async_example)\n",
    "importlib.reload(threaded_async_job)\n",
    "importlib.reload(jobs104)\n",
    "importlib.reload(config.search_params)\n",
    "importlib.reload(data_lake)\n",
    "importlib.reload(data_warehouse)\n",
    "importlib.reload(translation)\n",
    "importlib.reload(data_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f121df8-16a3-4c1b-8ef7-e3d220a52006",
   "metadata": {},
   "source": [
    "## 1-2. Import Modules - 匯入模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a236b8-7ccd-4cd6-be4e-2b64a7b8e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from crawler import Crawler\n",
    "from crawler104 import Crawler104\n",
    "from config.search_params import get_filter_params\n",
    "from data_lake import DataLake\n",
    "from data_warehouse import DataWarehouse\n",
    "from data_analysis import DataAnalysis\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24777e1b-41d4-46bf-aad7-f9db3acbebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速執行 reload & import\n",
    "%run main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9919d95d-b673-4216-99ce-107226faf946",
   "metadata": {},
   "source": [
    "# Step 2. Data Source - 爬蟲抓資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df19f934-3f23-4ec5-94e5-5a5f793e0910",
   "metadata": {},
   "source": [
    "## 2-1. Filter Setting - 過濾條件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7582c23b-cd00-4645-99c3-49cd4208a305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# custom filter params for search - for yidti\n",
    "role = {'ro':'全職'}\n",
    "keyword = {'keyword':\"後端工程師 python\"}\n",
    "# area = {'area':['新北市', '台北市', '桃園市', '台中市']}\n",
    "isnew = {'isnew':'三日內'}\n",
    "jobexp = {'jobexp':['1年以下', '1-3年']}\n",
    "# 預設\n",
    "mode = {'mode':'列表'}  # 一次能呈現比較多筆資料\n",
    "order = {'order':'日期排序'}\n",
    "asc = {'asc':'遞減'}\n",
    "# filter_params = get_filter_params(role, keyword, area, isnew, jobexp, mode, order, asc)\n",
    "filter_params = get_filter_params(role, keyword, isnew, jobexp, mode, order, asc)\n",
    "# user & title\n",
    "user = \"yidti\"\n",
    "title = \"data_Engineer\"\n",
    "crawler104 = Crawler104(filter_params, user, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f2ac55-a1a1-43d7-b10c-7b0a45d15125",
   "metadata": {},
   "source": [
    "## 2-2. Web Crawler - 抓取Jobs清單"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc82644b-0ee1-446c-8a85-25736a64e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome for testing -> https://googlechromelabs.github.io/chrome-for-testing/\n",
    "# keywords for filter job again\n",
    "job_keywords = ('工程','資料','python','data','數據','後端')\n",
    "# Exclude keywords to filter out companies related to gambling or others that I don't want to consider.\n",
    "company_exclude = ('新加坡商冕創有限公司','新博軟體開發股份有限公司','現觀科技股份有限公司'\n",
    "                   ,'全富數位有限公司','杰思數位有限公司','博凡星國際有限公司',\n",
    "                  '尊博科技股份有限公司','新騎資訊有限公司','新加坡商鈦坦科技股份有限公司台灣分公司',\n",
    "                   '豪穎科技股份有限公司','塶樂微創有限公司','磐弈有限公司',\n",
    "                   '聯訊網路有限公司','冶金數位科技有限公司','肥貓科技有限公司',\n",
    "                   '無名科技有限公司','博澭科技有限公司','緯雲股份有限公司',\n",
    "                   '風采有限公司','英屬維京群島商嘉碼科技有限公司台灣分公司',\n",
    "                   '冠宇數位科技股份有限公司','英仕國際有限公司','元遊科技有限公司',\n",
    "                   '禾碩資訊股份有限公司','向上集團_向上國際科技股份有限公司',\n",
    "                   '弈樂科技股份有限公司','馬來西亞商極限電腦科技有限公司台灣分公司',\n",
    "                   '樂夠科技有限公司','威智國際有限公司','紅信科技有限公司',\n",
    "                   '深思設計有限公司','揚帆科技有限公司','晶要資訊有限公司',\n",
    "                   '九七科技股份有限公司','臣悅科技有限公司','尊承科技股份有限公司',\n",
    "                   '遊戲河流有限公司','唐傳有限公司','捷訊資訊有限公司',\n",
    "                   '逍遙遊科技有限公司','澄果資訊服務有限公司','果遊科技有限公司',\n",
    "                   '昱泉國際股份有限公司','博星數位股份有限公司',\n",
    "                  )\n",
    "print(f\"設定排除{len(company_exclude)}家公司\")\n",
    "# 會將爬蟲資料存至暫存區 eg. yidti-data-Engineer.parquet ({user}-{title}.parquet)\n",
    "crawler104.run(job_keywords, company_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df33cf-ceb6-4b5d-93ed-5136ee1a8223",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(crawler.df_jobs)\n",
    "crawler.df_jobs.head(10)\n",
    "crawler.df_jobs.columns\n",
    "\n",
    "from datetime import datetime\n",
    "current_date = datetime.now().date()\n",
    "\n",
    "# 爬蟲之後\n",
    "crawler.df_jobs['data_stamp'] = current_date.strftime('%Y-%m-%d')\n",
    "crawler.df_jobs.to_parquet(parquet_path, index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ccfa49-41ec-4240-b16f-dfcd4a980a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "user = \"yidti\"\n",
    "title = \"data_Engineer\"\n",
    "parquet_file = f\"{user}_{title}.parquet\" \n",
    "parquet_path = f\"temp/{parquet_file}\"\n",
    "existing_df = pd.read_parquet(parquet_path)\n",
    "len(existing_df)\n",
    "existing_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fb4d88-569f-479a-8744-83b657f2fd1d",
   "metadata": {},
   "source": [
    "## 2-3. Web Scraper - 抓取Jobs內容(異步&多線程)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb81e800-8405-482b-b1ec-7841c53dac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py\n",
    "# custom filter params for search - for yidti\n",
    "role = {'ro':'全職'}\n",
    "keyword = {'keyword':\"後端工程師 python\"}\n",
    "# area = {'area':['新北市', '台北市', '桃園市', '台中市']}\n",
    "isnew = {'isnew':'三日內'}\n",
    "jobexp = {'jobexp':['1年以下', '1-3年']}\n",
    "# 預設\n",
    "mode = {'mode':'列表'}  # 一次能呈現比較多筆資料\n",
    "order = {'order':'日期排序'}\n",
    "asc = {'asc':'遞減'}\n",
    "# filter_params = get_filter_params(role, keyword, area, isnew, jobexp, mode, order, asc)\n",
    "filter_params = get_filter_params(role, keyword, isnew, jobexp, mode, order, asc)\n",
    "# user & title\n",
    "user = \"yidti\"\n",
    "title = \"data_Engineer\"\n",
    "crawler104 = Crawler104(filter_params, user, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2754bd0-7dfb-49c7-8fba-4ad1943e0713",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = crawler104.load_parquet(detail=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c5a646-756c-4430-adae-43c373e04a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(crawler104.df_jobs_details)\n",
    "# crawler104.df_jobs_details.columns\n",
    "# crawler104.df_jobs_details.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a93bc8-1f3d-4d8c-85e1-452099853e08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 新增 temp 暫存檔 parquet\n",
    "crawler104.detail()\n",
    "# remote chrome docker (10 node) =  2250 jobs / 852.56 sec = 2.63 job/s\n",
    "# local chrome docker = 2204 jobs / 860.34 sec = 2.56 job/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb9bc8-06a1-4c9f-998d-39109a45d899",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = crawler104.load_parquet(detail=True)\n",
    "print(df) \n",
    "# crawler.df_jobs_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aee73d-a6df-4196-b1c5-255be9e3d291",
   "metadata": {},
   "source": [
    "## 2-3. Export Flie - 輸出至Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8e103c-3cee-4eff-a52d-aa307d19f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to excel file (job)\n",
    "crawler.export_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c20eb7f-7c49-41fb-9220-64c4ccdbd6fc",
   "metadata": {},
   "source": [
    "# Step 3. Data Lake - 資料存入NoSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc71e9b-0209-4000-b095-6472c2961224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouput to noSQL (job, company, industry)\n",
    "%run main.py\n",
    "data_lake = DataLake()\n",
    "data_lake.save_nosql(user, crawler)\n",
    "data_lake.filter(job_keywords, company_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd23b65-8333-4cec-8337-5b9612cf4615",
   "metadata": {},
   "source": [
    "# Step 4 - Data Warehouse - 資料存入MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ca7d2-ffd9-4443-86d5-898a131f4a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速執行 reload & import\n",
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1ae46f-a3c3-46b0-9a79-373d3e5445f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py\n",
    "data_lake  = DataLake()\n",
    "data_Warehouse = DataWarehouse()\n",
    "data_Warehouse.initial_db()\n",
    "data_Warehouse.save_sql(data_lake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7137cbdc-5d82-4170-b450-9fd24551955f",
   "metadata": {},
   "source": [
    "# Step 5 - Exploratory Data Analysis (EDA) - 探索性資料分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c0676-9833-47fc-b54a-48241764d611",
   "metadata": {},
   "source": [
    "## 5-1 - Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53e79d2-5609-42d8-ace3-ee53c027e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速執行 reload & import\n",
    "%run main.py\n",
    "da = DataAnalysis()\n",
    "import pandas as pd\n",
    "\n",
    "# 抓取 education\n",
    "t1_columns = [\"job_id\"]  # 事實表要選擇的欄位名稱列表\n",
    "t2_columns = [\"education\"]  # 維度表要選擇的欄位名稱列表\n",
    "df_education = da.merge_data(\"job_info\", \"education\", \"education_id\", \"id\", t1_columns, t2_columns)\n",
    "\n",
    "# 抓取 city\n",
    "t1_columns = [\"job_id\"]  # 事實表要選擇的欄位名稱列表\n",
    "t2_columns = [\"city_region_id\"]  # 維度表要選擇的欄位名稱列表\n",
    "df_location = da.merge_data(\"job_info\", \"location\", \"location_id\", \"id\", t1_columns, t2_columns)\n",
    "\n",
    "t1_columns = [\"city_region_id\"]  # 事實表要選擇的欄位名稱列表\n",
    "t2_columns = [\"city\", \"region\"]  # 維度表要選擇的欄位名稱列表\n",
    "df_city_region = da.merge_data(\"location\", \"location_city_region\", \"city_region_id\", \"id\", t1_columns, t2_columns)\n",
    "\n",
    "df_city = pd.merge(df_location, df_city_region, on=\"city_region_id\", how =\"left\").drop_duplicates(subset='job_id')\n",
    "# 抓取 major\n",
    "df_major = da.read_sql(\"major\")\n",
    "df_major = df_major.rename(columns ={\"major_item\":\"major\"})\n",
    "# 抓取 skill\n",
    "df_skill = da.read_sql(\"skill\")\n",
    "df_skill = df_skill.rename(columns ={\"skill_item\":\"skill\"})\n",
    "# 抓取 tool\n",
    "df_tool = da.read_sql(\"tool\")\n",
    "df_tool = df_tool.rename(columns ={\"tool_item\":\"tool\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ef2c16-8696-49f5-bd19-b2f35e93fad9",
   "metadata": {},
   "source": [
    "## 5-2 - Count Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b47604-a53f-4279-86a6-548a6eef8eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py\n",
    "da = DataAnalysis()\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "da.plot_count(df_education, 'education', ax=axes[0], rotation =0)\n",
    "da.plot_count(df_city, 'city', ax=axes[1], rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f22487-1f4c-4aee-a387-f28936f11f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py\n",
    "da = DataAnalysis()\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "da.plot_count(df_education, 'education', ax=axes[0], vertical=False, rotation=0)\n",
    "da.plot_count(df_city, 'city', ax=axes[1], vertical=False, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd2270c-2d40-48a1-876c-ea783535715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py\n",
    "da = DataAnalysis()\n",
    "da.plot_count(df_major, 'major', figsize=(7, 10), vertical=False, rotation=0, threshold = 0.5, x_diff=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f1447b-a75b-4025-9c9c-f8a8a750e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py\n",
    "da = DataAnalysis()\n",
    "da.plot_count(df_skill, 'skill', figsize=(7, 10), vertical=False, rotation=0, threshold = 0.5, x_diff=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48711653-99d0-4143-b35a-3b4257a03d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py\n",
    "da = DataAnalysis()\n",
    "da.plot_count(df_tool, 'tool', figsize=(7, 10), vertical=False, rotation=0, threshold = 0.5, x_diff=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff25222a-ceb8-4c8e-9748-e577e5700be4",
   "metadata": {},
   "source": [
    "## 5-3 - Pie Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c1f93-e98a-4e77-bc2c-b85e47682ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py\n",
    "da = DataAnalysis()\n",
    "da.plot_pie(df_education, 'education', startangle=45)\n",
    "da.plot_pie(df_city, 'city', startangle=45, x_move=2, y_move=1.2, y_add=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43b0412-07d6-4fc8-87f9-247a567c0d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py\n",
    "da = DataAnalysis()\n",
    "da.plot_pie(df_major, 'major', startangle=60, x_move=2.4, y_move=1.2, y_add=0.2, threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fb66d4-9c14-40af-b581-715d76096659",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py\n",
    "da = DataAnalysis()\n",
    "da.plot_pie(df_skill, 'skill', startangle=150, x_move=2.4, y_move=1.2, y_add=0.2, threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bc3aeb-b40a-46a3-8d3e-dc5166ada9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py\n",
    "da = DataAnalysis()\n",
    "da.plot_pie(df_tool, 'tool', figsize=(12, 14), startangle=190, x_move=1.2, y_move=1.4, y_add=0.2, threshold=1, diff_ang=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142859e4-38e4-4b64-b228-3903e7ad9042",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py\n",
    "da = DataAnalysis()\n",
    "df_tool_new = da.tool_count(df_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e741f2-fbe6-4d4b-9aee-3eb2f4918e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py\n",
    "da = DataAnalysis()\n",
    "da.plot_bar(df_tool_new, x='tool', y='count', orient='vertical')\n",
    "da.plot_bar(df_tool_new, x='tool', y='count', orient='horizontal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950f968c-adbd-4c0d-9d93-53d4f3e248d2",
   "metadata": {},
   "source": [
    "# Step 6 - Creating Containers with Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef1b8b-b4a5-4d6a-9327-e93904b8c0a4",
   "metadata": {},
   "source": [
    "## 6-1 - Development Workflow Guide for Docker and Airflow \n",
    "\n",
    "1. 安裝 Docker 和 Docker Compose： 首先，確保在開發環境中安裝了 Docker 和 Docker Compose。這些工具將用於構建、運行和管理 Docker 容器。\n",
    "2. 建立 Dockerfile： 在 Airflow 專案的根目錄中建立一個名為 Dockerfile 的文件。這個文件將定義 Airflow 的運行環境，包括所需的相依性和配置。\n",
    "3. 建立 Docker Compose 文件： 建立一個名為 docker-compose.yml 的 Docker Compose 文件。在這個文件中，定義 Airflow 的容器配置，包括 Airflow 服務本身以及任何其他相關的服務，如數據庫。\n",
    "4. 編寫 Dockerfile 和 Docker Compose 文件： 在這些文件中定義所需的相依性、環境變數和配置，以及容器之間的連接。\n",
    "5. 構建 Docker 容器： 使用 Docker Compose 命令構建和運行容器。運行 docker-compose up 命令將會構建並啟動所有在 docker-compose.yml 文件中定義的容器。\n",
    "6. 測試 Airflow 工作流程： 一旦容器運行起來，可以在本地測試 Airflow 工作流程。可以使用 Airflow 的命令列工具來測試和調試工作流程。\n",
    "7. 部署到其他環境： 當開發和測試完成後，可以將 Docker 容器部署到其他環境，如測試或生產環境中。這可以通過將容器映像推送到容器註冊表並在目標環境中運行容器來實現。\n",
    "8. 監控和維護： 確保在生產環境中設置了監控和警報系統，以及定期維護 Docker 容器和 Airflow 服務。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2675f569-3a87-411a-bbf9-b02e270632fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ｔest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cfaf41-1966-428b-b38a-98b04151d4e2",
   "metadata": {},
   "source": [
    "# Step 7 - Configuring Airflow for Task Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525d1d26-195d-4928-817c-86642761e72f",
   "metadata": {},
   "source": [
    "# Step 99. Test Area - 測試區域\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb0afad-db26-4cd1-8dba-553d7d98bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_num = int(input())\n",
    "matrix =[]\n",
    "for num in range(matrix_num):\n",
    "    row = input().split(' ')\n",
    "    matrix.append(row)\n",
    "# print(matrix)\n",
    "\n",
    "# 21 53 158 194\n",
    "# 15 30 32 50\n",
    "# matrix = [['21', '53', '158', '194'], ['15', '30', '32', '50']]\n",
    "# matrix2 = [['74', '67', '180', '140'], ['56', '135', '33', '149'],['29', '79', '165', '70'],['121', '75', '54', '8']]\n",
    "\n",
    "\n",
    "def matrix_22(matrix):\n",
    "    if len(matrix) >=2:\n",
    "        a1, b1, c1, d1 = matrix[0]\n",
    "        a2, b2, c2, d2 = matrix[1]\n",
    "        a1 = int(a1)\n",
    "        a2 = int(a2)\n",
    "        b1 = int(b1)\n",
    "        b2 = int(b2)\n",
    "        c1 = int(c1)\n",
    "        c2 = int(c2)\n",
    "        d1 = int(d1)\n",
    "        d2 = int(d2)\n",
    "        a0 = a1*a2 + b1*c2\n",
    "        b0 = a1*b2 + b1*d2\n",
    "        c0 = a2*c1 + c2*d1\n",
    "        d0 = b2*c1 + d1*d2\n",
    "        new_matrix = matrix\n",
    "        del new_matrix[0]\n",
    "        del new_matrix[0]\n",
    "        new_matrix.insert(0,[a0, b0, c0, d0])\n",
    "        return matrix_22(new_matrix)\n",
    "    else:\n",
    "        return matrix\n",
    "\n",
    "print(matrix_22(matrix)[0])\n",
    "\n",
    "# for index in range(len(matrix2)-1):\n",
    "#     matrix = [matrix2[index], matrix2[index+1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f075a5a2-13b0-42c6-8442-4081a54774f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
