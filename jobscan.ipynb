{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1d4b84-ce72-4871-8366-dc78a7fb17fb",
   "metadata": {},
   "source": [
    "# Step 1. Reload files & Import Modules - 匯入模組"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c984bd7-9a31-4d81-91c4-aeba6791b17e",
   "metadata": {},
   "source": [
    "## 1-1. Reload files - 重讀檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1141b824-fa82-4335-a02d-00bed81a491a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_lake' from 'C:\\\\Users\\\\Rekam\\\\Documents\\\\Jobscan\\\\data_lake.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload file if you eaited them\n",
    "import crawler104, config.search_params, async_example, threaded_async_job, jobs104\n",
    "import data_lake\n",
    "import importlib\n",
    "importlib.reload(crawler104)\n",
    "importlib.reload(async_example)\n",
    "importlib.reload(threaded_async_job)\n",
    "importlib.reload(jobs104)\n",
    "importlib.reload(config.search_params)\n",
    "importlib.reload(data_lake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f121df8-16a3-4c1b-8ef7-e3d220a52006",
   "metadata": {},
   "source": [
    "## 1-2. Import Modules - 匯入模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a236b8-7ccd-4cd6-be4e-2b64a7b8e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from crawler104 import Crawler104\n",
    "from config.search_params import get_filter_params\n",
    "from data_lake import DataLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24777e1b-41d4-46bf-aad7-f9db3acbebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速執行 reload & import\n",
    "%run main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9919d95d-b673-4216-99ce-107226faf946",
   "metadata": {},
   "source": [
    "# Step 2. Data Source - 爬蟲抓資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f2ac55-a1a1-43d7-b10c-7b0a45d15125",
   "metadata": {},
   "source": [
    "## 2-1. Web Crawler - 抓取Jobs清單"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7582c23b-cd00-4645-99c3-49cd4208a305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# custom filter params for search - for yidti\n",
    "role = {'ro':'全職'}\n",
    "keyword = {'keyword':\"後端工程師 python\"}\n",
    "# area = {'area':['新北市', '台北市', '桃園市', '台中市']}\n",
    "isnew = {'isnew':'三日內'}\n",
    "jobexp = {'jobexp':['1年以下', '1-3年']}\n",
    "# 預設\n",
    "mode = {'mode':'列表'}  # 一次能呈現比較多筆資料\n",
    "order = {'order':'日期排序'}\n",
    "asc = {'asc':'遞減'}\n",
    "# filter_params = get_filter_params(role, keyword, area, isnew, jobexp, mode, order, asc)\n",
    "filter_params = get_filter_params(role, keyword, isnew, jobexp, mode, order, asc)\n",
    "\n",
    "# keywords for filter job again\n",
    "job_keywords = ('工程','資料','python','data','數據','後端')\n",
    "# Exclude keywords to filter out companies related to gambling or others that I don't want to consider.\n",
    "company_exclude = ('新加坡商冕創有限公司','新博軟體開發股份有限公司','現觀科技股份有限公司'\n",
    "                   ,'全富數位有限公司','杰思數位有限公司','博凡星國際有限公司',\n",
    "                  '尊博科技股份有限公司','新騎資訊有限公司','新加坡商鈦坦科技股份有限公司台灣分公司',\n",
    "                   '豪穎科技股份有限公司','塶樂微創有限公司','磐弈有限公司',\n",
    "                   '聯訊網路有限公司','冶金數位科技有限公司','肥貓科技有限公司',\n",
    "                   '無名科技有限公司','博澭科技有限公司','緯雲股份有限公司',\n",
    "                   '風采有限公司','英屬維京群島商嘉碼科技有限公司台灣分公司',\n",
    "                   '冠宇數位科技股份有限公司','英仕國際有限公司','元遊科技有限公司',\n",
    "                   '禾碩資訊股份有限公司','向上集團_向上國際科技股份有限公司',\n",
    "                   '弈樂科技股份有限公司','馬來西亞商極限電腦科技有限公司台灣分公司',\n",
    "                   '樂夠科技有限公司','威智國際有限公司','紅信科技有限公司',\n",
    "                   '深思設計有限公司','揚帆科技有限公司','晶要資訊有限公司',\n",
    "                   \n",
    "                  )\n",
    "user = \"yidti\"\n",
    "crawler = Crawler104(filter_params, user)\n",
    "crawler.run(job_keywords, company_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fb4d88-569f-479a-8744-83b657f2fd1d",
   "metadata": {},
   "source": [
    "## 2-2. Web Scraper - 抓取Jobs內容(異步&多線程)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5a93bc8-1f3d-4d8c-85e1-452099853e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet file 'temp/yidti-2024-02-16.parquet' not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jobs: 100%|██████████| 2252/2252 [06:47<00:00,  5.53job/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Details for 2252 Jobs | 花費 407.51 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 新增 temp 暫存檔 parquet\n",
    "crawler.detail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aee73d-a6df-4196-b1c5-255be9e3d291",
   "metadata": {},
   "source": [
    "## 2-3. Export Flie - 輸出至Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e8e103c-3cee-4eff-a52d-aa307d19f80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV文件保存成功: output/yidti-2024-02-16.xlsx\n"
     ]
    }
   ],
   "source": [
    "# output to excel file (job)\n",
    "crawler.export_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c20eb7f-7c49-41fb-9220-64c4ccdbd6fc",
   "metadata": {},
   "source": [
    "# Step 3. Data Lake - 資料存入NoSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dc71e9b-0209-4000-b095-6472c2961224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 2013 records, Insert 239 records in jobs_104 collection\n",
      "job keywords - 已刪除不符合關鍵字的文件數量: 0\n",
      "company exclude - 已刪除符合條件的文件數量: 13\n"
     ]
    }
   ],
   "source": [
    "# ouput to noSQL (job, company, industry)\n",
    "data_Lake = DataLake()\n",
    "data_Lake.export_nosql(user, crawler)\n",
    "data_Lake.filter(job_keywords, company_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd23b65-8333-4cec-8337-5b9612cf4615",
   "metadata": {},
   "source": [
    "# Step 4 - Data Warehouse - 資料存入MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b36ca7d2-ffd9-4443-86d5-898a131f4a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速執行 reload & import\n",
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "374f16d3-cfac-41f0-989e-a8352ff9fcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['更新', '職缺', '職缺_link', '公司_id', '公司', '公司_link', '產業_id', '產業', '縣市',\n",
       "       '區域', '地址', '經歷', '學歷', '內容', '類別', '科系', '語文', '工具', '技能', '其他', '待遇',\n",
       "       '性質', '管理', '出差', '時段', '休假', '可上', '人數', '福利'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Lake = DataLake()\n",
    "# 先從NoSQL抓資料dataframe\n",
    "df = data_Lake.load_latest()\n",
    "print(len(df))\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "972a76e5-1630-4797-86c3-3f84e9febcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('information_schema',)\n",
      "('job_db',)\n",
      "('mysql',)\n",
      "('performance_schema',)\n",
      "('sakila',)\n",
      "('sys',)\n",
      "('world',)\n"
     ]
    }
   ],
   "source": [
    "# create db\n",
    "import mysql.connector\n",
    "db_name = \"job_db\"\n",
    "\n",
    "def createDB(db_name):\n",
    "    connection = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user = \"root\",\n",
    "        password = \"Sql@1031\",\n",
    "        port = 3306\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {db_name}\")\n",
    "    cursor.execute(\"SHOW DATABASES\")\n",
    "    \n",
    "    for x in cursor:\n",
    "      print(x)\n",
    "\n",
    "    connection.commit()\n",
    "    connection.close()\n",
    "\n",
    "\n",
    "createDB(db_name)\n",
    "# cursor = connectDB(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "37db3900-d264-4d7e-bc88-43531ff95690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension.sql': '-- 把重複性高的column切割出來儲存成 Dimension Table\\n\\n\\n\\n\\n\\n\\n\\n\\n-- 經歷\\nCREATE TABLE IF NOT EXISTS working_exp(  \\n    id INT NOT NULL PRIMARY KEY AUTO_INCREMENT,\\n    year_exp VARCHAR(10) NOT NULL,\\n    UNIQUE (year_exp)\\n);',\n",
       " 'facts.sql': ''}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "def read_sql_file():\n",
    "    try:\n",
    "        # SQL 文件所在的目录路径\n",
    "        sql_directory = 'sql'\n",
    "        sql_script = {}\n",
    "        # 讀取 SQL 檔案\n",
    "        # 获取目录中所有的 SQL 文件\n",
    "        sql_files = [f for f in os.listdir(sql_directory) if f.endswith('.sql')]\n",
    "        for file_name in sql_files:\n",
    "            sql_file_path = os.path.join(sql_directory, file_name)\n",
    "            with open(sql_file_path, 'r') as f:\n",
    "                sql_content = f.read()\n",
    "                sql_script[file_name] = sql_content\n",
    "        return sql_script\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading SQL script from {sql_directory}: {e}\")\n",
    "        return None\n",
    "\n",
    "sql_script = read_sql_file()\n",
    "sql_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0882f6ff-bdce-47cc-82f0-ad66cf1ce126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-- 把重複性高的column切割出來儲存成 Dimension Table\\n\\n\\n\\n\\n\\n\\n\\n\\n-- 經歷\\nCREATE TABLE IF NOT EXISTS working_exp(  \\n    id INT NOT NULL PRIMARY KEY AUTO_INCREMENT,\\n    year_exp VARCHAR(10) NOT NULL,\\n    UNIQUE (year_exp)\\n);'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension = sql_script['dimension.sql']\n",
    "dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4df8edbd-9c75-4a75-89f3-b9acda371352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully executed SQL script\n"
     ]
    }
   ],
   "source": [
    "def execute_sql(db_name, sql_script):\n",
    "    connection = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user = \"root\",\n",
    "        password = \"Sql@1031\",\n",
    "        port = 3306,\n",
    "        database = db_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        # 執行 SQL 內容\n",
    "        cursor.execute(sql_script)\n",
    "        print(\"Successfully executed SQL script\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing SQL script: {e}\")\n",
    "    finally:\n",
    "        # 關閉資料庫連接\n",
    "        connection.close()\n",
    "\n",
    "db_name = \"job_db\"\n",
    "execute_sql(db_name,dimension)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "85630a10-1646-42f3-8dda-776d667298f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2年</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>不拘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1年</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  year_exp\n",
       "0       2年\n",
       "1       不拘\n",
       "2       1年"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_working_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9159eb9c-46e3-4dd7-b393-98d4fb4e16a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import urllib.parse\n",
    "# 对密码进行 URL 编码\n",
    "password = urllib.parse.quote_plus('Sql@1031')\n",
    "# 创建 SQLAlchemy 引擎\n",
    "db_name = \"job_db\"\n",
    "# 创建 SQLAlchemy 引擎\n",
    "engine = create_engine(f'mysql+mysqlconnector://root:{password}@localhost:3306/{db_name}')\n",
    "\n",
    "df_working_exp.to_sql(name='working_exp', con=engine, if_exists='replace', index=False, method='multi', chunksize=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2f49596b-18d4-4c2c-86c2-89e95ded46bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rekam\\AppData\\Local\\Temp\\ipykernel_88184\\1271073965.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_working_exp.to_sql(name='working_exp', con=connection, if_exists='append', index=False)\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\n        SELECT\n            name\n        FROM\n            sqlite_master\n        WHERE\n            type IN ('table', 'view')\n            AND name=?;\n        ': Not all parameters were used in the SQL statement",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\jobscan\\lib\\site-packages\\pandas\\io\\sql.py:2262\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2262\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jobscan\\lib\\site-packages\\mysql\\connector\\cursor_cext.py:369\u001b[0m, in \u001b[0;36mCMySQLCursor.execute\u001b[1;34m(self, operation, params, multi)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m psub\u001b[38;5;241m.\u001b[39mremaining \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ProgrammingError(\n\u001b[0;32m    370\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot all parameters were used in the SQL statement\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             )\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mProgrammingError\u001b[0m: Not all parameters were used in the SQL statement",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m df_working_exp \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m經歷\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m df_working_exp \u001b[38;5;241m=\u001b[39m df_working_exp\u001b[38;5;241m.\u001b[39mrename(columns \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m經歷\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear_exp\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m---> 12\u001b[0m \u001b[43mdf_working_exp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mworking_exp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jobscan\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jobscan\\lib\\site-packages\\pandas\\core\\generic.py:3008\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2813\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2814\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2815\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3004\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   3005\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m   3006\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[1;32m-> 3008\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3009\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3012\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3013\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3014\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3019\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jobscan\\lib\\site-packages\\pandas\\io\\sql.py:788\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    785\u001b[0m     )\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[0;32m    789\u001b[0m         frame,\n\u001b[0;32m    790\u001b[0m         name,\n\u001b[0;32m    791\u001b[0m         if_exists\u001b[38;5;241m=\u001b[39mif_exists,\n\u001b[0;32m    792\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m    793\u001b[0m         index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m    794\u001b[0m         schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m    795\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    796\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    797\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    798\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    799\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[0;32m    800\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jobscan\\lib\\site-packages\\pandas\\io\\sql.py:2438\u001b[0m, in \u001b[0;36mSQLiteDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   2427\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmy_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) not a string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2429\u001b[0m table \u001b[38;5;241m=\u001b[39m SQLiteTable(\n\u001b[0;32m   2430\u001b[0m     name,\n\u001b[0;32m   2431\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2436\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   2437\u001b[0m )\n\u001b[1;32m-> 2438\u001b[0m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39minsert(chunksize, method)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jobscan\\lib\\site-packages\\pandas\\io\\sql.py:925\u001b[0m, in \u001b[0;36mSQLTable.create\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_exists \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfail\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    927\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jobscan\\lib\\site-packages\\pandas\\io\\sql.py:911\u001b[0m, in \u001b[0;36mSQLTable.exists\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexists\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 911\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpd_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jobscan\\lib\\site-packages\\pandas\\io\\sql.py:2453\u001b[0m, in \u001b[0;36mSQLiteDatabase.has_table\u001b[1;34m(self, name, schema)\u001b[0m\n\u001b[0;32m   2442\u001b[0m wld \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2443\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   2444\u001b[0m \u001b[38;5;124mSELECT\u001b[39m\n\u001b[0;32m   2445\u001b[0m \u001b[38;5;124m    name\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;124m    AND name=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwld\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfetchall()) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jobscan\\lib\\site-packages\\pandas\\io\\sql.py:2274\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[0;32m   2273\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2274\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: Execution failed on sql '\n        SELECT\n            name\n        FROM\n            sqlite_master\n        WHERE\n            type IN ('table', 'view')\n            AND name=?;\n        ': Not all parameters were used in the SQL statement"
     ]
    }
   ],
   "source": [
    "# df['經歷']\n",
    "connection = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user = \"root\",\n",
    "        password = \"Sql@1031\",\n",
    "        port = 3306,\n",
    "        database = db_name\n",
    "    )\n",
    "\n",
    "df_working_exp = df[['經歷']].drop_duplicates().reset_index(drop=True)\n",
    "df_working_exp = df_working_exp.rename(columns = {'經歷':'year_exp'})\n",
    "df_working_exp.to_sql(name='working_exp', con=connection, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc38cd-8dbd-4723-8baa-cf8e39c7a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(db_name, sql_script):\n",
    "    connection = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user = \"root\",\n",
    "        password = \"Sql@1031\",\n",
    "        port = 3306,\n",
    "        database = db_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        # 執行 SQL 內容\n",
    "        cursor.execute(sql_script)\n",
    "        print(\"Successfully executed SQL script\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing SQL script: {e}\")\n",
    "    finally:\n",
    "        # 關閉資料庫連接\n",
    "        connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba77c4e2-b4c5-4a50-a571-5d88674a92aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 df 裏頭的某個 column 放到 dimension 的 table裏頭\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bead213b-240a-4a21-893f-fa5da5c85c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test OK\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.getenv(\"MODE\")\n",
    "from sqlalchemy import create_engine, text\n",
    "from urllib.parse import quote\n",
    "\n",
    "# 對密碼進行 URL 編碼\n",
    "user = \"root\"\n",
    "password = quote(\"Sql@1031\")\n",
    "host = \"localhost\"\n",
    "port = 3306\n",
    "db_name = \"job_db\"ZZ\n",
    "# 構建 MySQL 數據庫連接 URL\n",
    "connector_url = f\"mysql+mysqlconnector://{user}:{password}@{host}:{port}/{db_name}\"\n",
    "# print(connector_url)\n",
    "# 創建引擎object\n",
    "engine = create_engine(connector_url, future = True)\n",
    "\n",
    "# SQL 語句範例\n",
    "# sql_statement = \"SELECT * FROM your_table\"  # 替換成實際的表格名稱\n",
    "sql_job_table =  \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS JobsInfo  (\n",
    "            `更新日期` DATE,\n",
    "            `職缺名稱` VARCHAR(100),\n",
    "            `公司名稱` VARCHAR(100),\n",
    "            `工作內容` TEXT,\n",
    "            `職務類別` INT,\n",
    "            `工作待遇` VARCHAR(100),\n",
    "            `工作性質` INT,\n",
    "            `縣市` INT,\n",
    "            `上班地點` VARCHAR(100),\n",
    "            `管理責任` INT,\n",
    "            `出差外派` INT,\n",
    "            `上班時段` VARCHAR(100),\n",
    "            `休假制度` INT,\n",
    "            `可上班日` INT,\n",
    "            `需求人數` VARCHAR(50),\n",
    "            `工作經歷` INT,\n",
    "            `學歷要求` INT,\n",
    "            `科系要求` VARCHAR(50),\n",
    "            `語文條件` VARCHAR(50),\n",
    "            `擅長工具` VARCHAR(500),\n",
    "            `工作技能` VARCHAR(500),\n",
    "            `其他要求` TEXT,\n",
    "            `連結` TEXT,\n",
    "            PRIMARY KEY (`連結`(255))\n",
    ");\n",
    "        \"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    print(\"test OK\")\n",
    "    connection.execute(text(sql_job_table))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7137cbdc-5d82-4170-b450-9fd24551955f",
   "metadata": {},
   "source": [
    "# Step 5 - Data Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470f8917-6fb6-4b01-94ff-098a746f5938",
   "metadata": {},
   "source": [
    "# Step 99. Test Area - 測試區域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d90682b-1ada-4761-8eb0-54c64d0f4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom filter params for search - simon\n",
    "# role = {'ro':'全職'}\n",
    "# zone = {'zone': '4,5'}\n",
    "# indcat = {'indcat':'1001000000,1002000000,1012000000,1014000000'}\n",
    "# exclude = {'excludeJobKeyword': '軟體,會計,文件整理,行政,百貨,資訊,品管,財務,守衛,技術員,法務,品檢,登打,輪班,無經驗,客戶'}\n",
    "# mode = {'mode':'列表'}  # 一次能呈現比較多筆資料\n",
    "# order = {'order':'日期排序'}\n",
    "# asc = {'asc':'遞減'}\n",
    "# filter_params = get_filter_params(role, zone, indcat, exclude, mode, order, asc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e7b2d4-a954-4452-98fc-833e3e40e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果你在一個 Python script 中執行這樣的程式碼，你可能需要使用 asyncio.run() 函數。\n",
    "# 在異步程式碼中，如果你使用 asyncio.gather 函數收集異步任務的結果，而這些任務沒有顯式返回值，\n",
    "# gather 函數將返回一個包含每個異步任務結果的列表，而這些結果通常是 None。\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def async_example(i):\n",
    "    print(f\"Start asynchronous task {i}\")\n",
    "    await asyncio.sleep(1)\n",
    "    print(f\"End asynchronous task {i}\")\n",
    "    return f\"Result of task {i}\"\n",
    "\n",
    "# 直接在 Jupyter cell 中執行\n",
    "tasks = [async_example(i) for i in range(5)]\n",
    "results = await asyncio.gather(*tasks)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a847d05c-e49b-4300-9456-59586cda0f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 計算query時間\n",
    "import pandas as pd\n",
    "current_date = datetime.now().date()    \n",
    "parquet_file = f\"temp-{current_date}.parquet\" \n",
    "parquet_path = f\"temp/{parquet_file}\"\n",
    "df_read = pd.read_parquet(parquet_path)\n",
    "# len(df_read)\n",
    "# df_read\n",
    "# query\n",
    "\n",
    "# pd.read_parquet(parquet_path).query(\"id==13791668\")\n",
    "# CPU times: total: 15.6 ms\n",
    "# Wall time: 12.7 ms\n",
    "# test = pd.read_parquet(parquet_path, filters=[(\"id\", \"=\", 13791668)])\n",
    "# CPU times: total: 0 ns\n",
    "# Wall time: 5.82 ms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
