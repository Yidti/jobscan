{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1d4b84-ce72-4871-8366-dc78a7fb17fb",
   "metadata": {},
   "source": [
    "# Step 1. Reload files & Import Modules - 匯入模組"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c984bd7-9a31-4d81-91c4-aeba6791b17e",
   "metadata": {},
   "source": [
    "## 1-1. Reload files - 重讀檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d407f79-bd35-4d4c-8bbd-114212527717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1141b824-fa82-4335-a02d-00bed81a491a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_warehouse' from 'C:\\\\Users\\\\Rekam\\\\develop\\\\python\\\\jobscan\\\\data_warehouse.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload file if you eaited them\n",
    "import crawler104, config.search_params, async_example, threaded_async_job, jobs104\n",
    "import data_lake, data_warehouse\n",
    "import importlib\n",
    "importlib.reload(crawler104)\n",
    "importlib.reload(async_example)\n",
    "importlib.reload(threaded_async_job)\n",
    "importlib.reload(jobs104)\n",
    "importlib.reload(config.search_params)\n",
    "importlib.reload(data_lake)\n",
    "importlib.reload(data_warehouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f121df8-16a3-4c1b-8ef7-e3d220a52006",
   "metadata": {},
   "source": [
    "## 1-2. Import Modules - 匯入模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58a236b8-7ccd-4cd6-be4e-2b64a7b8e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from crawler104 import Crawler104\n",
    "from config.search_params import get_filter_params\n",
    "from data_lake import DataLake\n",
    "from data_warehouse import DataWarehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24777e1b-41d4-46bf-aad7-f9db3acbebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速執行 reload & import\n",
    "%run main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9919d95d-b673-4216-99ce-107226faf946",
   "metadata": {},
   "source": [
    "# Step 2. Data Source - 爬蟲抓資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df19f934-3f23-4ec5-94e5-5a5f793e0910",
   "metadata": {},
   "source": [
    "## 2-1. Filter Setting - 過濾條件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7582c23b-cd00-4645-99c3-49cd4208a305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "設定排除44家公司\n"
     ]
    }
   ],
   "source": [
    "# custom filter params for search - for yidti\n",
    "role = {'ro':'全職'}\n",
    "keyword = {'keyword':\"後端工程師 python\"}\n",
    "# area = {'area':['新北市', '台北市', '桃園市', '台中市']}\n",
    "isnew = {'isnew':'三日內'}\n",
    "jobexp = {'jobexp':['1年以下', '1-3年']}\n",
    "# 預設\n",
    "mode = {'mode':'列表'}  # 一次能呈現比較多筆資料\n",
    "order = {'order':'日期排序'}\n",
    "asc = {'asc':'遞減'}\n",
    "# filter_params = get_filter_params(role, keyword, area, isnew, jobexp, mode, order, asc)\n",
    "filter_params = get_filter_params(role, keyword, isnew, jobexp, mode, order, asc)\n",
    "# keywords for filter job again\n",
    "job_keywords = ('工程','資料','python','data','數據','後端')\n",
    "# Exclude keywords to filter out companies related to gambling or others that I don't want to consider.\n",
    "company_exclude = ('新加坡商冕創有限公司','新博軟體開發股份有限公司','現觀科技股份有限公司'\n",
    "                   ,'全富數位有限公司','杰思數位有限公司','博凡星國際有限公司',\n",
    "                  '尊博科技股份有限公司','新騎資訊有限公司','新加坡商鈦坦科技股份有限公司台灣分公司',\n",
    "                   '豪穎科技股份有限公司','塶樂微創有限公司','磐弈有限公司',\n",
    "                   '聯訊網路有限公司','冶金數位科技有限公司','肥貓科技有限公司',\n",
    "                   '無名科技有限公司','博澭科技有限公司','緯雲股份有限公司',\n",
    "                   '風采有限公司','英屬維京群島商嘉碼科技有限公司台灣分公司',\n",
    "                   '冠宇數位科技股份有限公司','英仕國際有限公司','元遊科技有限公司',\n",
    "                   '禾碩資訊股份有限公司','向上集團_向上國際科技股份有限公司',\n",
    "                   '弈樂科技股份有限公司','馬來西亞商極限電腦科技有限公司台灣分公司',\n",
    "                   '樂夠科技有限公司','威智國際有限公司','紅信科技有限公司',\n",
    "                   '深思設計有限公司','揚帆科技有限公司','晶要資訊有限公司',\n",
    "                   '九七科技股份有限公司','臣悅科技有限公司','尊承科技股份有限公司',\n",
    "                   '遊戲河流有限公司','唐傳有限公司','捷訊資訊有限公司',\n",
    "                   '逍遙遊科技有限公司','澄果資訊服務有限公司','果遊科技有限公司',\n",
    "                   '昱泉國際股份有限公司','博星數位股份有限公司',\n",
    "                  )\n",
    "user = \"yidti\"\n",
    "crawler = Crawler104(filter_params, user)\n",
    "print(f\"設定排除{len(company_exclude)}家公司\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f2ac55-a1a1-43d7-b10c-7b0a45d15125",
   "metadata": {},
   "source": [
    "## 2-2. Web Crawler - 抓取Jobs清單"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc82644b-0ee1-446c-8a85-25736a64e68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://www.104.com.tw/jobs/search/?ro=1&keyword=%E5%BE%8C%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%AB+python&isnew=3&jobexp=1%2C3&mode=l&order=16&asc=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|██████████| 100/100 [02:15<00:00,  1.36s/page]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "載入100頁 | 載入2967筆資料 | 過濾剩2217筆資料 | 花費 154.67 秒\n"
     ]
    }
   ],
   "source": [
    "# chrome for testing -> https://googlechromelabs.github.io/chrome-for-testing/\n",
    "crawler.run(job_keywords, company_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fb4d88-569f-479a-8744-83b657f2fd1d",
   "metadata": {},
   "source": [
    "## 2-3. Web Scraper - 抓取Jobs內容(異步&多線程)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5a93bc8-1f3d-4d8c-85e1-452099853e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclude exist and close data\n",
      "Remove from parquet, leaving 0 remaining to scrape .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jobs: 0job [00:00, ?job/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Details for 0 Jobs | 花費 0.07 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 新增 temp 暫存檔 parquet\n",
    "crawler.detail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aee73d-a6df-4196-b1c5-255be9e3d291",
   "metadata": {},
   "source": [
    "## 2-3. Export Flie - 輸出至Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e8e103c-3cee-4eff-a52d-aa307d19f80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV文件保存成功: output/yidti-2024-04-16.xlsx\n"
     ]
    }
   ],
   "source": [
    "# output to excel file (job)\n",
    "crawler.export_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c20eb7f-7c49-41fb-9220-64c4ccdbd6fc",
   "metadata": {},
   "source": [
    "# Step 3. Data Lake - 資料存入NoSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4dc71e9b-0209-4000-b095-6472c2961224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 2231 records, Insert 0 records in jobs_104 collection\n",
      "job keywords - 已刪除不符合關鍵字的文件數量: 0\n",
      "company exclude - 已刪除符合條件的文件數量: 0\n"
     ]
    }
   ],
   "source": [
    "# ouput to noSQL (job, company, industry)\n",
    "data_lake = DataLake()\n",
    "data_lake.save_nosql(user, crawler)\n",
    "data_lake.filter(job_keywords, company_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd23b65-8333-4cec-8337-5b9612cf4615",
   "metadata": {},
   "source": [
    "# Step 4 - Data Warehouse - 資料存入MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b36ca7d2-ffd9-4443-86d5-898a131f4a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速執行 reload & import\n",
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b1ae46f-a3c3-46b0-9a79-373d3e5445f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2231"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lake  = DataLake()\n",
    "data_Warehouse = DataWarehouse()\n",
    "data_Warehouse.save_sql(data_lake)\n",
    "len(data_Warehouse.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "374f16d3-cfac-41f0-989e-a8352ff9fcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['更新', '職缺', '職缺_link', '公司_id', '公司', '公司_link', '產業_id', '產業', '縣市',\n",
       "       '區域', '地址', '經歷', '學歷', '內容', '類別', '科系', '語文', '工具', '技能', '其他', '待遇',\n",
       "       '性質', '管理', '出差', '時段', '休假', '可上', '人數', '福利'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Lake = DataLake()\n",
    "# 先從NoSQL抓資料dataframe\n",
    "df = data_Lake.load_latest()\n",
    "print(len(df))\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "ebc02dc3-b4bd-453b-b923-8ae1b452765f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB is created (job_db)\n",
      "Successfully executed SQL script\n",
      "Successfully executed SQL script\n"
     ]
    }
   ],
   "source": [
    "data_Warehouse = DataWarehouse()\n",
    "db_name = \"job_db\"\n",
    "data_Warehouse.createDB(\"job_db\")\n",
    "data_Warehouse.read_sql_file()\n",
    "sql_dimension = data_Warehouse.sql_script['dimension.sql']\n",
    "sql_fact = data_Warehouse.sql_script['fact.sql']\n",
    "data_Warehouse.execute_sql(db_name,sql_dimension)\n",
    "data_Warehouse.execute_sql(db_name,sql_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "c6e3053d-8c79-482e-be66-c8911aecb492",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_dict = {\n",
    "    '更新': 'update',\n",
    "    '職缺': 'position',\n",
    "    '職缺_link': 'position_link',\n",
    "    '公司_id': 'company_id',\n",
    "    '公司': 'company',\n",
    "    '公司_link': 'company_link',\n",
    "    '產業_id': 'industry_id',\n",
    "    '產業': 'industry',\n",
    "    '縣市': 'city',\n",
    "    '區域': 'region',\n",
    "    '地址': 'address',\n",
    "    '經歷': 'experience',\n",
    "    '學歷': 'education',\n",
    "    '內容': 'content',\n",
    "    '類別': 'category',\n",
    "    '科系': 'major',\n",
    "    '語文': 'language',\n",
    "    '工具': 'tool',\n",
    "    '技能': 'skill',\n",
    "    '其他': 'other',\n",
    "    '待遇': 'benefits',\n",
    "    '性質': 'type',\n",
    "    '管理': 'management',\n",
    "    '出差': 'business_trip',\n",
    "    '時段': 'working_hours',\n",
    "    '休假': 'vacation',\n",
    "    '可上': 'available',\n",
    "    '人數': 'quantity',\n",
    "    '福利': 'welfare'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "2f49596b-18d4-4c2c-86c2-89e95ded46bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有要寫入的值都已存在於目標表中，無需進行寫入\n"
     ]
    }
   ],
   "source": [
    "# 將 df 裏頭的某個 column 放到 dimension 的 table裏頭\n",
    "# 將 dimension sql 存入 df['經歷']\n",
    "from sqlalchemy import create_engine\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "\n",
    "# 对密码进行 URL 编码\n",
    "password = urllib.parse.quote_plus('Sql@1031')\n",
    "# 创建 SQLAlchemy 引擎\n",
    "db_name = \"job_db\"\n",
    "# 创建 SQLAlchemy 引擎\n",
    "engine = create_engine(f'mysql+mysqlconnector://root:{password}@localhost:3306/{db_name}')\n",
    "\n",
    "\n",
    "# 將列名重命名為與目標表相匹配的名稱\n",
    "df_new = df.rename(columns=translation_dict)\n",
    "\n",
    "\n",
    "df_working_exp = df_new[['experience']].drop_duplicates().reset_index(drop=True)\n",
    "df_working_exp = df_working_exp.rename(columns = {'experience':'exp_year'})\n",
    "\n",
    "# 讀取目標表的資料\n",
    "existing_data = pd.read_sql('SELECT * FROM experience', con=engine)\n",
    "existing_data\n",
    "# 檢查要寫入的資料是否已存在於目標表中\n",
    "duplicate_rows = df_working_exp[df_working_exp['exp_year'].isin(existing_data['exp_year'])]\n",
    "# 找出要寫入的資料中不重複的值\n",
    "insert_data = df_working_exp[~df_working_exp['exp_year'].isin(existing_data['exp_year'])]\n",
    "insert_data\n",
    "# 如果有不重複的值，將其寫入目標表\n",
    "if not insert_data.empty:\n",
    "    insert_data.to_sql(name='experience', con=engine, if_exists='append', index=False)\n",
    "    print(\"不重複的值已成功寫入目標表\")\n",
    "else:\n",
    "    print(\"所有要寫入的值都已存在於目標表中，無需進行寫入\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "5a2e6f9b-af2d-468d-893d-c50e1014a7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>exp_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1年</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1年以上</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2年</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>不拘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>經歷不拘</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id exp_year\n",
       "0   2       1年\n",
       "1   5     1年以上\n",
       "2   3       2年\n",
       "3   1       不拘\n",
       "4   4     經歷不拘"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 SQLAlchemy 引擎\n",
    "engine = create_engine(f'mysql+mysqlconnector://root:{password}@localhost:3306/{db_name}')\n",
    "existing_experience = pd.read_sql('SELECT * FROM experience', con=engine)\n",
    "existing_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "ea8fafd5-4c26-448b-b262-76864a5e32ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       13824437\n",
       "1       12177177\n",
       "2        8554677\n",
       "3       13445267\n",
       "4       13116901\n",
       "          ...   \n",
       "1768    12465043\n",
       "1769    13609980\n",
       "1770    13302385\n",
       "1771    13245891\n",
       "1772    13942262\n",
       "Name: id_job, Length: 1773, dtype: int64"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 讀取目標表的資料\n",
    "existing_data = pd.read_sql('SELECT * FROM job_info', con=engine)\n",
    "existing_data['id_job']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "28c5b59d-8f8c-4fb2-904f-77b8d7021777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不重複的值已成功寫入目標表, 寫入1筆\n"
     ]
    }
   ],
   "source": [
    "# 將列名重命名為與目標表相匹配的名稱\n",
    "df_new = df.rename(columns=translation_dict)\n",
    "selected_columns = df_new.loc[:, ['position', 'content', 'experience']]\n",
    "selected_columns.reset_index(inplace=True)\n",
    "selected_columns.rename(columns={'id': 'id_job'}, inplace=True)\n",
    "# 將 'working_exp' 列中的值與 'working_exp' 表中的 id 對應起來，以準備作為外鍵\n",
    "selected_columns = selected_columns.merge(existing_experience, left_on='experience', right_on='exp_year', how='left')\n",
    "selected_columns['experience'] = selected_columns['id']\n",
    "# 刪除 'id','year_exp' 列，因為它不再需要\n",
    "selected_columns.drop(columns=['id', 'exp_year'], inplace=True)\n",
    "selected_columns = selected_columns.rename(columns={'experience': 'exp_id'})\n",
    "\n",
    "\n",
    "# 讀取目標表的資料\n",
    "existing_data = pd.read_sql('SELECT * FROM job_info', con=engine)\n",
    "existing_data\n",
    "# 檢查要寫入的資料是否已存在於目標表中\n",
    "duplicate_rows = selected_columns[selected_columns['id_job'].isin(existing_data['id_job'])]\n",
    "# 找出要寫入的資料中不重複的值\n",
    "insert_data = selected_columns[~selected_columns['id_job'].isin(existing_data['id_job'])]\n",
    "insert_data\n",
    "\n",
    "# 如果有不重複的值，將其寫入目標表\n",
    "if not insert_data.empty:\n",
    "    insert_data.to_sql(name='job_info', con=engine, if_exists='append', index=False)\n",
    "    print(f\"不重複的值已成功寫入目標表, 寫入{len(insert_data)}筆\")\n",
    "else:\n",
    "    print(\"所有要寫入的值都已存在於目標表中，無需進行寫入\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a26c8-9f58-4dcd-a57a-410d3ff9f382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假設您已經從 DataFrame 中選擇了 'title'、'description' 和 'working_exp' 這幾列\n",
    "selected_columns = df[['title', 'description', 'working_exp']]\n",
    "\n",
    "# 將 'working_exp' 列中的值與 'working_exp' 表中的 id 對應起來，以準備作為外鍵\n",
    "selected_columns = selected_columns.merge(df_working_exp, left_on='working_exp', right_on='year_exp', how='left')\n",
    "\n",
    "# 刪除 'year_exp' 列，因為它不再需要\n",
    "selected_columns.drop(columns=['year_exp'], inplace=True)\n",
    "\n",
    "# 將選定的列寫入到 job_info 表中\n",
    "selected_columns.to_sql(name='job_info', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7137cbdc-5d82-4170-b450-9fd24551955f",
   "metadata": {},
   "source": [
    "# Step 5 - Data Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470f8917-6fb6-4b01-94ff-098a746f5938",
   "metadata": {},
   "source": [
    "# Step 99. Test Area - 測試區域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bead213b-240a-4a21-893f-fa5da5c85c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test OK\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.getenv(\"MODE\")\n",
    "from sqlalchemy import create_engine, text\n",
    "from urllib.parse import quote\n",
    "\n",
    "# 對密碼進行 URL 編碼\n",
    "user = \"root\"\n",
    "password = quote(\"Sql@1031\")\n",
    "host = \"localhost\"\n",
    "port = 3306\n",
    "db_name = \"job_db\"\n",
    "# 構建 MySQL 數據庫連接 URL\n",
    "connector_url = f\"mysql+mysqlconnector://{user}:{password}@{host}:{port}/{db_name}\"\n",
    "# print(connector_url)\n",
    "# 創建引擎object\n",
    "engine = create_engine(connector_url, future = True)\n",
    "\n",
    "# SQL 語句範例\n",
    "# sql_statement = \"SELECT * FROM your_table\"  # 替換成實際的表格名稱\n",
    "sql_job_table =  \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS JobsInfo  (\n",
    "            `更新日期` DATE,\n",
    "            `職缺名稱` VARCHAR(100),\n",
    "            `公司名稱` VARCHAR(100),\n",
    "            `工作內容` TEXT,\n",
    "            `職務類別` INT,\n",
    "            `工作待遇` VARCHAR(100),\n",
    "            `工作性質` INT,\n",
    "            `縣市` INT,\n",
    "            `上班地點` VARCHAR(100),\n",
    "            `管理責任` INT,\n",
    "            `出差外派` INT,\n",
    "            `上班時段` VARCHAR(100),\n",
    "            `休假制度` INT,\n",
    "            `可上班日` INT,\n",
    "            `需求人數` VARCHAR(50),\n",
    "            `工作經歷` INT,\n",
    "            `學歷要求` INT,\n",
    "            `科系要求` VARCHAR(50),\n",
    "            `語文條件` VARCHAR(50),\n",
    "            `擅長工具` VARCHAR(500),\n",
    "            `工作技能` VARCHAR(500),\n",
    "            `其他要求` TEXT,\n",
    "            `連結` TEXT,\n",
    "            PRIMARY KEY (`連結`(255))\n",
    ");\n",
    "        \"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    print(\"test OK\")\n",
    "    connection.execute(text(sql_job_table))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d90682b-1ada-4761-8eb0-54c64d0f4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom filter params for search - simon\n",
    "# role = {'ro':'全職'}\n",
    "# zone = {'zone': '4,5'}\n",
    "# indcat = {'indcat':'1001000000,1002000000,1012000000,1014000000'}\n",
    "# exclude = {'excludeJobKeyword': '軟體,會計,文件整理,行政,百貨,資訊,品管,財務,守衛,技術員,法務,品檢,登打,輪班,無經驗,客戶'}\n",
    "# mode = {'mode':'列表'}  # 一次能呈現比較多筆資料\n",
    "# order = {'order':'日期排序'}\n",
    "# asc = {'asc':'遞減'}\n",
    "# filter_params = get_filter_params(role, zone, indcat, exclude, mode, order, asc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e7b2d4-a954-4452-98fc-833e3e40e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果你在一個 Python script 中執行這樣的程式碼，你可能需要使用 asyncio.run() 函數。\n",
    "# 在異步程式碼中，如果你使用 asyncio.gather 函數收集異步任務的結果，而這些任務沒有顯式返回值，\n",
    "# gather 函數將返回一個包含每個異步任務結果的列表，而這些結果通常是 None。\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def async_example(i):\n",
    "    print(f\"Start asynchronous task {i}\")\n",
    "    await asyncio.sleep(1)\n",
    "    print(f\"End asynchronous task {i}\")\n",
    "    return f\"Result of task {i}\"\n",
    "\n",
    "# 直接在 Jupyter cell 中執行\n",
    "tasks = [async_example(i) for i in range(5)]\n",
    "results = await asyncio.gather(*tasks)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a847d05c-e49b-4300-9456-59586cda0f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 計算query時間\n",
    "import pandas as pd\n",
    "current_date = datetime.now().date()    \n",
    "parquet_file = f\"temp-{current_date}.parquet\" \n",
    "parquet_path = f\"temp/{parquet_file}\"\n",
    "df_read = pd.read_parquet(parquet_path)\n",
    "# len(df_read)\n",
    "# df_read\n",
    "# query\n",
    "\n",
    "# pd.read_parquet(parquet_path).query(\"id==13791668\")\n",
    "# CPU times: total: 15.6 ms\n",
    "# Wall time: 12.7 ms\n",
    "# test = pd.read_parquet(parquet_path, filters=[(\"id\", \"=\", 13791668)])\n",
    "# CPU times: total: 0 ns\n",
    "# Wall time: 5.82 ms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
