{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1d4b84-ce72-4871-8366-dc78a7fb17fb",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e50a30a2-e1b7-40cc-af24-427c18426ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, time, requests, random\n",
    "from datetime import datetime\n",
    "# 爬蟲\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# import grequests # 看起要在.py才能用\n",
    "\n",
    "# 非同步HTTP請求\n",
    "from aiohttp import ClientSession, TCPConnector\n",
    "# Python標準庫中提供的用於支援異步編程的模組, 可使用async和await關鍵字來定義異步協程\n",
    "import asyncio\n",
    "# 處理嵌套事件迴圈（nested event loop）的庫, 在Python中，通常只能有一個事件迴圈運行，\n",
    "# 但某些情況下，比如在Jupyter Notebook中執行異步代碼時，可能會遇到嵌套事件迴圈的問題。\n",
    "# nest_asyncio的作用就是解決這個問題，允許在已有事件迴圈的情況下再創建一個新的事件迴圈。\n",
    "import nest_asyncio\n",
    "# 它會修改當前執行環境，允許在已有事件迴圈的情況下再次建立一個新的事件迴圈，\n",
    "# 通常用於處理一些特定的情況，例如在Jupyter Notebook中執行異步代碼。\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f2ac55-a1a1-43d7-b10c-7b0a45d15125",
   "metadata": {},
   "source": [
    "# 執行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9220c210-4531-434d-beb7-5d1edd8d79cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config.search_params' from 'C:\\\\Users\\\\Rekam\\\\Documents\\\\Jobscan\\\\config\\\\search_params.py'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import crawler104_async, config.search_params\n",
    "import importlib\n",
    "importlib.reload(crawler104_async)\n",
    "importlib.reload(config.search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7582c23b-cd00-4645-99c3-49cd4208a305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://www.104.com.tw/jobs/search/?ro=1&keyword=%E5%BE%8C%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%AB+python&area=6001002000%2C6001001000%2C6001005000%2C6001008000&isnew=3&jobexp=1%2C3&mode=l&order=16&asc=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|██████████| 15/15 [00:30<00:00,  2.01s/page]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "載入438筆資料 | 過濾後338筆 | 花費 42.61322331428528 秒\n"
     ]
    }
   ],
   "source": [
    "from crawler104_async import JobScan104\n",
    "from config.search_params import get_filter_params\n",
    "import numpy as np\n",
    "\n",
    "keywords_pattern = r'工程|資料|python|data|數據|後端'\n",
    "\n",
    "# custom filter search\n",
    "role = '全職'\n",
    "keyword = \"後端工程師 python\"\n",
    "cities = ['新北市', '台北市', '桃園市', '台中市']\n",
    "isnew = '三日內'\n",
    "jobexp = ['1年以下', '1-3年']\n",
    "model = '列表'  # 一次能呈現比較多筆資料\n",
    "order = '日期排序'\n",
    "asc = '遞減'\n",
    "\n",
    "filter_params = get_filter_params(role, keyword, cities, isnew, jobexp, model, order, asc)\n",
    "\n",
    "# 碼表 Start\n",
    "start_time = time.time()\n",
    "# 建立物件\n",
    "df = pd.DataFrame()\n",
    "js104 = JobScan104(filter_params, keywords_pattern)\n",
    "# 開始爬蟲\n",
    "retry_count = 0\n",
    "while True:\n",
    "    try:\n",
    "        raw_jobs = js104.search_job()\n",
    "        break\n",
    "    except:\n",
    "        retry_count += 1\n",
    "        if retry_count == 3:\n",
    "            break\n",
    "        print(f'執行錯誤, retry {retry_count}')\n",
    "\n",
    "filter_jobs = js104.filter_job(raw_jobs)\n",
    "# result_df = EJS.main(Job_list, DF)\n",
    "# 碼表 End\n",
    "print(f\"花費 {np.round(time.time() - start_time)} 秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e9fcf-9ec0-4afd-aca3-48d4eb7ed65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape():\n",
    "    print('test')\n",
    "\n",
    "\n",
    "# raw_Job_list[20]\n",
    "print(len(filter_jobs))\n",
    "# 每個 batch 的 size (非同步每個 batch 處理)\n",
    "batch_size = 30\n",
    "# 確認 batches 數量\n",
    "num_batches = (len(filter_jobs) + batch_size - 1) // batch_size\n",
    "\n",
    "for batch_idx in range(num_batches):\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = min((batch_idx + 1) * batch_size, len(filter_jobs))\n",
    "    # 每個 batch 頭尾 (0->29; 30->59; ......)\n",
    "    jobs_batch = filter_jobs[start_idx:end_idx]\n",
    "    # 取得異布事件循環\n",
    "    loop = asyncio.get_event_loop()\n",
    "    results = loop.run_until_complete(scrape())\n",
    "    loop.close()\n",
    "\n",
    "#     \n",
    "#     loop = asyncio.get_event_loop()\n",
    "#     results = loop.run_until_complete(self.scrape(Job_list_batch))\n",
    "#     # loop.close()\n",
    "\n",
    "#     for df in results:\n",
    "#         if df is not None:\n",
    "#             DF = pd.concat([DF, df], ignore_index=True)\n",
    "\n",
    "# DF.to_csv(f\"./output/JBLIST_{self.current_date}.csv\", sep=',', index=False)\n",
    "# return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e90e067a-dbad-4979-95f0-7b0a2e95e714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class eJob_search104():\n",
    "    \n",
    "    \n",
    "    def update_date(self, soup) -> str:\n",
    "        update_date = soup.find(\"div\", class_=\"job-header__title\")\n",
    "        return update_date.find('span').text.strip().replace('更新','') if update_date else '無'\n",
    "    \n",
    "    def company(self, soup) -> str:\n",
    "        name = soup.find(\"div\", class_=\"mt-3\")\n",
    "        return name.select_one('div > a').text.strip() if name else '無'\n",
    "    \n",
    "    def jd_info(self, soup) -> dict:\n",
    "        result = {}\n",
    "        JD = soup.find('div', class_='job-description-table row')\n",
    "        if JD:\n",
    "            jd_items = JD.find_all('div', recursive=False)\n",
    "            if jd_items:\n",
    "                    try:\n",
    "                        job_content = jd_items[0].find('p').text if jd_items[0].find('p').text else '無'\n",
    "                    except:\n",
    "                        job_content = '無'\n",
    "\n",
    "                    try:\n",
    "                        job_category = ', '.join(i.text for i in jd_items[1].find_all('u')) if jd_items[1].find_all('u') else '無'\n",
    "                    except:\n",
    "                        job_category = '無'\n",
    "                    \n",
    "                    try:\n",
    "                        salary = jd_items[2].find_all('div', recursive=False)[-1].text.strip() if jd_items[2].find_all('div', recursive=False)[-1].text.strip() else '無'\n",
    "                    except:\n",
    "                        salary = '無'\n",
    "                    \n",
    "                    try:\n",
    "                        job_type = jd_items[3].find_all('div')[-1].text.strip() if jd_items[3].find_all('div')[-1].text.strip() else '無'\n",
    "                    except:\n",
    "                        job_type = '無'\n",
    "\n",
    "                    try:\n",
    "                        workingplace = jd_items[4].find_all('div')[-1].text.strip() if jd_items[4].find_all('div')[-1].text.strip() != '代企業徵才' else None\n",
    "                    except:\n",
    "                        workingplace = '無'\n",
    "\n",
    "                    try:\n",
    "                        management_responsibility = jd_items[6].find_all('div')[-1].text.strip() if jd_items[6].find_all('div')[-1].text.strip() else '無'\n",
    "                    except:\n",
    "                        management_responsibility = '無'\n",
    "                    \n",
    "                    try:\n",
    "                        business_trip = jd_items[7].find_all('div')[-1].text.strip() if jd_items[7].find_all('div')[-1].text.strip() else '無'\n",
    "                    except:\n",
    "                        business_trip = '無'\n",
    "\n",
    "                    try:\n",
    "                        working_duration = jd_items[8].find_all('div')[-1].text.strip() if jd_items[8].find_all('div')[-1].text.strip() else '無'\n",
    "                    except:\n",
    "                        working_duration = '無'\n",
    "                    \n",
    "                    try:\n",
    "                        Holiday_System = jd_items[9].find_all('div')[-1].text.strip() if jd_items[9].find_all('div')[-1].text.strip() else '無'\n",
    "                    except:\n",
    "                        Holiday_System = '無'\n",
    "                    \n",
    "                    try:\n",
    "                        Working_date = jd_items[10].find_all('div')[-1].text.strip() if jd_items[10].find_all('div')[-1].text.strip() else '無'\n",
    "                    except:\n",
    "                        Working_date = '無'\n",
    "                    \n",
    "                    try:\n",
    "                        ppl_required = jd_items[11].find_all('div')[-1].text.strip() if jd_items[11].find_all('div')[-1].text.strip() else '無'\n",
    "                    except:\n",
    "                        ppl_required = '無'\n",
    "\n",
    "\n",
    "                    result = {\n",
    "                                '工作內容': job_content,\n",
    "                                '職務類別': job_category,\n",
    "                                '工作待遇': salary,\n",
    "                                '工作性質': job_type,\n",
    "                                '上班地點': workingplace,\n",
    "                                '管理責任': management_responsibility,\n",
    "                                '出差外派': business_trip,\n",
    "                                '上班時段': working_duration,\n",
    "                                '休假制度': Holiday_System,\n",
    "                                '可上班日': Working_date,\n",
    "                                '需求人數': ppl_required\n",
    "                            }\n",
    "        return result\n",
    "    \n",
    "    def jr_info(self, soup) -> dict:\n",
    "        result = {}\n",
    "        JR = soup.find('div', class_= 'job-requirement-table row')\n",
    "        JRO = soup.find('div', class_= 'job-requirement col opened')\n",
    "        if JR:\n",
    "            jr_items = JR.find_all('div', recursive=False)\n",
    "            if jr_items:\n",
    "                try:\n",
    "                    work_exp = jr_items[0].find_all('div')[-1].text.strip() if jr_items[0].find_all('div')[-1].text.strip() else '無'\n",
    "                except:\n",
    "                    work_exp = '無'\n",
    "                \n",
    "                try:\n",
    "                    academic_require = jr_items[1].find_all('div')[-1].text.strip() if jr_items[1].find_all('div')[-1].text.strip() else '無'\n",
    "                except:\n",
    "                    academic_require = '無'\n",
    "                \n",
    "                try:\n",
    "                    department_require = jr_items[2].find_all('div')[-1].text.strip() if jr_items[2].find_all('div')[-1].text.strip() else '無'\n",
    "                except:\n",
    "                    department_require = '無'\n",
    "\n",
    "                try:\n",
    "                    language = jr_items[3].find('p').text.strip() if jr_items[3].find('p').text.strip() else '無'\n",
    "                except:\n",
    "                    language = '無'\n",
    "\n",
    "                try:\n",
    "                    tool = ', '.join(i.text for i in jr_items[4].find_all('u')) if jr_items[4].find_all('u') else '無'\n",
    "                except:\n",
    "                    tool = '無'\n",
    "                \n",
    "                try:\n",
    "                    working_ability = jr_items[5].find_all('div')[-1].text.strip() if jr_items[5].find_all('div')[-1].text.strip() else '無'\n",
    "                except:\n",
    "                    working_ability = '無'\n",
    "   \n",
    "        try:\n",
    "            others = JRO.find_all('div')[-1].text.strip() if JRO.find_all('div')[-1].text.strip() else '無'\n",
    "        except:\n",
    "            others = '無'\n",
    "\n",
    "        if JR and JRO:\n",
    "            result = {\n",
    "                '工作經歷' : work_exp,\n",
    "                '學歷要求' : academic_require,\n",
    "                '科系要求' : department_require,\n",
    "                '語文條件' : language,\n",
    "                '擅長工具' : tool,\n",
    "                '工作技能' : working_ability,\n",
    "                '其他要求' : others\n",
    "            }\n",
    "\n",
    "        # result = {\n",
    "        #     '工作經歷' : work_exp,\n",
    "        #     '學歷要求' : academic_require,\n",
    "        #     '科系要求' : department_require,\n",
    "        #     '語文條件' : language,\n",
    "        #     '擅長工具' : tool,\n",
    "        #     '工作技能' : working_ability,\n",
    "        #     '其他要求' : others\n",
    "        # }\n",
    "        return result\n",
    "    \n",
    "    async def fetch(self, session, url):\n",
    "        async with session.get(url, headers = {'User-Agent':'GoogleBot'}) as response:\n",
    "            return await response.text()\n",
    "\n",
    "    async def get_job_info(self, item):\n",
    "        try:\n",
    "            title = item['title']\n",
    "            Job_link = f\"https:{item['href']}\"\n",
    "            connector = TCPConnector(limit=10)\n",
    "            async with ClientSession(connector=connector) as session:\n",
    "                html = await self.fetch(session, Job_link)\n",
    "                soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "            Data = {\n",
    "                '更新日期': [self.update_date(soup)],\n",
    "                '職缺名稱': [title],\n",
    "                '公司名稱': [self.company(soup)],\n",
    "                '連結': [Job_link]\n",
    "            }\n",
    "            Data.update(self.jd_info(soup))\n",
    "            Data.update(self.jr_info(soup))\n",
    "            df = pd.DataFrame(Data, columns=['更新日期', '職缺名稱', '公司名稱', '工作內容', '職務類別', '工作待遇',\n",
    "                                            '工作性質', '上班地點', '管理責任', '出差外派', '上班時段', '休假制度',\n",
    "                                            '可上班日', '需求人數', '工作經歷', '學歷要求', '科系要求', '語文條件',\n",
    "                                            '擅長工具', '工作技能', '其他要求', '連結'])\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(\"發生錯誤\", e)\n",
    "            return None\n",
    "\n",
    "    async def scrape(self, Job_list):\n",
    "        tasks = []\n",
    "        semaphore = asyncio.Semaphore(10)  # Limit concurrent requests to 10\n",
    "\n",
    "        for item in Job_list:\n",
    "            async with semaphore:\n",
    "                task = asyncio.ensure_future(self.get_job_info(item))\n",
    "                tasks.append(task)\n",
    "\n",
    "        return await asyncio.gather(*tasks)\n",
    "    \n",
    "    def main(self, Job_list: list, DF):\n",
    "        print(len(Job_list))\n",
    "        batch_size = 30\n",
    "        num_batches = (len(Job_list) + batch_size - 1) // batch_size\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = min((batch_idx + 1) * batch_size, len(Job_list))\n",
    "            Job_list_batch = Job_list[start_idx:end_idx]\n",
    "            loop = asyncio.get_event_loop()\n",
    "            results = loop.run_until_complete(self.scrape(Job_list_batch))\n",
    "            # loop.close()\n",
    "\n",
    "            for df in results:\n",
    "                if df is not None:\n",
    "                    DF = pd.concat([DF, df], ignore_index=True)\n",
    "\n",
    "        DF.to_csv(f\"./output/JBLIST_{self.current_date}.csv\", sep=',', index=False)\n",
    "        return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23e7b2d4-a954-4452-98fc-833e3e40e7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start asynchronous task 0\n",
      "Start asynchronous task 1\n",
      "Start asynchronous task 2\n",
      "Start asynchronous task 3\n",
      "Start asynchronous task 4\n",
      "End asynchronous task 0\n",
      "End asynchronous task 2\n",
      "End asynchronous task 4\n",
      "End asynchronous task 1\n",
      "End asynchronous task 3\n",
      "['Result of task 0', 'Result of task 1', 'Result of task 2', 'Result of task 3', 'Result of task 4']\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def async_example(i):\n",
    "    print(f\"Start asynchronous task {i}\")\n",
    "    await asyncio.sleep(1)\n",
    "    print(f\"End asynchronous task {i}\")\n",
    "    return f\"Result of task {i}\"\n",
    "\n",
    "# 直接在 Jupyter cell 中執行\n",
    "tasks = [async_example(i) for i in range(5)]\n",
    "results = await asyncio.gather(*tasks)\n",
    "print(results)\n",
    "\n",
    "\n",
    "# 如果你在一個 Python script 中執行這樣的程式碼，你可能需要使用 asyncio.run() 函數。\n",
    "# 在異步程式碼中，如果你使用 asyncio.gather 函數收集異步任務的結果，而這些任務沒有顯式返回值，gather 函數將返回一個包含每個異步任務結果的列表，而這些結果通常是 None。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98f4ab-468e-41c0-8d8f-eae76d091d70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
